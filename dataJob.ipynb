{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration des donn√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataFrame=pd.read_csv(\"job-data.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacyNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading spacy-3.6.0-cp311-cp311-win_amd64.whl (12.3 MB)\n",
      "                                              0.0/12.3 MB ? eta -:--:--\n",
      "                                              0.0/12.3 MB 1.4 MB/s eta 0:00:09\n",
      "                                             0.1/12.3 MB 991.0 kB/s eta 0:00:13\n",
      "                                             0.1/12.3 MB 901.1 kB/s eta 0:00:14\n",
      "                                             0.1/12.3 MB 950.9 kB/s eta 0:00:13\n",
      "                                             0.1/12.3 MB 950.9 kB/s eta 0:00:13\n",
      "                                             0.1/12.3 MB 950.9 kB/s eta 0:00:13\n",
      "                                             0.2/12.3 MB 510.2 kB/s eta 0:00:24\n",
      "                                             0.2/12.3 MB 477.7 kB/s eta 0:00:26\n",
      "                                             0.2/12.3 MB 491.5 kB/s eta 0:00:25\n",
      "                                             0.2/12.3 MB 474.7 kB/s eta 0:00:26\n",
      "                                             0.2/12.3 MB 474.7 kB/s eta 0:00:26\n",
      "                                             0.2/12.3 MB 474.7 kB/s eta 0:00:26\n",
      "                                             0.2/12.3 MB 411.8 kB/s eta 0:00:30\n",
      "                                             0.3/12.3 MB 414.4 kB/s eta 0:00:29\n",
      "                                             0.3/12.3 MB 411.4 kB/s eta 0:00:30\n",
      "     -                                       0.3/12.3 MB 427.9 kB/s eta 0:00:28\n",
      "     -                                       0.4/12.3 MB 464.2 kB/s eta 0:00:26\n",
      "     -                                       0.4/12.3 MB 432.9 kB/s eta 0:00:28\n",
      "     -                                       0.4/12.3 MB 453.0 kB/s eta 0:00:27\n",
      "     -                                       0.5/12.3 MB 486.0 kB/s eta 0:00:25\n",
      "     -                                       0.5/12.3 MB 537.2 kB/s eta 0:00:22\n",
      "     -                                       0.6/12.3 MB 542.7 kB/s eta 0:00:22\n",
      "     -                                       0.6/12.3 MB 544.8 kB/s eta 0:00:22\n",
      "     -                                       0.6/12.3 MB 544.8 kB/s eta 0:00:22\n",
      "     --                                      0.7/12.3 MB 574.9 kB/s eta 0:00:21\n",
      "     --                                      0.7/12.3 MB 594.1 kB/s eta 0:00:20\n",
      "     --                                      0.8/12.3 MB 614.1 kB/s eta 0:00:19\n",
      "     --                                      0.8/12.3 MB 623.3 kB/s eta 0:00:19\n",
      "     --                                      0.8/12.3 MB 623.7 kB/s eta 0:00:19\n",
      "     --                                      0.8/12.3 MB 623.7 kB/s eta 0:00:19\n",
      "     --                                      0.8/12.3 MB 623.7 kB/s eta 0:00:19\n",
      "     --                                      0.8/12.3 MB 623.7 kB/s eta 0:00:19\n",
      "     --                                      0.9/12.3 MB 586.5 kB/s eta 0:00:20\n",
      "     --                                      0.9/12.3 MB 588.0 kB/s eta 0:00:20\n",
      "     ---                                     1.0/12.3 MB 585.5 kB/s eta 0:00:20\n",
      "     ---                                     1.0/12.3 MB 586.0 kB/s eta 0:00:20\n",
      "     ---                                     1.0/12.3 MB 594.9 kB/s eta 0:00:19\n",
      "     ---                                     1.1/12.3 MB 602.7 kB/s eta 0:00:19\n",
      "     ---                                     1.1/12.3 MB 621.0 kB/s eta 0:00:18\n",
      "     ---                                     1.2/12.3 MB 638.6 kB/s eta 0:00:18\n",
      "     ---                                     1.2/12.3 MB 655.5 kB/s eta 0:00:17\n",
      "     ----                                    1.3/12.3 MB 650.0 kB/s eta 0:00:17\n",
      "     ----                                    1.3/12.3 MB 645.2 kB/s eta 0:00:18\n",
      "     ----                                    1.4/12.3 MB 680.6 kB/s eta 0:00:16\n",
      "     ----                                    1.4/12.3 MB 675.4 kB/s eta 0:00:17\n",
      "     ----                                    1.5/12.3 MB 684.6 kB/s eta 0:00:16\n",
      "     ----                                    1.5/12.3 MB 683.9 kB/s eta 0:00:16\n",
      "     ----                                    1.5/12.3 MB 687.9 kB/s eta 0:00:16\n",
      "     ----                                    1.6/12.3 MB 691.8 kB/s eta 0:00:16\n",
      "     ----                                    1.6/12.3 MB 691.8 kB/s eta 0:00:16\n",
      "     -----                                   1.6/12.3 MB 686.2 kB/s eta 0:00:16\n",
      "     -----                                   1.6/12.3 MB 685.8 kB/s eta 0:00:16\n",
      "     -----                                   1.7/12.3 MB 676.5 kB/s eta 0:00:16\n",
      "     -----                                   1.7/12.3 MB 676.5 kB/s eta 0:00:16\n",
      "     -----                                   1.7/12.3 MB 663.7 kB/s eta 0:00:16\n",
      "     -----                                   1.7/12.3 MB 663.5 kB/s eta 0:00:16\n",
      "     -----                                   1.7/12.3 MB 659.4 kB/s eta 0:00:16\n",
      "     -----                                   1.7/12.3 MB 659.4 kB/s eta 0:00:16\n",
      "     -----                                   1.7/12.3 MB 640.2 kB/s eta 0:00:17\n",
      "     -----                                   1.8/12.3 MB 640.5 kB/s eta 0:00:17\n",
      "     -----                                   1.8/12.3 MB 644.3 kB/s eta 0:00:17\n",
      "     -----                                   1.8/12.3 MB 648.1 kB/s eta 0:00:17\n",
      "     -----                                   1.8/12.3 MB 648.1 kB/s eta 0:00:17\n",
      "     -----                                   1.8/12.3 MB 648.1 kB/s eta 0:00:17\n",
      "     -----                                   1.8/12.3 MB 648.1 kB/s eta 0:00:17\n",
      "     -----                                   1.8/12.3 MB 648.1 kB/s eta 0:00:17\n",
      "     -----                                   1.8/12.3 MB 648.1 kB/s eta 0:00:17\n",
      "     ------                                  1.9/12.3 MB 606.2 kB/s eta 0:00:18\n",
      "     ------                                  1.9/12.3 MB 606.2 kB/s eta 0:00:18\n",
      "     ------                                  1.9/12.3 MB 598.2 kB/s eta 0:00:18\n",
      "     ------                                  2.0/12.3 MB 595.9 kB/s eta 0:00:18\n",
      "     ------                                  2.0/12.3 MB 595.9 kB/s eta 0:00:18\n",
      "     ------                                  2.0/12.3 MB 595.9 kB/s eta 0:00:18\n",
      "     ------                                  2.0/12.3 MB 595.9 kB/s eta 0:00:18\n",
      "     ------                                  2.0/12.3 MB 572.0 kB/s eta 0:00:18\n",
      "     ------                                  2.0/12.3 MB 573.1 kB/s eta 0:00:18\n",
      "     ------                                  2.0/12.3 MB 568.4 kB/s eta 0:00:19\n",
      "     ------                                  2.0/12.3 MB 568.4 kB/s eta 0:00:19\n",
      "     ------                                  2.0/12.3 MB 568.4 kB/s eta 0:00:19\n",
      "     ------                                  2.0/12.3 MB 568.4 kB/s eta 0:00:19\n",
      "     ------                                  2.0/12.3 MB 568.4 kB/s eta 0:00:19\n",
      "     ------                                  2.0/12.3 MB 568.4 kB/s eta 0:00:19\n",
      "     ------                                  2.0/12.3 MB 529.7 kB/s eta 0:00:20\n",
      "     ------                                  2.1/12.3 MB 537.7 kB/s eta 0:00:19\n",
      "     ------                                  2.1/12.3 MB 537.7 kB/s eta 0:00:19\n",
      "     ------                                  2.1/12.3 MB 537.7 kB/s eta 0:00:19\n",
      "     ------                                  2.1/12.3 MB 537.7 kB/s eta 0:00:19\n",
      "     ------                                  2.1/12.3 MB 537.7 kB/s eta 0:00:19\n",
      "     ------                                  2.1/12.3 MB 510.4 kB/s eta 0:00:20\n",
      "     ------                                  2.1/12.3 MB 510.4 kB/s eta 0:00:20\n",
      "     ------                                  2.1/12.3 MB 510.4 kB/s eta 0:00:20\n",
      "     ------                                  2.1/12.3 MB 501.9 kB/s eta 0:00:21\n",
      "     ------                                  2.1/12.3 MB 497.5 kB/s eta 0:00:21\n",
      "     ------                                  2.1/12.3 MB 497.5 kB/s eta 0:00:21\n",
      "     ------                                  2.2/12.3 MB 493.9 kB/s eta 0:00:21\n",
      "     ------                                  2.2/12.3 MB 492.7 kB/s eta 0:00:21\n",
      "     -------                                 2.2/12.3 MB 496.7 kB/s eta 0:00:21\n",
      "     -------                                 2.2/12.3 MB 493.8 kB/s eta 0:00:21\n",
      "     -------                                 2.3/12.3 MB 493.8 kB/s eta 0:00:21\n",
      "     -------                                 2.3/12.3 MB 499.4 kB/s eta 0:00:20\n",
      "     -------                                 2.3/12.3 MB 501.0 kB/s eta 0:00:20\n",
      "     -------                                 2.4/12.3 MB 506.9 kB/s eta 0:00:20\n",
      "     -------                                 2.4/12.3 MB 510.0 kB/s eta 0:00:20\n",
      "     -------                                 2.5/12.3 MB 516.2 kB/s eta 0:00:19\n",
      "     -------                                 2.5/12.3 MB 517.5 kB/s eta 0:00:19\n",
      "     --------                                2.5/12.3 MB 522.6 kB/s eta 0:00:19\n",
      "     --------                                2.6/12.3 MB 523.9 kB/s eta 0:00:19\n",
      "     --------                                2.6/12.3 MB 523.5 kB/s eta 0:00:19\n",
      "     --------                                2.7/12.3 MB 528.8 kB/s eta 0:00:19\n",
      "     --------                                2.7/12.3 MB 533.3 kB/s eta 0:00:18\n",
      "     --------                                2.7/12.3 MB 536.8 kB/s eta 0:00:18\n",
      "     --------                                2.8/12.3 MB 541.9 kB/s eta 0:00:18\n",
      "     ---------                               2.8/12.3 MB 544.9 kB/s eta 0:00:18\n",
      "     ---------                               2.9/12.3 MB 549.8 kB/s eta 0:00:18\n",
      "     ---------                               3.0/12.3 MB 558.4 kB/s eta 0:00:17\n",
      "     ---------                               3.0/12.3 MB 565.0 kB/s eta 0:00:17\n",
      "     ---------                               3.1/12.3 MB 571.5 kB/s eta 0:00:17\n",
      "     ----------                              3.2/12.3 MB 579.8 kB/s eta 0:00:16\n",
      "     ----------                              3.2/12.3 MB 586.2 kB/s eta 0:00:16\n",
      "     ----------                              3.2/12.3 MB 588.3 kB/s eta 0:00:16\n",
      "     ----------                              3.3/12.3 MB 591.0 kB/s eta 0:00:16\n",
      "     ----------                              3.4/12.3 MB 598.8 kB/s eta 0:00:15\n",
      "     ----------                              3.4/12.3 MB 606.4 kB/s eta 0:00:15\n",
      "     -----------                             3.5/12.3 MB 617.7 kB/s eta 0:00:15\n",
      "     -----------                             3.6/12.3 MB 619.7 kB/s eta 0:00:15\n",
      "     -----------                             3.7/12.3 MB 628.8 kB/s eta 0:00:14\n",
      "     -----------                             3.7/12.3 MB 639.6 kB/s eta 0:00:14\n",
      "     ------------                            3.8/12.3 MB 646.7 kB/s eta 0:00:14\n",
      "     ------------                            3.9/12.3 MB 660.5 kB/s eta 0:00:13\n",
      "     ------------                            4.0/12.3 MB 664.0 kB/s eta 0:00:13\n",
      "     ------------                            4.1/12.3 MB 677.6 kB/s eta 0:00:13\n",
      "     -------------                           4.2/12.3 MB 685.8 kB/s eta 0:00:12\n",
      "     -------------                           4.3/12.3 MB 695.6 kB/s eta 0:00:12\n",
      "     -------------                           4.4/12.3 MB 707.0 kB/s eta 0:00:12\n",
      "     --------------                          4.4/12.3 MB 709.9 kB/s eta 0:00:12\n",
      "     --------------                          4.5/12.3 MB 717.6 kB/s eta 0:00:11\n",
      "     --------------                          4.6/12.3 MB 728.5 kB/s eta 0:00:11\n",
      "     --------------                          4.7/12.3 MB 737.8 kB/s eta 0:00:11\n",
      "     ---------------                         4.7/12.3 MB 742.1 kB/s eta 0:00:11\n",
      "     ---------------                         4.8/12.3 MB 750.9 kB/s eta 0:00:10\n",
      "     ---------------                         4.9/12.3 MB 759.9 kB/s eta 0:00:10\n",
      "     ---------------                         5.0/12.3 MB 767.0 kB/s eta 0:00:10\n",
      "     ---------------                         5.0/12.3 MB 767.0 kB/s eta 0:00:10\n",
      "     ----------------                        5.0/12.3 MB 758.9 kB/s eta 0:00:10\n",
      "     ----------------                        5.1/12.3 MB 762.8 kB/s eta 0:00:10\n",
      "     ----------------                        5.2/12.3 MB 766.9 kB/s eta 0:00:10\n",
      "     ----------------                        5.3/12.3 MB 776.7 kB/s eta 0:00:10\n",
      "     ----------------                        5.3/12.3 MB 777.4 kB/s eta 0:00:09\n",
      "     ----------------                        5.3/12.3 MB 779.8 kB/s eta 0:00:09\n",
      "     -----------------                       5.4/12.3 MB 777.3 kB/s eta 0:00:09\n",
      "     -----------------                       5.4/12.3 MB 780.9 kB/s eta 0:00:09\n",
      "     -----------------                       5.5/12.3 MB 783.0 kB/s eta 0:00:09\n",
      "     -----------------                       5.5/12.3 MB 788.5 kB/s eta 0:00:09\n",
      "     -----------------                       5.6/12.3 MB 788.5 kB/s eta 0:00:09\n",
      "     ------------------                      5.7/12.3 MB 796.6 kB/s eta 0:00:09\n",
      "     ------------------                      5.8/12.3 MB 801.0 kB/s eta 0:00:09\n",
      "     ------------------                      5.9/12.3 MB 811.8 kB/s eta 0:00:08\n",
      "     ------------------                      5.9/12.3 MB 813.5 kB/s eta 0:00:08\n",
      "     ------------------                      5.9/12.3 MB 812.3 kB/s eta 0:00:08\n",
      "     -------------------                     6.0/12.3 MB 816.1 kB/s eta 0:00:08\n",
      "     -------------------                     6.1/12.3 MB 817.5 kB/s eta 0:00:08\n",
      "     -------------------                     6.1/12.3 MB 820.6 kB/s eta 0:00:08\n",
      "     -------------------                     6.2/12.3 MB 825.1 kB/s eta 0:00:08\n",
      "     -------------------                     6.3/12.3 MB 830.8 kB/s eta 0:00:08\n",
      "     --------------------                    6.3/12.3 MB 835.5 kB/s eta 0:00:08\n",
      "     --------------------                    6.4/12.3 MB 842.0 kB/s eta 0:00:07\n",
      "     --------------------                    6.5/12.3 MB 844.9 kB/s eta 0:00:07\n",
      "     --------------------                    6.5/12.3 MB 844.9 kB/s eta 0:00:07\n",
      "     --------------------                    6.5/12.3 MB 844.9 kB/s eta 0:00:07\n",
      "     --------------------                    6.5/12.3 MB 844.9 kB/s eta 0:00:07\n",
      "     --------------------                    6.5/12.3 MB 844.9 kB/s eta 0:00:07\n",
      "     --------------------                    6.5/12.3 MB 844.9 kB/s eta 0:00:07\n",
      "     --------------------                    6.5/12.3 MB 844.9 kB/s eta 0:00:07\n",
      "     --------------------                    6.5/12.3 MB 844.9 kB/s eta 0:00:07\n",
      "     --------------------                    6.5/12.3 MB 844.9 kB/s eta 0:00:07\n",
      "     --------------------                    6.5/12.3 MB 844.9 kB/s eta 0:00:07\n",
      "     --------------------                    6.5/12.3 MB 844.9 kB/s eta 0:00:07\n",
      "     --------------------                    6.6/12.3 MB 803.2 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 803.2 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 803.2 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 803.2 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 803.2 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 803.2 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 803.2 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 776.1 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 776.1 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 776.1 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 776.1 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 776.1 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 776.1 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 776.1 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 776.1 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 776.1 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 776.1 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 776.1 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 776.1 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 776.1 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 776.1 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 776.1 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 776.1 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 776.1 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 776.1 kB/s eta 0:00:08\n",
      "     --------------------                    6.6/12.3 MB 776.1 kB/s eta 0:00:08\n",
      "     ---------------------                   6.7/12.3 MB 709.9 kB/s eta 0:00:08\n",
      "     ---------------------                   6.7/12.3 MB 709.9 kB/s eta 0:00:08\n",
      "     ---------------------                   6.7/12.3 MB 709.9 kB/s eta 0:00:08\n",
      "     ---------------------                   6.7/12.3 MB 709.9 kB/s eta 0:00:08\n",
      "     ---------------------                   6.7/12.3 MB 709.9 kB/s eta 0:00:08\n",
      "     ---------------------                   6.7/12.3 MB 694.8 kB/s eta 0:00:09\n",
      "     ---------------------                   6.7/12.3 MB 694.8 kB/s eta 0:00:09\n",
      "     ---------------------                   6.7/12.3 MB 694.8 kB/s eta 0:00:09\n",
      "     ---------------------                   6.7/12.3 MB 694.8 kB/s eta 0:00:09\n",
      "     ---------------------                   6.7/12.3 MB 694.8 kB/s eta 0:00:09\n",
      "     ---------------------                   6.7/12.3 MB 694.8 kB/s eta 0:00:09\n",
      "     ---------------------                   6.7/12.3 MB 694.8 kB/s eta 0:00:09\n",
      "     ---------------------                   6.7/12.3 MB 694.8 kB/s eta 0:00:09\n",
      "     ---------------------                   6.7/12.3 MB 694.8 kB/s eta 0:00:09\n",
      "     ---------------------                   6.7/12.3 MB 670.7 kB/s eta 0:00:09\n",
      "     ---------------------                   6.7/12.3 MB 670.7 kB/s eta 0:00:09\n",
      "     ---------------------                   6.7/12.3 MB 670.7 kB/s eta 0:00:09\n",
      "     ---------------------                   6.7/12.3 MB 670.7 kB/s eta 0:00:09\n",
      "     ---------------------                   6.7/12.3 MB 670.7 kB/s eta 0:00:09\n",
      "     ---------------------                   6.7/12.3 MB 670.7 kB/s eta 0:00:09\n",
      "     ---------------------                   6.7/12.3 MB 670.7 kB/s eta 0:00:09\n",
      "     ---------------------                   6.7/12.3 MB 670.7 kB/s eta 0:00:09\n",
      "     ---------------------                   6.8/12.3 MB 648.5 kB/s eta 0:00:09\n",
      "     ---------------------                   6.8/12.3 MB 647.5 kB/s eta 0:00:09\n",
      "     ---------------------                   6.8/12.3 MB 644.7 kB/s eta 0:00:09\n",
      "     ---------------------                   6.8/12.3 MB 643.7 kB/s eta 0:00:09\n",
      "     ---------------------                   6.8/12.3 MB 640.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.8/12.3 MB 640.0 kB/s eta 0:00:09\n",
      "     ---------------------                   6.8/12.3 MB 640.0 kB/s eta 0:00:09\n",
      "     ---------------------                   6.8/12.3 MB 640.0 kB/s eta 0:00:09\n",
      "     ---------------------                   6.8/12.3 MB 640.0 kB/s eta 0:00:09\n",
      "     ---------------------                   6.8/12.3 MB 640.0 kB/s eta 0:00:09\n",
      "     ---------------------                   6.8/12.3 MB 640.0 kB/s eta 0:00:09\n",
      "     ---------------------                   6.8/12.3 MB 640.0 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 622.8 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 622.8 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 621.1 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 621.1 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 621.1 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 615.9 kB/s eta 0:00:09\n",
      "     ---------------------                   6.9/12.3 MB 482.2 kB/s eta 0:00:12\n",
      "     ---------------------                   6.9/12.3 MB 482.2 kB/s eta 0:00:12\n",
      "     ---------------------                   6.9/12.3 MB 482.2 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 479.5 kB/s eta 0:00:12\n",
      "     ----------------------                  6.9/12.3 MB 406.7 kB/s eta 0:00:14\n",
      "     ----------------------                  6.9/12.3 MB 406.7 kB/s eta 0:00:14\n",
      "     ----------------------                  6.9/12.3 MB 406.7 kB/s eta 0:00:14\n",
      "     ----------------------                  6.9/12.3 MB 406.7 kB/s eta 0:00:14\n",
      "     ----------------------                  6.9/12.3 MB 406.7 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 402.7 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 402.7 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.8 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.8 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 400.1 kB/s eta 0:00:14\n",
      "     ----------------------                  7.0/12.3 MB 258.5 kB/s eta 0:00:21\n",
      "     ----------------------                  7.0/12.3 MB 258.5 kB/s eta 0:00:21\n",
      "     ----------------------                  7.0/12.3 MB 258.5 kB/s eta 0:00:21\n",
      "     ----------------------                  7.0/12.3 MB 258.5 kB/s eta 0:00:21\n",
      "     ----------------------                  7.0/12.3 MB 258.5 kB/s eta 0:00:21\n",
      "     ----------------------                  7.0/12.3 MB 256.7 kB/s eta 0:00:21\n",
      "     ----------------------                  7.0/12.3 MB 256.7 kB/s eta 0:00:21\n",
      "     ----------------------                  7.0/12.3 MB 256.7 kB/s eta 0:00:21\n",
      "     ----------------------                  7.0/12.3 MB 256.3 kB/s eta 0:00:21\n",
      "     ----------------------                  7.0/12.3 MB 256.3 kB/s eta 0:00:21\n",
      "     ----------------------                  7.1/12.3 MB 255.6 kB/s eta 0:00:21\n",
      "     ----------------------                  7.1/12.3 MB 255.6 kB/s eta 0:00:21\n",
      "     ----------------------                  7.1/12.3 MB 255.8 kB/s eta 0:00:21\n",
      "     ----------------------                  7.1/12.3 MB 256.1 kB/s eta 0:00:21\n",
      "     ----------------------                  7.1/12.3 MB 256.5 kB/s eta 0:00:21\n",
      "     ----------------------                  7.1/12.3 MB 256.5 kB/s eta 0:00:21\n",
      "     ----------------------                  7.2/12.3 MB 256.8 kB/s eta 0:00:20\n",
      "     ----------------------                  7.2/12.3 MB 257.4 kB/s eta 0:00:20\n",
      "     ----------------------                  7.2/12.3 MB 257.8 kB/s eta 0:00:20\n",
      "     ----------------------                  7.2/12.3 MB 257.9 kB/s eta 0:00:20\n",
      "     -----------------------                 7.3/12.3 MB 258.6 kB/s eta 0:00:20\n",
      "     -----------------------                 7.3/12.3 MB 259.3 kB/s eta 0:00:20\n",
      "     -----------------------                 7.3/12.3 MB 259.4 kB/s eta 0:00:20\n",
      "     -----------------------                 7.3/12.3 MB 259.8 kB/s eta 0:00:20\n",
      "     -----------------------                 7.4/12.3 MB 260.2 kB/s eta 0:00:19\n",
      "     -----------------------                 7.4/12.3 MB 261.0 kB/s eta 0:00:19\n",
      "     -----------------------                 7.4/12.3 MB 262.0 kB/s eta 0:00:19\n",
      "     -----------------------                 7.5/12.3 MB 262.7 kB/s eta 0:00:19\n",
      "     -----------------------                 7.5/12.3 MB 264.0 kB/s eta 0:00:19\n",
      "     -----------------------                 7.5/12.3 MB 264.7 kB/s eta 0:00:18\n",
      "     ------------------------                7.6/12.3 MB 265.6 kB/s eta 0:00:18\n",
      "     ------------------------                7.6/12.3 MB 266.7 kB/s eta 0:00:18\n",
      "     ------------------------                7.7/12.3 MB 268.0 kB/s eta 0:00:18\n",
      "     ------------------------                7.7/12.3 MB 269.7 kB/s eta 0:00:17\n",
      "     ------------------------                7.8/12.3 MB 271.6 kB/s eta 0:00:17\n",
      "     -------------------------               7.9/12.3 MB 273.8 kB/s eta 0:00:17\n",
      "     -------------------------               8.0/12.3 MB 276.2 kB/s eta 0:00:16\n",
      "     -------------------------               8.0/12.3 MB 278.1 kB/s eta 0:00:16\n",
      "     -------------------------               8.1/12.3 MB 279.1 kB/s eta 0:00:16\n",
      "     -------------------------               8.1/12.3 MB 281.3 kB/s eta 0:00:15\n",
      "     --------------------------              8.2/12.3 MB 283.5 kB/s eta 0:00:15\n",
      "     --------------------------              8.3/12.3 MB 285.1 kB/s eta 0:00:15\n",
      "     --------------------------              8.4/12.3 MB 288.2 kB/s eta 0:00:14\n",
      "     --------------------------              8.4/12.3 MB 288.2 kB/s eta 0:00:14\n",
      "     --------------------------              8.4/12.3 MB 289.0 kB/s eta 0:00:14\n",
      "     --------------------------              8.4/12.3 MB 288.9 kB/s eta 0:00:14\n",
      "     --------------------------              8.5/12.3 MB 289.5 kB/s eta 0:00:14\n",
      "     ---------------------------             8.5/12.3 MB 290.7 kB/s eta 0:00:13\n",
      "     ---------------------------             8.5/12.3 MB 291.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.6/12.3 MB 292.4 kB/s eta 0:00:13\n",
      "     ---------------------------             8.6/12.3 MB 292.4 kB/s eta 0:00:13\n",
      "     ---------------------------             8.6/12.3 MB 292.4 kB/s eta 0:00:13\n",
      "     ---------------------------             8.6/12.3 MB 292.4 kB/s eta 0:00:13\n",
      "     ---------------------------             8.6/12.3 MB 292.4 kB/s eta 0:00:13\n",
      "     ---------------------------             8.6/12.3 MB 292.4 kB/s eta 0:00:13\n",
      "     ---------------------------             8.6/12.3 MB 292.4 kB/s eta 0:00:13\n",
      "     ---------------------------             8.6/12.3 MB 292.4 kB/s eta 0:00:13\n",
      "     ---------------------------             8.6/12.3 MB 292.4 kB/s eta 0:00:13\n",
      "     ---------------------------             8.6/12.3 MB 292.4 kB/s eta 0:00:13\n",
      "     ---------------------------             8.6/12.3 MB 292.4 kB/s eta 0:00:13\n",
      "     ---------------------------             8.6/12.3 MB 292.4 kB/s eta 0:00:13\n",
      "     ---------------------------             8.6/12.3 MB 292.4 kB/s eta 0:00:13\n",
      "     ---------------------------             8.6/12.3 MB 292.4 kB/s eta 0:00:13\n",
      "     ---------------------------             8.6/12.3 MB 292.4 kB/s eta 0:00:13\n",
      "     ---------------------------             8.6/12.3 MB 285.0 kB/s eta 0:00:13\n",
      "     ---------------------------             8.6/12.3 MB 285.0 kB/s eta 0:00:13\n",
      "     ---------------------------             8.7/12.3 MB 286.0 kB/s eta 0:00:13\n",
      "     ---------------------------             8.7/12.3 MB 286.0 kB/s eta 0:00:13\n",
      "     ---------------------------             8.7/12.3 MB 286.0 kB/s eta 0:00:13\n",
      "     ---------------------------             8.7/12.3 MB 286.0 kB/s eta 0:00:13\n",
      "     ---------------------------             8.7/12.3 MB 286.0 kB/s eta 0:00:13\n",
      "     ---------------------------             8.7/12.3 MB 286.0 kB/s eta 0:00:13\n",
      "     ---------------------------             8.7/12.3 MB 286.0 kB/s eta 0:00:13\n",
      "     ---------------------------             8.7/12.3 MB 286.0 kB/s eta 0:00:13\n",
      "     ---------------------------             8.7/12.3 MB 286.0 kB/s eta 0:00:13\n",
      "     ---------------------------             8.7/12.3 MB 286.0 kB/s eta 0:00:13\n",
      "     ---------------------------             8.7/12.3 MB 286.0 kB/s eta 0:00:13\n",
      "     ---------------------------             8.7/12.3 MB 286.0 kB/s eta 0:00:13\n",
      "     ---------------------------             8.7/12.3 MB 286.0 kB/s eta 0:00:13\n",
      "     ---------------------------             8.7/12.3 MB 286.0 kB/s eta 0:00:13\n",
      "     ---------------------------             8.7/12.3 MB 286.0 kB/s eta 0:00:13\n",
      "     ---------------------------             8.7/12.3 MB 286.0 kB/s eta 0:00:13\n",
      "     ---------------------------             8.7/12.3 MB 286.0 kB/s eta 0:00:13\n",
      "     ---------------------------             8.7/12.3 MB 286.0 kB/s eta 0:00:13\n",
      "     ---------------------------             8.7/12.3 MB 272.4 kB/s eta 0:00:14\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 273.2 kB/s eta 0:00:13\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n",
      "     ---------------------------             8.8/12.3 MB 235.9 kB/s eta 0:00:15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher\n",
      "    yield\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 561, in read\n",
      "    data = self._fp_read(amt) if not fp_closed else b\"\"\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 527, in _fp_read\n",
      "    return self._fp.read(amt) if amt is not None else self._fp.read()\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 90, in read\n",
      "    data = self.__fp.read(amt)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\http\\client.py\", line 466, in read\n",
      "    s = self.fp.read(amt)\n",
      "        ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\socket.py\", line 706, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\ssl.py\", line 1278, in recv_into\n",
      "    return self.read(nbytes, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\ssl.py\", line 1134, in read\n",
      "    return self._sslobj.read(len, buffer)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TimeoutError: The read operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 169, in exc_logging_wrapper\n",
      "    status = run_func(*args)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 248, in wrapper\n",
      "    return func(self, options, args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 377, in run\n",
      "    requirement_set = resolver.resolve(\n",
      "                      ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 92, in resolve\n",
      "    result = self._result = resolver.resolve(\n",
      "                            ^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 546, in resolve\n",
      "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 397, in resolve\n",
      "    self._add_to_criteria(self.state.criteria, r, parent=None)\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 173, in _add_to_criteria\n",
      "    if not criterion.candidates:\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 156, in __bool__\n",
      "    return bool(self._sequence)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 155, in __bool__\n",
      "    return any(self)\n",
      "           ^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 143, in <genexpr>\n",
      "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 47, in _iter_built\n",
      "    candidate = func()\n",
      "                ^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 206, in _make_candidate_from_link\n",
      "    self._link_candidate_cache[link] = LinkCandidate(\n",
      "                                       ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 293, in __init__\n",
      "    super().__init__(\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 156, in __init__\n",
      "    self.dist = self._prepare()\n",
      "                ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 225, in _prepare\n",
      "    dist = self._prepare_distribution()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 304, in _prepare_distribution\n",
      "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 516, in prepare_linked_requirement\n",
      "    return self._prepare_linked_requirement(req, parallel_builds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 587, in _prepare_linked_requirement\n",
      "    local_file = unpack_url(\n",
      "                 ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 166, in unpack_url\n",
      "    file = get_http_url(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 107, in get_http_url\n",
      "    from_path, content_type = download(link, temp_dir.path)\n",
      "                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_internal\\network\\download.py\", line 147, in __call__\n",
      "    for chunk in chunks:\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 53, in _rich_progress_bar\n",
      "    for chunk in iterable:\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 63, in response_chunks\n",
      "    for chunk in response.raw.stream(\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 622, in stream\n",
      "    data = self.read(amt=amt, decode_content=decode_content)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 560, in read\n",
      "    with self._error_catcher():\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\contextlib.py\", line 155, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"c:\\Users\\LENOVO\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 443, in _error_catcher\n",
      "    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\n",
      "pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspacy\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Load the spaCy language model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39men_core_web_sm\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Sample job titles (replace this with your actual job titles)\n",
    "job_titles =dataFrame['Job Title']\n",
    "\n",
    "# Define a function to extract location from job titles\n",
    "def extract_location(text):\n",
    "    doc = nlp(text)\n",
    "    location = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in ['GPE', 'LOC']:  # GPE: Geo-Political Entity, LOC: Location\n",
    "            location.append(ent.text)\n",
    "    if \"remote\" in text.lower():\n",
    "        location.append(\"Remote\")\n",
    "    return location\n",
    "\n",
    "# Create a new 'location' column with extracted locations\n",
    "location_column = [extract_location(title) for title in job_titles]\n",
    "\n",
    "# Combine the job titles and locations into a DataFrame (assuming you already have a DataFrame for job titles)\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Job Title': job_titles,\n",
    "    'Location': location_column\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "                                              0.0/77.1 kB ? eta -:--:--\n",
      "     ---------------                          30.7/77.1 kB ? eta -:--:--\n",
      "     --------------------                   41.0/77.1 kB 653.6 kB/s eta 0:00:01\n",
      "     --------------------                   41.0/77.1 kB 653.6 kB/s eta 0:00:01\n",
      "     -----------------------------------    71.7/77.1 kB 280.5 kB/s eta 0:00:01\n",
      "     -------------------------------------- 77.1/77.1 kB 251.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\miniconda3\\envs\\scraping_brief\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.65.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame = dataFrame.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sgs</td>\n",
       "      <td>clinical data analyst</td>\n",
       "      <td>richardson, tx, united states</td>\n",
       "      <td>full time</td>\n",
       "      <td>entry-level</td>\n",
       "      <td>48k+ *</td>\n",
       "      <td>computer science,data quality,genetics,mathema...</td>\n",
       "      <td>,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ocorian</td>\n",
       "      <td>aml/cft &amp; data analyst</td>\n",
       "      <td>eb√®ne, mauritius</td>\n",
       "      <td>full time</td>\n",
       "      <td>entry-level</td>\n",
       "      <td>48k+ *</td>\n",
       "      <td>agile,data management,finance,security,,</td>\n",
       "      <td>,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cricut</td>\n",
       "      <td>machine learning engineer</td>\n",
       "      <td>south jordan, ut, united states</td>\n",
       "      <td>full time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90k+ *</td>\n",
       "      <td>agile,architecture,aws,computer science,comput...</td>\n",
       "      <td>career development,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bosch group</td>\n",
       "      <td>application developer &amp; data analyst</td>\n",
       "      <td>nonantola, italy</td>\n",
       "      <td>full time</td>\n",
       "      <td>entry-level</td>\n",
       "      <td>48k+ *</td>\n",
       "      <td>engineering,industrial,oracle,power bi,r,r&amp;d</td>\n",
       "      <td>,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>publicis groupe</td>\n",
       "      <td>data engineer full time (public sector) usa</td>\n",
       "      <td>arlington, va, united states</td>\n",
       "      <td>full time</td>\n",
       "      <td>mid-level</td>\n",
       "      <td>108k+</td>\n",
       "      <td>aws,azure,computer science,consulting,dataflow...</td>\n",
       "      <td>flex hours,flex vacation,parental leave,unlimi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>servicenow</td>\n",
       "      <td>sr staff data scientist - atg</td>\n",
       "      <td>kirkland, washington, united states</td>\n",
       "      <td>full time</td>\n",
       "      <td>senior-level</td>\n",
       "      <td>184k+</td>\n",
       "      <td>computer science,deep learning,industrial,mach...</td>\n",
       "      <td>401(k) matching,career development,competitive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>natixis in portugal</td>\n",
       "      <td>vendor management and data quality lead</td>\n",
       "      <td>porto, portugal</td>\n",
       "      <td>full time</td>\n",
       "      <td>entry-level</td>\n",
       "      <td>39k+ *</td>\n",
       "      <td>banking,data quality,excel,security,,</td>\n",
       "      <td>gear,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>nielseniq</td>\n",
       "      <td>intern (business intelligence service support)</td>\n",
       "      <td>bangkok, thailand</td>\n",
       "      <td>internship</td>\n",
       "      <td>entry-level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>business intelligence,excel,genetics,,,</td>\n",
       "      <td>,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>western digital</td>\n",
       "      <td>summer 2023 data engineering intern</td>\n",
       "      <td>san jose, ca, united states</td>\n",
       "      <td>internship</td>\n",
       "      <td>entry-level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>big data,computer science,engineering,machine ...</td>\n",
       "      <td>career development,competitive pay,equity,flex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>palo alto networks</td>\n",
       "      <td>principal cloud data engineer (prisma access)</td>\n",
       "      <td>santa clara, ca, united states</td>\n",
       "      <td>full time</td>\n",
       "      <td>senior-level</td>\n",
       "      <td>140k+</td>\n",
       "      <td>agile,apis,aws,azure,big data,computer science</td>\n",
       "      <td>career development,medical leave,salary bonus,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company                                       Job Title  \\\n",
       "0                  sgs                           clinical data analyst   \n",
       "1              ocorian                          aml/cft & data analyst   \n",
       "2               cricut                       machine learning engineer   \n",
       "3          bosch group            application developer & data analyst   \n",
       "4      publicis groupe     data engineer full time (public sector) usa   \n",
       "5           servicenow                   sr staff data scientist - atg   \n",
       "6  natixis in portugal         vendor management and data quality lead   \n",
       "7            nielseniq  intern (business intelligence service support)   \n",
       "8      western digital             summer 2023 data engineering intern   \n",
       "9   palo alto networks   principal cloud data engineer (prisma access)   \n",
       "\n",
       "                              Location    Job Type Experience level   Salary  \\\n",
       "0        richardson, tx, united states   full time      entry-level   48k+ *   \n",
       "1                     eb√®ne, mauritius   full time      entry-level   48k+ *   \n",
       "2      south jordan, ut, united states   full time              NaN   90k+ *   \n",
       "3                     nonantola, italy   full time      entry-level   48k+ *   \n",
       "4         arlington, va, united states   full time        mid-level    108k+   \n",
       "5  kirkland, washington, united states   full time     senior-level    184k+   \n",
       "6                      porto, portugal   full time      entry-level   39k+ *   \n",
       "7                    bangkok, thailand  internship      entry-level      NaN   \n",
       "8          san jose, ca, united states  internship      entry-level      NaN   \n",
       "9       santa clara, ca, united states   full time     senior-level    140k+   \n",
       "\n",
       "                          Requirment of the company   \\\n",
       "0  computer science,data quality,genetics,mathema...   \n",
       "1           agile,data management,finance,security,,   \n",
       "2  agile,architecture,aws,computer science,comput...   \n",
       "3       engineering,industrial,oracle,power bi,r,r&d   \n",
       "4  aws,azure,computer science,consulting,dataflow...   \n",
       "5  computer science,deep learning,industrial,mach...   \n",
       "6              banking,data quality,excel,security,,   \n",
       "7            business intelligence,excel,genetics,,,   \n",
       "8  big data,computer science,engineering,machine ...   \n",
       "9     agile,apis,aws,azure,big data,computer science   \n",
       "\n",
       "                                          Facilities  \n",
       "0                                               ,,,,  \n",
       "1                                               ,,,,  \n",
       "2                             career development,,,,  \n",
       "3                                               ,,,,  \n",
       "4  flex hours,flex vacation,parental leave,unlimi...  \n",
       "5  401(k) matching,career development,competitive...  \n",
       "6                                           gear,,,,  \n",
       "7                                               ,,,,  \n",
       "8  career development,competitive pay,equity,flex...  \n",
       "9  career development,medical leave,salary bonus,...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On essai de afficher les premier lignes de notre data set pour just savoir sa forme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Les valeurs NAN </li>\n",
    "<p> est ce que on peut remplire ces valeur ? ou bien il faut les supprimer</p>\n",
    "<li>list des <strong>facilities</strong></li>\n",
    "<p>une list des que on peut la separer</p>\n",
    "<li>forme de <strong>salary</strong> \"48K+*\" </li>\n",
    "<p>des salaire avec des etoile ,cest quoi la senification de ces etoiles ?, on remarque que on a des salaire sans \"*\"</p>\n",
    "<p>On remarque que les salaire sont on deferente davise il faut les unifier.(eur,¬£,$)</p>\n",
    "\n",
    "<li>les  <strong>job title</strong> on deferente language il faut les unifier on oenlais ou bien en fran√ßais </li>\n",
    "\n",
    "<li>les  <strong>location</strong> on va les deviser par city,state county</li>\n",
    "\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of unique Salary : ['GBP 80K+', 'GBP 65K+', 'GBP 60K+', 'GBP 55K+', 'GBP 55K', 'GBP 54K+', 'GBP 51K+', 'GBP 50K+', 'GBP 45K+', 'GBP 42K+', 'GBP 35K', 'EUR 81K', 'EUR 80K+', 'EUR 60K+', 'EUR 36K+', 'EUR 130K+', ' 99K+', ' 98K+', ' 97K+', ' 96K+ *', ' 96K+', ' 95K+ *', ' 95K+', ' 94K+', ' 93K+', ' 92K+ *', ' 90K+ *', ' 90K+', ' 89K+ *', ' 86K+', ' 85K+', ' 84K+', ' 83K+', ' 82K+', ' 81K+ *', ' 81K+', ' 80K+ *', ' 80K+', ' 79K+', ' 78K+', ' 77K+ *', ' 76K+', ' 75K+ *', ' 75K+', ' 74K+ *', ' 74K+', ' 73K+ *', ' 73K+', ' 72K+', ' 71K+', ' 70K+ *', ' 70K+', ' 69K+ *', ' 68K+', ' 67K+', ' 66K+ *', ' 66K+', ' 65K+ *', ' 65K+', ' 63K+ *', ' 63K+', ' 62K+ *', ' 61K+ *', ' 60K+ *', ' 60K+', ' 59K+ *', ' 59K+', ' 57K+ *', ' 56K+ *', ' 55K+ *', ' 55K+', ' 54K+ *', ' 52K+', ' 51K+ *', ' 51K+', ' 50K+ *', ' 50K+', ' 49K+ *', ' 48K+ *', ' 45K+ *', ' 45K+', ' 44K+ *', ' 43K+', ' 42K+ *', ' 40K+ *', ' 40K+', ' 39K+ *', ' 36K+ *', ' 35K+ *', ' 33K+ *', ' 31K+ *', ' 315K+', ' 310K+', ' 30K+ *', ' 295K+', ' 283K+', ' 267K+', ' 253K+', ' 245K+', ' 236K+', ' 235K+', ' 234K+', ' 230K+', ' 227K+', ' 225K+', ' 224K+', ' 220K+', ' 218K+', ' 214K+', ' 207K+', ' 205K+', ' 204K+', ' 202K+', ' 200K+ *', ' 200K+', ' 199K+', ' 197K+', ' 196K+', ' 195K+', ' 193K+', ' 190K+', ' 189K+', ' 187K+', ' 185K+', ' 184K+ *', ' 184K+', ' 183K+', ' 182K+', ' 180K+', ' 179K+', ' 178K+', ' 177K+', ' 176K+', ' 175K+', ' 174K+', ' 173K+', ' 172K+', ' 171K+', ' 170K+', ' 168K+', ' 167K+', ' 166K+', ' 165K+', ' 164K+', ' 163K+', ' 161K+', ' 160K+', ' 159K+', ' 158K+', ' 157K+', ' 156K+', ' 155K+ *', ' 155K+', ' 154K+', ' 153K+', ' 152K+', ' 151K+', ' 150K+', ' 149K+', ' 148K+', ' 147K+', ' 146K+', ' 145K+', ' 144K+ *', ' 144K+', ' 143K+', ' 142K+', ' 141K+ *', ' 141K+', ' 140K+', ' 139K+', ' 138K+', ' 136K+', ' 135K+ *', ' 135K+', ' 134K+', ' 133K+', ' 132K+', ' 131K+ *', ' 131K+', ' 130K+', ' 129K+ *', ' 129K+', ' 128K+', ' 127K+', ' 126K+', ' 125K+', ' 124K+', ' 123K+', ' 122K+ *', ' 122K+', ' 121K+', ' 120K+ *', ' 120K+', ' 119K+', ' 117K+', ' 116K+', ' 115K+ *', ' 115K+', ' 113K+', ' 112K+', ' 111K+', ' 110K+ *', ' 110K+', ' 109K+ *', ' 109K+', ' 108K+', ' 107K+', ' 106K+', ' 105K+ *', ' 105K+', ' 104K+', ' 103K+ *', ' 103K+', ' 102K+ *', ' 102K+', ' 100K+ *', ' 100K+', nan]\n"
     ]
    }
   ],
   "source": [
    "print(\"list of unique Salary :\",dataFrame[\"Salary\"].sort_values(ascending=False).unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1246    GBP 80K+\n",
       "2536    GBP 65K+\n",
       "1384    GBP 60K+\n",
       "2492    GBP 55K+\n",
       "2716     GBP 55K\n",
       "          ...   \n",
       "3126         NaN\n",
       "3134         NaN\n",
       "3152         NaN\n",
       "3159         NaN\n",
       "3166         NaN\n",
       "Name: Salary, Length: 3198, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.Salary.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows : 3198\n"
     ]
    }
   ],
   "source": [
    "print(\"number of rows :\",dataFrame.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of columns : 8 : Index(['Company', 'Job Title', 'Location', 'Job Type', 'Experience level',\n",
      "       'Salary', 'Requirment of the company ', 'Facilities'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"number of columns :\",str(dataFrame.shape[1])+\" : \"+ str(dataFrame.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3198 entries, 0 to 3197\n",
      "Data columns (total 8 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   Company                     3197 non-null   object\n",
      " 1   Job Title                   3197 non-null   object\n",
      " 2   Location                    3197 non-null   object\n",
      " 3   Job Type                    3197 non-null   object\n",
      " 4   Experience level            2962 non-null   object\n",
      " 5   Salary                      3009 non-null   object\n",
      " 6   Requirment of the company   3198 non-null   object\n",
      " 7   Facilities                  3198 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 200.0+ KB\n"
     ]
    }
   ],
   "source": [
    "dataFrame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3197</td>\n",
       "      <td>3197</td>\n",
       "      <td>3197</td>\n",
       "      <td>3197</td>\n",
       "      <td>2962</td>\n",
       "      <td>3009</td>\n",
       "      <td>3198</td>\n",
       "      <td>3198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1106</td>\n",
       "      <td>2138</td>\n",
       "      <td>1117</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>218</td>\n",
       "      <td>2600</td>\n",
       "      <td>777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Publicis Groupe</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Bengaluru, India</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>115K+ *</td>\n",
       "      <td>Big Data,Business Intelligence,Data analysis,E...</td>\n",
       "      <td>,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>126</td>\n",
       "      <td>105</td>\n",
       "      <td>90</td>\n",
       "      <td>3116</td>\n",
       "      <td>1876</td>\n",
       "      <td>253</td>\n",
       "      <td>12</td>\n",
       "      <td>542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company      Job Title          Location   Job Type  \\\n",
       "count              3197           3197              3197       3197   \n",
       "unique             1106           2138              1117          3   \n",
       "top     Publicis Groupe  Data Engineer  Bengaluru, India  Full Time   \n",
       "freq                126            105                90       3116   \n",
       "\n",
       "       Experience level    Salary  \\\n",
       "count              2962      3009   \n",
       "unique                4       218   \n",
       "top        Senior-level   115K+ *   \n",
       "freq               1876       253   \n",
       "\n",
       "                               Requirment of the company  Facilities  \n",
       "count                                                3198       3198  \n",
       "unique                                               2600        777  \n",
       "top     Big Data,Business Intelligence,Data analysis,E...       ,,,,  \n",
       "freq                                                   12        542  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of unique Job types : ['Full Time' 'Internship' 'Part Time' nan]\n"
     ]
    }
   ],
   "source": [
    "print(\"list of unique Job types :\",dataFrame[\"Job Type\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of unique Job Title : ['Clinical Data Analyst' 'AML/CFT & Data Analyst'\n",
      " 'Machine Learning Engineer' ...\n",
      " 'Application Integration Engineer, Computer Vision Program'\n",
      " 'Senior Software Engineer, Machine Learning - Ads Intelligence'\n",
      " 'Data Scientist - New College Graduate']\n"
     ]
    }
   ],
   "source": [
    "print(\"list of unique Job Title :\",dataFrame[\"Job Title\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of unique Experience level\t : ['Entry-level' nan 'Mid-level' 'Senior-level' 'Executive-level']\n"
     ]
    }
   ],
   "source": [
    "print(\"list of unique Experience level\t :\",dataFrame[\"Experience level\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company                         1\n",
       "Job Title                       1\n",
       "Location                        1\n",
       "Job Type                        1\n",
       "Experience level              228\n",
       "Salary                        172\n",
       "Requirment of the company       0\n",
       "Facilities                      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Salary column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame[\"Salary\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       48K+ *\n",
       "1       48K+ *\n",
       "2       90K+ *\n",
       "3       48K+ *\n",
       "4        108K+\n",
       "         ...  \n",
       "3190     113K+\n",
       "3191     106K+\n",
       "3192     176K+\n",
       "3193    39K+ *\n",
       "3196    39K+ *\n",
       "Name: Salary, Length: 2996, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame[\"Salary\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>bunq</td>\n",
       "      <td>Data Science Intern - Large Language Models</td>\n",
       "      <td>Amsterdam, Noord-Holland, Netherlands</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Engineering,FinTech,LLMs,NLP,,</td>\n",
       "      <td>Career development,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>bunq</td>\n",
       "      <td>Data Science Intern - Large Language Model</td>\n",
       "      <td>Amsterdam, Noord-Holland, Netherlands</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Engineering,FinTech,LLMs,NLP,,</td>\n",
       "      <td>Career development,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>Definitive Logic</td>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Big Data,Consulting,Consulting firm,Data analy...</td>\n",
       "      <td>Career development,Competitive pay,Flex hours,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>Cube RM</td>\n",
       "      <td>Business Data Analyst Intern</td>\n",
       "      <td>Athens, Attica, Greece</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Agile,Azure,Computer Science,Data analysis,Exc...</td>\n",
       "      <td>Career development,Flex hours,Flex vacation,Ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NielsenIQ</td>\n",
       "      <td>Intern (Business Intelligence Service Support)</td>\n",
       "      <td>Bangkok, Thailand</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business Intelligence,Excel,Genetics,,,</td>\n",
       "      <td>,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>Dentons</td>\n",
       "      <td>Marketing Data Analyst Intern</td>\n",
       "      <td>Warsaw, Masovian Voivodeship, Poland</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data analysis,Excel,,,,</td>\n",
       "      <td>,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>DNSFilter</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Washington, District of Columbia, United State...</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Mid-level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWS,Computer Science,Data analysis,Data visual...</td>\n",
       "      <td>Career development,Flex hours,Flex vacation,He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>REWE International Dienstleistungsgesellschaft...</td>\n",
       "      <td>Junior Data Science Engineer (m/w/x)</td>\n",
       "      <td>Wien, Austria</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CI/CD,Computer Science,Data pipelines,Deep Lea...</td>\n",
       "      <td>,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>Opera</td>\n",
       "      <td>Data Scientist Summer Intern</td>\n",
       "      <td>Wroclaw, PL</td>\n",
       "      <td>Part Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Computer Science,Data analysis,Data visualizat...</td>\n",
       "      <td>Startup environment,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>,,,,,</td>\n",
       "      <td>,,,,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Company  \\\n",
       "669                                                bunq   \n",
       "973                                                bunq   \n",
       "3073                                   Definitive Logic   \n",
       "1525                                            Cube RM   \n",
       "7                                             NielsenIQ   \n",
       "...                                                 ...   \n",
       "1669                                            Dentons   \n",
       "3166                                          DNSFilter   \n",
       "44    REWE International Dienstleistungsgesellschaft...   \n",
       "1954                                              Opera   \n",
       "797                                                 NaN   \n",
       "\n",
       "                                           Job Title  \\\n",
       "669      Data Science Intern - Large Language Models   \n",
       "973       Data Science Intern - Large Language Model   \n",
       "3073                             Data Science Intern   \n",
       "1525                    Business Data Analyst Intern   \n",
       "7     Intern (Business Intelligence Service Support)   \n",
       "...                                              ...   \n",
       "1669                   Marketing Data Analyst Intern   \n",
       "3166                           Senior Data Scientist   \n",
       "44              Junior Data Science Engineer (m/w/x)   \n",
       "1954                    Data Scientist Summer Intern   \n",
       "797                                              NaN   \n",
       "\n",
       "                                               Location    Job Type  \\\n",
       "669               Amsterdam, Noord-Holland, Netherlands  Internship   \n",
       "973               Amsterdam, Noord-Holland, Netherlands  Internship   \n",
       "3073                                      Arlington, VA  Internship   \n",
       "1525                             Athens, Attica, Greece  Internship   \n",
       "7                                     Bangkok, Thailand  Internship   \n",
       "...                                                 ...         ...   \n",
       "1669               Warsaw, Masovian Voivodeship, Poland  Internship   \n",
       "3166  Washington, District of Columbia, United State...   Full Time   \n",
       "44                                        Wien, Austria   Full Time   \n",
       "1954                                        Wroclaw, PL   Part Time   \n",
       "797                                                 NaN         NaN   \n",
       "\n",
       "     Experience level Salary  \\\n",
       "669       Entry-level    NaN   \n",
       "973       Entry-level    NaN   \n",
       "3073      Entry-level    NaN   \n",
       "1525      Entry-level    NaN   \n",
       "7         Entry-level    NaN   \n",
       "...               ...    ...   \n",
       "1669      Entry-level    NaN   \n",
       "3166        Mid-level    NaN   \n",
       "44        Entry-level    NaN   \n",
       "1954      Entry-level    NaN   \n",
       "797               NaN    NaN   \n",
       "\n",
       "                             Requirment of the company   \\\n",
       "669                      Engineering,FinTech,LLMs,NLP,,   \n",
       "973                      Engineering,FinTech,LLMs,NLP,,   \n",
       "3073  Big Data,Consulting,Consulting firm,Data analy...   \n",
       "1525  Agile,Azure,Computer Science,Data analysis,Exc...   \n",
       "7               Business Intelligence,Excel,Genetics,,,   \n",
       "...                                                 ...   \n",
       "1669                            Data analysis,Excel,,,,   \n",
       "3166  AWS,Computer Science,Data analysis,Data visual...   \n",
       "44    CI/CD,Computer Science,Data pipelines,Deep Lea...   \n",
       "1954  Computer Science,Data analysis,Data visualizat...   \n",
       "797                                               ,,,,,   \n",
       "\n",
       "                                             Facilities  \n",
       "669                              Career development,,,,  \n",
       "973                              Career development,,,,  \n",
       "3073  Career development,Competitive pay,Flex hours,...  \n",
       "1525  Career development,Flex hours,Flex vacation,Ge...  \n",
       "7                                                  ,,,,  \n",
       "...                                                 ...  \n",
       "1669                                               ,,,,  \n",
       "3166  Career development,Flex hours,Flex vacation,He...  \n",
       "44                                                 ,,,,  \n",
       "1954                            Startup environment,,,,  \n",
       "797                                                ,,,,  \n",
       "\n",
       "[172 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame[dataFrame[\"Salary\"].isna()].sort_values('Location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame.dropna(thresh=3,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NielsenIQ</td>\n",
       "      <td>Intern (Business Intelligence Service Support)</td>\n",
       "      <td>Bangkok, Thailand</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Business Intelligence,Excel,Genetics,,,</td>\n",
       "      <td>,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Western Digital</td>\n",
       "      <td>Summer 2023 Data Engineering Intern</td>\n",
       "      <td>San Jose, CA, United States</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Big Data,Computer Science,Engineering,Machine ...</td>\n",
       "      <td>Career development,Competitive pay,Equity,Flex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Angi</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Indianapolis, IN - Hybrid</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Big Data,Data Mining,Machine Learning,Mathemat...</td>\n",
       "      <td>401(k) matching,Career development,Competitive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>REWE International Dienstleistungsgesellschaft...</td>\n",
       "      <td>Junior Data Science Engineer (m/w/x)</td>\n",
       "      <td>Wien, Austria</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CI/CD,Computer Science,Data pipelines,Deep Lea...</td>\n",
       "      <td>,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Metiora</td>\n",
       "      <td>Data Analyst Intern</td>\n",
       "      <td>Madrid, Spain</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Matplotlib,MongoDB,NumPy,Pandas,Power BI,Python</td>\n",
       "      <td>,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3109</th>\n",
       "      <td>METRO/MAKRO</td>\n",
       "      <td>STAGE 6 mois - Data Scientist Junior H/F</td>\n",
       "      <td>Nanterre, France</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Big Data,Power BI,Python,R,SQL,</td>\n",
       "      <td>,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134</th>\n",
       "      <td>Junglee Games</td>\n",
       "      <td>ETL and Data Warehouse Testing Intern</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Computer Science,Data quality,Data warehouse,E...</td>\n",
       "      <td>,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152</th>\n",
       "      <td>Lely</td>\n",
       "      <td>Stage: Computer Science, Robotics, Computer Vi...</td>\n",
       "      <td>Maassluis, Netherlands</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Computer Science,Computer Vision,Engineering,O...</td>\n",
       "      <td>,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159</th>\n",
       "      <td>Deezer</td>\n",
       "      <td>Data Analyst Intern m/f/d - Business</td>\n",
       "      <td>Paris, France</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Data analysis,Data pipelines,Data visualizatio...</td>\n",
       "      <td>Career development,Health care,Insurance,Start...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>DNSFilter</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Washington, District of Columbia, United State...</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Mid-level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWS,Computer Science,Data analysis,Data visual...</td>\n",
       "      <td>Career development,Flex hours,Flex vacation,He...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Company  \\\n",
       "7                                             NielsenIQ   \n",
       "8                                       Western Digital   \n",
       "39                                                 Angi   \n",
       "44    REWE International Dienstleistungsgesellschaft...   \n",
       "75                                              Metiora   \n",
       "...                                                 ...   \n",
       "3109                                        METRO/MAKRO   \n",
       "3134                                      Junglee Games   \n",
       "3152                                               Lely   \n",
       "3159                                             Deezer   \n",
       "3166                                          DNSFilter   \n",
       "\n",
       "                                              Job Title  \\\n",
       "7        Intern (Business Intelligence Service Support)   \n",
       "8                   Summer 2023 Data Engineering Intern   \n",
       "39                                Senior Data Scientist   \n",
       "44                 Junior Data Science Engineer (m/w/x)   \n",
       "75                                  Data Analyst Intern   \n",
       "...                                                 ...   \n",
       "3109           STAGE 6 mois - Data Scientist Junior H/F   \n",
       "3134              ETL and Data Warehouse Testing Intern   \n",
       "3152  Stage: Computer Science, Robotics, Computer Vi...   \n",
       "3159               Data Analyst Intern m/f/d - Business   \n",
       "3166                              Senior Data Scientist   \n",
       "\n",
       "                                               Location    Job Type  \\\n",
       "7                                     Bangkok, Thailand  Internship   \n",
       "8                           San Jose, CA, United States  Internship   \n",
       "39                            Indianapolis, IN - Hybrid   Full Time   \n",
       "44                                        Wien, Austria   Full Time   \n",
       "75                                        Madrid, Spain   Full Time   \n",
       "...                                                 ...         ...   \n",
       "3109                                   Nanterre, France   Full Time   \n",
       "3134                        Bengaluru, Karnataka, India  Internship   \n",
       "3152                             Maassluis, Netherlands   Full Time   \n",
       "3159                                      Paris, France  Internship   \n",
       "3166  Washington, District of Columbia, United State...   Full Time   \n",
       "\n",
       "     Experience level Salary  \\\n",
       "7         Entry-level    NaN   \n",
       "8         Entry-level    NaN   \n",
       "39       Senior-level    NaN   \n",
       "44        Entry-level    NaN   \n",
       "75        Entry-level    NaN   \n",
       "...               ...    ...   \n",
       "3109      Entry-level    NaN   \n",
       "3134      Entry-level    NaN   \n",
       "3152      Entry-level    NaN   \n",
       "3159      Entry-level    NaN   \n",
       "3166        Mid-level    NaN   \n",
       "\n",
       "                             Requirment of the company   \\\n",
       "7               Business Intelligence,Excel,Genetics,,,   \n",
       "8     Big Data,Computer Science,Engineering,Machine ...   \n",
       "39    Big Data,Data Mining,Machine Learning,Mathemat...   \n",
       "44    CI/CD,Computer Science,Data pipelines,Deep Lea...   \n",
       "75      Matplotlib,MongoDB,NumPy,Pandas,Power BI,Python   \n",
       "...                                                 ...   \n",
       "3109                    Big Data,Power BI,Python,R,SQL,   \n",
       "3134  Computer Science,Data quality,Data warehouse,E...   \n",
       "3152  Computer Science,Computer Vision,Engineering,O...   \n",
       "3159  Data analysis,Data pipelines,Data visualizatio...   \n",
       "3166  AWS,Computer Science,Data analysis,Data visual...   \n",
       "\n",
       "                                             Facilities  \n",
       "7                                                  ,,,,  \n",
       "8     Career development,Competitive pay,Equity,Flex...  \n",
       "39    401(k) matching,Career development,Competitive...  \n",
       "44                                                 ,,,,  \n",
       "75                                                 ,,,,  \n",
       "...                                                 ...  \n",
       "3109                                               ,,,,  \n",
       "3134                                               ,,,,  \n",
       "3152                                               ,,,,  \n",
       "3159  Career development,Health care,Insurance,Start...  \n",
       "3166  Career development,Flex hours,Flex vacation,He...  \n",
       "\n",
       "[171 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame[dataFrame[\"Salary\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame[\"Salary\"].fillna('negociable',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGS</td>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Richardson, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48K+ *</td>\n",
       "      <td>Computer Science,Data quality,Genetics,Mathema...</td>\n",
       "      <td>,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ocorian</td>\n",
       "      <td>AML/CFT &amp; Data Analyst</td>\n",
       "      <td>Eb√®ne, Mauritius</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48K+ *</td>\n",
       "      <td>Agile,Data management,Finance,Security,,</td>\n",
       "      <td>,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bosch Group</td>\n",
       "      <td>Application Developer &amp; Data Analyst</td>\n",
       "      <td>Nonantola, Italy</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48K+ *</td>\n",
       "      <td>Engineering,Industrial,Oracle,Power BI,R,R&amp;D</td>\n",
       "      <td>,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Natixis in Portugal</td>\n",
       "      <td>Vendor Management and Data Quality Lead</td>\n",
       "      <td>Porto, Portugal</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>39K+ *</td>\n",
       "      <td>Banking,Data quality,Excel,Security,,</td>\n",
       "      <td>Gear,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NielsenIQ</td>\n",
       "      <td>Intern (Business Intelligence Service Support)</td>\n",
       "      <td>Bangkok, Thailand</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>negociable</td>\n",
       "      <td>Business Intelligence,Excel,Genetics,,,</td>\n",
       "      <td>,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>Rackspace</td>\n",
       "      <td>Trainee Data Engineer - R-16792</td>\n",
       "      <td>India - Remote</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>59K+ *</td>\n",
       "      <td>Architecture,Azure,Big Data,Computer Science,D...</td>\n",
       "      <td>Team events,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3170</th>\n",
       "      <td>Wise</td>\n",
       "      <td>Data Analytics Manager - Compliance, Risk &amp; In...</td>\n",
       "      <td>London</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>120K+ *</td>\n",
       "      <td>Airflow,APIs,Data Analytics,Data pipelines,Dat...</td>\n",
       "      <td>,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3176</th>\n",
       "      <td>iTech Media</td>\n",
       "      <td>Data Analytics Engineer</td>\n",
       "      <td>Warsaw Remote</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>30K+ *</td>\n",
       "      <td>Airflow,Data Analytics,Engineering,Finance,Kaf...</td>\n",
       "      <td>Career development,Flex hours,Flex vacation,He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>Western Digital</td>\n",
       "      <td>Data Scientist - New College Graduate</td>\n",
       "      <td>Bi√±an, Philippines</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>39K+ *</td>\n",
       "      <td>APIs,Clustering,Computer Science,Data visualiz...</td>\n",
       "      <td>Career development,,,,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>ATB Financial</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Edmonton, Alberta, Canada</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>39K+ *</td>\n",
       "      <td>Computer Science,Data Analytics,Data Mining,Ec...</td>\n",
       "      <td>Career development,Startup environment,,,</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>462 rows √ó 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Company                                          Job Title  \\\n",
       "0                     SGS                              Clinical Data Analyst   \n",
       "1                 Ocorian                             AML/CFT & Data Analyst   \n",
       "3             Bosch Group               Application Developer & Data Analyst   \n",
       "6     Natixis in Portugal            Vendor Management and Data Quality Lead   \n",
       "7               NielsenIQ     Intern (Business Intelligence Service Support)   \n",
       "...                   ...                                                ...   \n",
       "3164            Rackspace                    Trainee Data Engineer - R-16792   \n",
       "3170                 Wise  Data Analytics Manager - Compliance, Risk & In...   \n",
       "3176          iTech Media                            Data Analytics Engineer   \n",
       "3193      Western Digital              Data Scientist - New College Graduate   \n",
       "3196        ATB Financial                                     Data Scientist   \n",
       "\n",
       "                           Location    Job Type Experience level      Salary  \\\n",
       "0     Richardson, TX, United States   Full Time      Entry-level      48K+ *   \n",
       "1                  Eb√®ne, Mauritius   Full Time      Entry-level      48K+ *   \n",
       "3                  Nonantola, Italy   Full Time      Entry-level      48K+ *   \n",
       "6                   Porto, Portugal   Full Time      Entry-level      39K+ *   \n",
       "7                 Bangkok, Thailand  Internship      Entry-level  negociable   \n",
       "...                             ...         ...              ...         ...   \n",
       "3164                 India - Remote   Full Time      Entry-level      59K+ *   \n",
       "3170                         London   Full Time      Entry-level     120K+ *   \n",
       "3176                  Warsaw Remote   Full Time      Entry-level      30K+ *   \n",
       "3193             Bi√±an, Philippines   Full Time      Entry-level      39K+ *   \n",
       "3196      Edmonton, Alberta, Canada   Full Time      Entry-level      39K+ *   \n",
       "\n",
       "                             Requirment of the company   \\\n",
       "0     Computer Science,Data quality,Genetics,Mathema...   \n",
       "1              Agile,Data management,Finance,Security,,   \n",
       "3          Engineering,Industrial,Oracle,Power BI,R,R&D   \n",
       "6                 Banking,Data quality,Excel,Security,,   \n",
       "7               Business Intelligence,Excel,Genetics,,,   \n",
       "...                                                 ...   \n",
       "3164  Architecture,Azure,Big Data,Computer Science,D...   \n",
       "3170  Airflow,APIs,Data Analytics,Data pipelines,Dat...   \n",
       "3176  Airflow,Data Analytics,Engineering,Finance,Kaf...   \n",
       "3193  APIs,Clustering,Computer Science,Data visualiz...   \n",
       "3196  Computer Science,Data Analytics,Data Mining,Ec...   \n",
       "\n",
       "                                             Facilities  \n",
       "0                                                  ,,,,  \n",
       "1                                                  ,,,,  \n",
       "3                                                  ,,,,  \n",
       "6                                              Gear,,,,  \n",
       "7                                                  ,,,,  \n",
       "...                                                 ...  \n",
       "3164                                    Team events,,,,  \n",
       "3170                                               ,,,,  \n",
       "3176  Career development,Flex hours,Flex vacation,He...  \n",
       "3193                             Career development,,,,  \n",
       "3196          Career development,Startup environment,,,  \n",
       "\n",
       "[462 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame[dataFrame[\"Experience level\"]==\"Entry-level\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pour les valeurs nan on salaire on va les remplacer par \"negociable\" pour le moment \n",
    "#return\n",
    "# dataFrame[\"Salary\"].replace(['negociable'],'',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajout  autre colonne de bonuses (primes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame[['Salary', 'Plus']] = dataFrame[\"Salary\"].apply(lambda x: pd.Series(str(x).split(\"+\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame[\"Plus\"].fillna('no bonuses',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonuses est une colonnes qui sinifier les primes (*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Plus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Company, Job Title, Location, Job Type, Experience level, Salary, Requirment of the company , Facilities, Plus]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame[dataFrame[\"Salary\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajout  autre colonne des devises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame[['Currency','Salary']] = dataFrame[\"Salary\"][dataFrame[\"Salary\"]!=\"negociable\"].apply(lambda x: pd.Series(str(x).split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# les salaire avec des valeurs vides sont on dollar:\n",
    "# dataFrame['Currency']=dataFrame['Currency'][dataFrame['Salary']=='negociable'].replace('negociable','USD',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Plus</th>\n",
       "      <th>Currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>Bosch Group</td>\n",
       "      <td>Master Data Management Plants (f/m/div.) (sala...</td>\n",
       "      <td>Karlsruhe, Germany</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>81K</td>\n",
       "      <td>Agile,Computer Science,Data analysis,Data mana...</td>\n",
       "      <td>Career development,Competitive pay,Salary bonus,,</td>\n",
       "      <td>no bonuses</td>\n",
       "      <td>EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Sr. Staff Machine Learning Engineer</td>\n",
       "      <td>Remote Germany</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>130K</td>\n",
       "      <td>Architecture,AWS,Azure,Big Data,Computer Scien...</td>\n",
       "      <td>Career development,Flex vacation,Health care,H...</td>\n",
       "      <td></td>\n",
       "      <td>EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Staff Product Manager, Machine Learning and Re...</td>\n",
       "      <td>Remote Germany</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>80K</td>\n",
       "      <td>Agile,Computer Science,Data management,Enginee...</td>\n",
       "      <td>Career development,Flex vacation,Health care,H...</td>\n",
       "      <td></td>\n",
       "      <td>EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>Metiora</td>\n",
       "      <td>Data Scientist Senior</td>\n",
       "      <td>Madrid, Spain</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>36K</td>\n",
       "      <td>Deep Learning,Machine Learning,Matplotlib,Mong...</td>\n",
       "      <td>,,,,</td>\n",
       "      <td></td>\n",
       "      <td>EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>CybelAngel</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Paris, √éle-de-France, France - Remote</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Mid-level</td>\n",
       "      <td>60K</td>\n",
       "      <td>Airflow,BigQuery,Bigtable,Data analysis,Data g...</td>\n",
       "      <td>Career development,Equity,Salary bonus,,</td>\n",
       "      <td></td>\n",
       "      <td>EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>Evolution</td>\n",
       "      <td>Software Developer in Data Science Team</td>\n",
       "      <td>Riga, Latvia</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>36K</td>\n",
       "      <td>Agile,AWS,Big Data,Classification,Clustering,C...</td>\n",
       "      <td>Career development,Competitive pay,Health care...</td>\n",
       "      <td></td>\n",
       "      <td>EUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>CITECH</td>\n",
       "      <td>Ing√©nieur Data / Power BI (H/F)</td>\n",
       "      <td>Dijon, France</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>60K</td>\n",
       "      <td>Azure,Data Analytics,KPIs,PostgreSQL,Power BI,...</td>\n",
       "      <td>,,,,</td>\n",
       "      <td></td>\n",
       "      <td>EUR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Company                                          Job Title  \\\n",
       "324   Bosch Group  Master Data Management Plants (f/m/div.) (sala...   \n",
       "456       Mozilla                Sr. Staff Machine Learning Engineer   \n",
       "1057      Mozilla  Staff Product Manager, Machine Learning and Re...   \n",
       "1100      Metiora                              Data Scientist Senior   \n",
       "1117   CybelAngel                               Senior Data Engineer   \n",
       "1280    Evolution            Software Developer in Data Science Team   \n",
       "1467       CITECH                    Ing√©nieur Data / Power BI (H/F)   \n",
       "\n",
       "                                   Location   Job Type Experience level  \\\n",
       "324                      Karlsruhe, Germany  Full Time      Entry-level   \n",
       "456                          Remote Germany  Full Time     Senior-level   \n",
       "1057                         Remote Germany  Full Time     Senior-level   \n",
       "1100                          Madrid, Spain  Full Time     Senior-level   \n",
       "1117  Paris, √éle-de-France, France - Remote  Full Time        Mid-level   \n",
       "1280                           Riga, Latvia  Full Time     Senior-level   \n",
       "1467                          Dijon, France  Full Time     Senior-level   \n",
       "\n",
       "     Salary                         Requirment of the company   \\\n",
       "324     81K  Agile,Computer Science,Data analysis,Data mana...   \n",
       "456    130K  Architecture,AWS,Azure,Big Data,Computer Scien...   \n",
       "1057    80K  Agile,Computer Science,Data management,Enginee...   \n",
       "1100    36K  Deep Learning,Machine Learning,Matplotlib,Mong...   \n",
       "1117    60K  Airflow,BigQuery,Bigtable,Data analysis,Data g...   \n",
       "1280    36K  Agile,AWS,Big Data,Classification,Clustering,C...   \n",
       "1467    60K  Azure,Data Analytics,KPIs,PostgreSQL,Power BI,...   \n",
       "\n",
       "                                             Facilities        Plus Currency  \n",
       "324   Career development,Competitive pay,Salary bonus,,  no bonuses      EUR  \n",
       "456   Career development,Flex vacation,Health care,H...                  EUR  \n",
       "1057  Career development,Flex vacation,Health care,H...                  EUR  \n",
       "1100                                               ,,,,                  EUR  \n",
       "1117           Career development,Equity,Salary bonus,,                  EUR  \n",
       "1280  Career development,Competitive pay,Health care...                  EUR  \n",
       "1467                                               ,,,,                  EUR  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pour les valeurs nan on salaire on va les remplacer par \"negociable\" pour le moment \n",
    "dataFrame[dataFrame[\"Currency\"]== \"EUR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame['Currency'].replace('','USD',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame['Currency'][dataFrame['Salary'].isna()]=dataFrame['Currency'].str.replace('nan','--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame['Plus'].replace('','no bonuses',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame['Plus'].replace(' *','bonuses',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame['Plus'] = dataFrame['Plus'].map({'bonuses': True, 'no bonuses': False})      # Replace string by boolean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of unique Currency : ['USD', 'EUR', 'GBP']\n"
     ]
    }
   ],
   "source": [
    "print(\"list of unique Currency :\",dataFrame[\"Currency\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Plus</th>\n",
       "      <th>Currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Company, Job Title, Location, Job Type, Experience level, Salary, Requirment of the company , Facilities, Plus, Currency]\n",
       "Index: []"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame[dataFrame['Currency'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame['Currency'].fillna('--',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame['Salary'] = dataFrame['Salary'].str.replace('K', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change tonumerique\n",
    "dataFrame[\"Salary\"]=pd.to_numeric(dataFrame['Salary'], errors='coerce')*1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame[\"Salary\"].fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Plus</th>\n",
       "      <th>Currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NielsenIQ</td>\n",
       "      <td>Intern (Business Intelligence Service Support)</td>\n",
       "      <td>Bangkok, Thailand</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Business Intelligence,Excel,Genetics,,,</td>\n",
       "      <td>,,,,</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Western Digital</td>\n",
       "      <td>Summer 2023 Data Engineering Intern</td>\n",
       "      <td>San Jose, CA, United States</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Big Data,Computer Science,Engineering,Machine ...</td>\n",
       "      <td>Career development,Competitive pay,Equity,Flex...</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Angi</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Indianapolis, IN - Hybrid</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Big Data,Data Mining,Machine Learning,Mathemat...</td>\n",
       "      <td>401(k) matching,Career development,Competitive...</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>REWE International Dienstleistungsgesellschaft...</td>\n",
       "      <td>Junior Data Science Engineer (m/w/x)</td>\n",
       "      <td>Wien, Austria</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CI/CD,Computer Science,Data pipelines,Deep Lea...</td>\n",
       "      <td>,,,,</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Metiora</td>\n",
       "      <td>Data Analyst Intern</td>\n",
       "      <td>Madrid, Spain</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Matplotlib,MongoDB,NumPy,Pandas,Power BI,Python</td>\n",
       "      <td>,,,,</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3109</th>\n",
       "      <td>METRO/MAKRO</td>\n",
       "      <td>STAGE 6 mois - Data Scientist Junior H/F</td>\n",
       "      <td>Nanterre, France</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Big Data,Power BI,Python,R,SQL,</td>\n",
       "      <td>,,,,</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134</th>\n",
       "      <td>Junglee Games</td>\n",
       "      <td>ETL and Data Warehouse Testing Intern</td>\n",
       "      <td>Bengaluru, Karnataka, India</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Computer Science,Data quality,Data warehouse,E...</td>\n",
       "      <td>,,,,</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152</th>\n",
       "      <td>Lely</td>\n",
       "      <td>Stage: Computer Science, Robotics, Computer Vi...</td>\n",
       "      <td>Maassluis, Netherlands</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Computer Science,Computer Vision,Engineering,O...</td>\n",
       "      <td>,,,,</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3159</th>\n",
       "      <td>Deezer</td>\n",
       "      <td>Data Analyst Intern m/f/d - Business</td>\n",
       "      <td>Paris, France</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Data analysis,Data pipelines,Data visualizatio...</td>\n",
       "      <td>Career development,Health care,Insurance,Start...</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>DNSFilter</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Washington, District of Columbia, United State...</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Mid-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AWS,Computer Science,Data analysis,Data visual...</td>\n",
       "      <td>Career development,Flex hours,Flex vacation,He...</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Company  \\\n",
       "7                                             NielsenIQ   \n",
       "8                                       Western Digital   \n",
       "39                                                 Angi   \n",
       "44    REWE International Dienstleistungsgesellschaft...   \n",
       "75                                              Metiora   \n",
       "...                                                 ...   \n",
       "3109                                        METRO/MAKRO   \n",
       "3134                                      Junglee Games   \n",
       "3152                                               Lely   \n",
       "3159                                             Deezer   \n",
       "3166                                          DNSFilter   \n",
       "\n",
       "                                              Job Title  \\\n",
       "7        Intern (Business Intelligence Service Support)   \n",
       "8                   Summer 2023 Data Engineering Intern   \n",
       "39                                Senior Data Scientist   \n",
       "44                 Junior Data Science Engineer (m/w/x)   \n",
       "75                                  Data Analyst Intern   \n",
       "...                                                 ...   \n",
       "3109           STAGE 6 mois - Data Scientist Junior H/F   \n",
       "3134              ETL and Data Warehouse Testing Intern   \n",
       "3152  Stage: Computer Science, Robotics, Computer Vi...   \n",
       "3159               Data Analyst Intern m/f/d - Business   \n",
       "3166                              Senior Data Scientist   \n",
       "\n",
       "                                               Location    Job Type  \\\n",
       "7                                     Bangkok, Thailand  Internship   \n",
       "8                           San Jose, CA, United States  Internship   \n",
       "39                            Indianapolis, IN - Hybrid   Full Time   \n",
       "44                                        Wien, Austria   Full Time   \n",
       "75                                        Madrid, Spain   Full Time   \n",
       "...                                                 ...         ...   \n",
       "3109                                   Nanterre, France   Full Time   \n",
       "3134                        Bengaluru, Karnataka, India  Internship   \n",
       "3152                             Maassluis, Netherlands   Full Time   \n",
       "3159                                      Paris, France  Internship   \n",
       "3166  Washington, District of Columbia, United State...   Full Time   \n",
       "\n",
       "     Experience level  Salary  \\\n",
       "7         Entry-level     0.0   \n",
       "8         Entry-level     0.0   \n",
       "39       Senior-level     0.0   \n",
       "44        Entry-level     0.0   \n",
       "75        Entry-level     0.0   \n",
       "...               ...     ...   \n",
       "3109      Entry-level     0.0   \n",
       "3134      Entry-level     0.0   \n",
       "3152      Entry-level     0.0   \n",
       "3159      Entry-level     0.0   \n",
       "3166        Mid-level     0.0   \n",
       "\n",
       "                             Requirment of the company   \\\n",
       "7               Business Intelligence,Excel,Genetics,,,   \n",
       "8     Big Data,Computer Science,Engineering,Machine ...   \n",
       "39    Big Data,Data Mining,Machine Learning,Mathemat...   \n",
       "44    CI/CD,Computer Science,Data pipelines,Deep Lea...   \n",
       "75      Matplotlib,MongoDB,NumPy,Pandas,Power BI,Python   \n",
       "...                                                 ...   \n",
       "3109                    Big Data,Power BI,Python,R,SQL,   \n",
       "3134  Computer Science,Data quality,Data warehouse,E...   \n",
       "3152  Computer Science,Computer Vision,Engineering,O...   \n",
       "3159  Data analysis,Data pipelines,Data visualizatio...   \n",
       "3166  AWS,Computer Science,Data analysis,Data visual...   \n",
       "\n",
       "                                             Facilities   Plus Currency  \n",
       "7                                                  ,,,,  False      USD  \n",
       "8     Career development,Competitive pay,Equity,Flex...  False      USD  \n",
       "39    401(k) matching,Career development,Competitive...  False      USD  \n",
       "44                                                 ,,,,  False      USD  \n",
       "75                                                 ,,,,  False      USD  \n",
       "...                                                 ...    ...      ...  \n",
       "3109                                               ,,,,  False      USD  \n",
       "3134                                               ,,,,  False      USD  \n",
       "3152                                               ,,,,  False      USD  \n",
       "3159  Career development,Health care,Insurance,Start...  False      USD  \n",
       "3166  Career development,Flex hours,Flex vacation,He...  False      USD  \n",
       "\n",
       "[171 rows x 10 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame[dataFrame[\"Salary\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2995 entries, 0 to 3196\n",
      "Data columns (total 10 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Company                     2995 non-null   object \n",
      " 1   Job Title                   2995 non-null   object \n",
      " 2   Location                    2995 non-null   object \n",
      " 3   Job Type                    2995 non-null   object \n",
      " 4   Experience level            2768 non-null   object \n",
      " 5   Salary                      2995 non-null   float64\n",
      " 6   Requirment of the company   2995 non-null   object \n",
      " 7   Facilities                  2995 non-null   object \n",
      " 8   Plus                        2995 non-null   bool   \n",
      " 9   Currency                    2995 non-null   object \n",
      "dtypes: bool(1), float64(1), object(8)\n",
      "memory usage: 236.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dataFrame.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Experience level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of unique Experience level : ['Entry-level', nan, 'Mid-level', 'Senior-level', 'Executive-level']\n"
     ]
    }
   ],
   "source": [
    "print(\"list of unique Experience level :\",dataFrame[\"Experience level\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine Learning Engineer',\n",
       " 'Data Analyst - Revenue Optimizer',\n",
       " 'BI Analyst',\n",
       " 'Data Science Lead (Hybrid)',\n",
       " 'Data Analyst, Customer Experience',\n",
       " 'Data Engineer',\n",
       " 'HR Data Analyst',\n",
       " 'Data Product Manager',\n",
       " 'Finance Business Intelligence , Operations Finance',\n",
       " 'Data Scientist',\n",
       " 'Data Manager',\n",
       " 'Salesforce Administrator/Data Specialist',\n",
       " 'Business Intelligence Analyst, AWS Cloud Logistics',\n",
       " 'Machine Learning Manager (Systems)',\n",
       " 'Product Manager- Data Visualization & Analytics',\n",
       " 'Data Engineering Manager',\n",
       " 'Data Analyst, Go Live',\n",
       " 'Data Engineer',\n",
       " 'BI Analyst',\n",
       " 'Marketing Data Analyst',\n",
       " 'Software Engineer - Machine Learning, Granica Screen',\n",
       " 'Robotic Research Engineer - Mechatronics',\n",
       " 'Supervis√£o de Business Intelligence (foco em m√≠dia/comunica√ß√£o)',\n",
       " 'Data Analyst (Oslo-based)',\n",
       " 'Business Intelligence Data Strategist',\n",
       " 'Data Engineer Customer Analytics',\n",
       " 'Business Intelligence Analyst - Sales Operations',\n",
       " 'Data Analyst',\n",
       " 'Data Engineer',\n",
       " 'Coordinator of Data Operations',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist (Pricing)',\n",
       " 'Data Specialist - Governance',\n",
       " 'Data Manager',\n",
       " 'Confirmed Data Analyst - Data Pro Supply',\n",
       " 'Product Data Analyst s√©nior (h/f) en CDI √† Paris',\n",
       " 'Backend / Data Engineers II, Cerebro',\n",
       " 'Data Infrastructure Engineer',\n",
       " 'Data Science Software Engineer',\n",
       " 'Data Scientist',\n",
       " 'Data Engineer II',\n",
       " 'Business Intelligence Analyst I',\n",
       " 'QuintoAndar - Analytics Engineer',\n",
       " '(Canada) Business Intelligence Engineer',\n",
       " 'Machine Learning Engineer',\n",
       " 'Lead Data Scientist - Pricing',\n",
       " 'Data Scientist - Data Analytics and Infrastructure',\n",
       " 'Databricks Administrator',\n",
       " 'Lead Data Engineer- Bangalore',\n",
       " 'Marketing Data Scientist',\n",
       " 'Machine Learning Engineer (m/w/x)',\n",
       " 'Data Scientist',\n",
       " 'Python Machine Learning Engineer (AdLight)',\n",
       " 'Middle Product Manager (Data Analysis, Fintech)',\n",
       " 'Data Manager Zakelijke Markt',\n",
       " 'Business Intelligence Specialist',\n",
       " 'Chatbot Engineer',\n",
       " 'Data Quality Management Specialist',\n",
       " 'Data Analyst II',\n",
       " 'Support Ops Manager I, ML Data Operations, FBA Support Operations',\n",
       " 'Consultant (German Speaking) - Data Analytics',\n",
       " 'NLP Engineer',\n",
       " 'Data Analytics Engineer',\n",
       " 'Data Visualisation Consultant',\n",
       " 'Financial Data Analyst',\n",
       " 'Lead-Data Analyst',\n",
       " 'Data Scientist for Reliability Engineering (M/F/D)',\n",
       " 'Data Scientist (Data Science Hub)',\n",
       " 'Clinical Data Manager',\n",
       " 'Logistics Lead - Imaging',\n",
       " 'Lead Data Scientist',\n",
       " 'Data Science Consultant',\n",
       " 'Data Operations Manager - Link',\n",
       " 'Data Scientist, Product Growth',\n",
       " 'Data Scientist, Research',\n",
       " 'Data Analyst, Product',\n",
       " 'Business Intelligence Analytics Lead, (Permanent Remote)',\n",
       " 'Data Engineer',\n",
       " 'Data Scientist (Customer Acquisition)',\n",
       " 'AI/ML Data Labeling Manager - UK',\n",
       " 'Data Engineering Manager',\n",
       " 'Data Scientist (S&OP)',\n",
       " 'Big Data Engineer (IT-DA-DS-2023-76-LD)',\n",
       " 'Data Analytics Manager',\n",
       " 'AI Compiler and Performance Engineer',\n",
       " 'Big Data Specialist',\n",
       " 'Data Scientist (M/F)',\n",
       " 'Data Engineer (Hong Kong)',\n",
       " 'Data Engineer with Top Secret',\n",
       " 'Business Intelligence Analyst - Risk',\n",
       " 'Simulation and Data Engineer Inductive Sensors (m/f)',\n",
       " 'Analyst, Data Science',\n",
       " 'Manager, Business Intelligence',\n",
       " 'Economist, Pricing and Causal Inference',\n",
       " 'Data Specialist',\n",
       " 'QA Data Engineer',\n",
       " 'Lead Data Engineer',\n",
       " 'Data Scientist - Product (U.S. only)',\n",
       " 'Data Operations Analyst',\n",
       " 'Quality Assurance Engineer, Data Center Engineering',\n",
       " 'Data Analyst, Medicare Advantage, Remote',\n",
       " 'Business Intelligence \\x96 Data Engineer (Open to Remote)',\n",
       " 'Clinical Data Manager/Analyst',\n",
       " 'Analytics Engineer',\n",
       " 'Frontend Developer (Chatbot)',\n",
       " 'Data Engineer (F/H)',\n",
       " 'Data Product Manager - SafeMine Cloud',\n",
       " 'Security Engineer, Data Security',\n",
       " 'Data Engineer',\n",
       " 'Data Analyst (Dublin or Paris)',\n",
       " 'Data Analyst, Business Optimisation',\n",
       " 'Robotics Software Developer (multiple positions) - [BGSW]',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer (H/F)',\n",
       " 'Computer Engineer, Computer Vision Hardware (MID//SR)-m/f/d',\n",
       " 'Data Engineer - Concepteur - D√©veloppeur SQL - BigL',\n",
       " 'Research Analyst \\x96 LNG Short-Term',\n",
       " 'Computer Engineer, Computer Vision Hardware (MID//SR)',\n",
       " 'Implementation Data Scientist',\n",
       " 'Data Analytics Specialist',\n",
       " 'Tech Lead BI / Power BI CDI - H/F',\n",
       " 'Data Science Manager',\n",
       " 'Data Analyst',\n",
       " 'MLOps Engineer',\n",
       " 'Financial Data analyst',\n",
       " 'SAP Consultant for Product Data Management',\n",
       " 'Manager, Business Operations - Diagnostic Imaging and Laboratory',\n",
       " 'Computer Engineer, Computer Vision Software and Hardware',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer (Infrastructure)',\n",
       " 'Data Quality Analyst',\n",
       " 'BI Developer',\n",
       " 'Manager, Business Intelligence',\n",
       " 'Cloud Data Scientist',\n",
       " 'AI Data Manager',\n",
       " 'Lead Data Engineer (F/H)',\n",
       " 'Data Strategy Manager (CRM & Loyalty, Consumer Experience, eCommerce)',\n",
       " 'Data Integration Analyst (West Coast/Chicago)',\n",
       " 'Gameplay AI programmer',\n",
       " 'Data Product Manager',\n",
       " 'Finance Data Analyst',\n",
       " 'Product Manager - Computer Vision',\n",
       " 'Data Science Manager, Risk Interventions',\n",
       " 'Analyst, Data Science',\n",
       " 'Vice President, Data Strategy',\n",
       " 'Data Scientist',\n",
       " 'Data Analyst',\n",
       " 'Mid Data Scientist',\n",
       " 'Marketing Data Analyst',\n",
       " 'Machine Learning Engineer',\n",
       " 'Business Intelligence Analyst (m/f/d)',\n",
       " 'Clinical NLP Engineer',\n",
       " 'Personal Assistant to the CIO (AI Asset Mgmt Team)',\n",
       " 'Data Scientist, Marketing & Sales',\n",
       " 'Data Analyst',\n",
       " 'Portfolio Data Feeds - Portfolio Data Analyst',\n",
       " 'Application Infrastructure Consulting (Aic) - 22662 - 22663',\n",
       " 'Data Scientist (F/H)',\n",
       " 'Lead Data Manager',\n",
       " 'IT Data Engineer - Private Banking',\n",
       " 'Healthcare Data Analyst',\n",
       " 'Data Scientist (m/f/d)',\n",
       " 'Data Analyst \\x96 CRM',\n",
       " 'Event manager (AI House)',\n",
       " 'Data Analytics Engineer H/F',\n",
       " 'Data Analyst',\n",
       " 'Data Engineer (TS/SCI clearance)',\n",
       " 'Java Full Stack Developer-Robotics (Colorado only)',\n",
       " 'Full stack Data Scientist',\n",
       " 'SQL Server and ETL Support Engineer (Tier 1/Tier 2)',\n",
       " 'Data Analyst (Trust, Safety & CX Automation Products)',\n",
       " 'Product Data Analyst',\n",
       " 'Hardware Analysis Engineer (Airbag System)',\n",
       " 'ML Engineer',\n",
       " 'Data Analyst',\n",
       " 'Data Operations Manager',\n",
       " 'Business Intelligence Analyst supporting the Operations and Customer teams',\n",
       " 'Analytics Engineer',\n",
       " 'Unreal Engine 3D developer (Zibra AI)',\n",
       " 'Qlik Data Analyst',\n",
       " 'Data Scientist',\n",
       " 'Research Engineer \\x96 Electrolysis and Fuel Cell Experiments',\n",
       " 'Analytics Engineer - ENA London, Warsaw (F/M)',\n",
       " 'Sales B2B (ZibraAI)',\n",
       " 'Machine Learning Engineer',\n",
       " 'Consultant(e) confirm√©(e) ETL',\n",
       " 'Machine Learning Engineer',\n",
       " 'Chatbot Specialist',\n",
       " '[10418 ] Data Developer Master, Brazil',\n",
       " 'DB/ETL Tech Lead',\n",
       " 'Data engineer',\n",
       " 'Data Analyst',\n",
       " 'Data Engineer - TheFork',\n",
       " 'Data Developer, Client Experience Metrics',\n",
       " 'Quant Researcher (AI Asset Mgmt Team)',\n",
       " 'Software Engineer for Real-Driving Data Analysis Applications',\n",
       " 'Lead Data Engineer',\n",
       " 'Machine Learning Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer',\n",
       " 'Developer - Big Data',\n",
       " 'Machine Learning Engineer II',\n",
       " 'Data Scientist',\n",
       " 'Engineer I (MLOps)',\n",
       " 'Data Scientist (TS/SCI clearance)',\n",
       " 'Machine Learning Solutions Engineer',\n",
       " 'Product Manager, AI/ML',\n",
       " 'Machine Learning Specialist',\n",
       " 'Research Scientist',\n",
       " 'Analytics Engineer - Ads Business Insights',\n",
       " 'Data Analyst - London',\n",
       " 'Data Engineer - 14072',\n",
       " 'Data Scientist',\n",
       " 'Data Engineer',\n",
       " 'Manager, Data Analytics',\n",
       " 'MLOps Engineer - AI (Remote, India)',\n",
       " 'Data Engineer (TS/SCI clearance)',\n",
       " 'Consultant Data Visualisation - H/F',\n",
       " 'Sustainability Data Analyst',\n",
       " 'Data Visualisation Consultant',\n",
       " 'Data Analyst',\n",
       " 'FAIR Data Lead',\n",
       " 'Agronomy Data Scientist (M/W) - CDI',\n",
       " 'Data Engineer',\n",
       " 'Data Operations Engineer',\n",
       " 'Data Engineer',\n",
       " 'Data Engineer (Contractor)']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame[\"Job Title\"][dataFrame[\"Experience level\"].isna()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame['Facilities'] = dataFrame['Facilities'].str.replace(',,,,', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame[\"Experience level\"].fillna('not-specified',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame[\"Experience level\"]=dataFrame[\"Experience level\"].str.replace('not-required','not-specified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Categorier les \"Experience level\" colonnes\n",
    "data = pd.get_dummies(dataFrame, columns=['Experience level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Plus</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Experience level_Entry-level</th>\n",
       "      <th>Experience level_Executive-level</th>\n",
       "      <th>Experience level_Mid-level</th>\n",
       "      <th>Experience level_Senior-level</th>\n",
       "      <th>Experience level_not-specified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGS</td>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Richardson, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Computer Science,Data quality,Genetics,Mathema...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ocorian</td>\n",
       "      <td>AML/CFT &amp; Data Analyst</td>\n",
       "      <td>Eb√®ne, Mauritius</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Agile,Data management,Finance,Security,,</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cricut</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>South Jordan, UT, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>Agile,Architecture,AWS,Computer Science,Comput...</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bosch Group</td>\n",
       "      <td>Application Developer &amp; Data Analyst</td>\n",
       "      <td>Nonantola, Italy</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Engineering,Industrial,Oracle,Power BI,R,R&amp;D</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Publicis Groupe</td>\n",
       "      <td>Data Engineer Full time (Public Sector) USA</td>\n",
       "      <td>Arlington, VA, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>108000.0</td>\n",
       "      <td>AWS,Azure,Computer Science,Consulting,Dataflow...</td>\n",
       "      <td>Flex hours,Flex vacation,Parental leave,Unlimi...</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3190</th>\n",
       "      <td>CCRi</td>\n",
       "      <td>Application Integration Engineer, Computer Vis...</td>\n",
       "      <td>Chantilly, Virginia, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>113000.0</td>\n",
       "      <td>Agile,Angular,APIs,Architecture,AWS,Azure</td>\n",
       "      <td>401(k) matching,Career development,Flex hours,...</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3191</th>\n",
       "      <td>Publicis Groupe</td>\n",
       "      <td>Associate Director, Data Science</td>\n",
       "      <td>New York City, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>106000.0</td>\n",
       "      <td>Bayesian,Classification,Clustering,Data analys...</td>\n",
       "      <td>Career development,Health care,,,</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3192</th>\n",
       "      <td>DoorDash</td>\n",
       "      <td>Senior Software Engineer, Machine Learning - A...</td>\n",
       "      <td>Sunnyvale, CA; San Francisco, CA; New York</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>176000.0</td>\n",
       "      <td>Computer Science,Data analysis,Engineering,Exc...</td>\n",
       "      <td>401(k) matching,Career development,Equity,Insu...</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>Western Digital</td>\n",
       "      <td>Data Scientist - New College Graduate</td>\n",
       "      <td>Bi√±an, Philippines</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>39000.0</td>\n",
       "      <td>APIs,Clustering,Computer Science,Data visualiz...</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>ATB Financial</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Edmonton, Alberta, Canada</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>39000.0</td>\n",
       "      <td>Computer Science,Data Analytics,Data Mining,Ec...</td>\n",
       "      <td>Career development,Startup environment,,,</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2995 rows √ó 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Company                                          Job Title  \\\n",
       "0                 SGS                              Clinical Data Analyst   \n",
       "1             Ocorian                             AML/CFT & Data Analyst   \n",
       "2              Cricut                          Machine Learning Engineer   \n",
       "3         Bosch Group               Application Developer & Data Analyst   \n",
       "4     Publicis Groupe        Data Engineer Full time (Public Sector) USA   \n",
       "...               ...                                                ...   \n",
       "3190             CCRi  Application Integration Engineer, Computer Vis...   \n",
       "3191  Publicis Groupe                   Associate Director, Data Science   \n",
       "3192         DoorDash  Senior Software Engineer, Machine Learning - A...   \n",
       "3193  Western Digital              Data Scientist - New College Graduate   \n",
       "3196    ATB Financial                                     Data Scientist   \n",
       "\n",
       "                                          Location   Job Type    Salary  \\\n",
       "0                    Richardson, TX, United States  Full Time   48000.0   \n",
       "1                                 Eb√®ne, Mauritius  Full Time   48000.0   \n",
       "2                  South Jordan, UT, United States  Full Time   90000.0   \n",
       "3                                 Nonantola, Italy  Full Time   48000.0   \n",
       "4                     Arlington, VA, United States  Full Time  108000.0   \n",
       "...                                            ...        ...       ...   \n",
       "3190            Chantilly, Virginia, United States  Full Time  113000.0   \n",
       "3191                  New York City, United States  Full Time  106000.0   \n",
       "3192  Sunnyvale, CA; San Francisco, CA; New York \n",
       "  Full Time  176000.0   \n",
       "3193                            Bi√±an, Philippines  Full Time   39000.0   \n",
       "3196                     Edmonton, Alberta, Canada  Full Time   39000.0   \n",
       "\n",
       "                             Requirment of the company   \\\n",
       "0     Computer Science,Data quality,Genetics,Mathema...   \n",
       "1              Agile,Data management,Finance,Security,,   \n",
       "2     Agile,Architecture,AWS,Computer Science,Comput...   \n",
       "3          Engineering,Industrial,Oracle,Power BI,R,R&D   \n",
       "4     AWS,Azure,Computer Science,Consulting,Dataflow...   \n",
       "...                                                 ...   \n",
       "3190          Agile,Angular,APIs,Architecture,AWS,Azure   \n",
       "3191  Bayesian,Classification,Clustering,Data analys...   \n",
       "3192  Computer Science,Data analysis,Engineering,Exc...   \n",
       "3193  APIs,Clustering,Computer Science,Data visualiz...   \n",
       "3196  Computer Science,Data Analytics,Data Mining,Ec...   \n",
       "\n",
       "                                             Facilities   Plus Currency  \\\n",
       "0                                                         True      USD   \n",
       "1                                                         True      USD   \n",
       "2                                    Career development   True      USD   \n",
       "3                                                         True      USD   \n",
       "4     Flex hours,Flex vacation,Parental leave,Unlimi...  False      USD   \n",
       "...                                                 ...    ...      ...   \n",
       "3190  401(k) matching,Career development,Flex hours,...  False      USD   \n",
       "3191                  Career development,Health care,,,  False      USD   \n",
       "3192  401(k) matching,Career development,Equity,Insu...  False      USD   \n",
       "3193                                 Career development   True      USD   \n",
       "3196          Career development,Startup environment,,,   True      USD   \n",
       "\n",
       "      Experience level_Entry-level  Experience level_Executive-level  \\\n",
       "0                                1                                 0   \n",
       "1                                1                                 0   \n",
       "2                                0                                 0   \n",
       "3                                1                                 0   \n",
       "4                                0                                 0   \n",
       "...                            ...                               ...   \n",
       "3190                             0                                 0   \n",
       "3191                             0                                 0   \n",
       "3192                             0                                 0   \n",
       "3193                             1                                 0   \n",
       "3196                             1                                 0   \n",
       "\n",
       "      Experience level_Mid-level  Experience level_Senior-level  \\\n",
       "0                              0                              0   \n",
       "1                              0                              0   \n",
       "2                              0                              0   \n",
       "3                              0                              0   \n",
       "4                              1                              0   \n",
       "...                          ...                            ...   \n",
       "3190                           1                              0   \n",
       "3191                           1                              0   \n",
       "3192                           0                              1   \n",
       "3193                           0                              0   \n",
       "3196                           0                              0   \n",
       "\n",
       "      Experience level_not-specified  \n",
       "0                                  0  \n",
       "1                                  0  \n",
       "2                                  1  \n",
       "3                                  0  \n",
       "4                                  0  \n",
       "...                              ...  \n",
       "3190                               0  \n",
       "3191                               0  \n",
       "3192                               0  \n",
       "3193                               0  \n",
       "3196                               0  \n",
       "\n",
       "[2995 rows x 14 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Requirment of the company et Facilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Plus</th>\n",
       "      <th>Currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>ATB Financial</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Edmonton, Alberta, Canada</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Mid-level</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>Agile,Banking,Business Analytics,Computer Scie...</td>\n",
       "      <td>Flex hours,Flex vacation,Health care,Startup e...</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>ATB Financial</td>\n",
       "      <td>Data Developer, Client Experience Metrics</td>\n",
       "      <td>Alberta, Canada - Remote</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>not-specified</td>\n",
       "      <td>56000.0</td>\n",
       "      <td>Architecture,Banking,Computer Science,CX,Distr...</td>\n",
       "      <td>Career development,Flex vacation,Startup envir...</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>ATB Financial</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Edmonton, Alberta, Canada</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>39000.0</td>\n",
       "      <td>Computer Science,Data Analytics,Data Mining,Ec...</td>\n",
       "      <td>Career development,Startup environment,,,</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Company                                  Job Title  \\\n",
       "1585  ATB Financial                               Data Analyst   \n",
       "2717  ATB Financial  Data Developer, Client Experience Metrics   \n",
       "3196  ATB Financial                             Data Scientist   \n",
       "\n",
       "                       Location   Job Type Experience level   Salary  \\\n",
       "1585  Edmonton, Alberta, Canada  Full Time        Mid-level  65000.0   \n",
       "2717   Alberta, Canada - Remote  Full Time    not-specified  56000.0   \n",
       "3196  Edmonton, Alberta, Canada  Full Time      Entry-level  39000.0   \n",
       "\n",
       "                             Requirment of the company   \\\n",
       "1585  Agile,Banking,Business Analytics,Computer Scie...   \n",
       "2717  Architecture,Banking,Computer Science,CX,Distr...   \n",
       "3196  Computer Science,Data Analytics,Data Mining,Ec...   \n",
       "\n",
       "                                             Facilities  Plus Currency  \n",
       "1585  Flex hours,Flex vacation,Health care,Startup e...  True      USD  \n",
       "2717  Career development,Flex vacation,Startup envir...  True      USD  \n",
       "3196          Career development,Startup environment,,,  True      USD  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame[dataFrame[\"Company\"]=='ATB Financial']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_comma_column_values (colum_name_comma_value,dataFrame) :\n",
    "    dataFrame[colum_name_comma_value] = dataFrame[colum_name_comma_value].str.split(',')\n",
    "    new_df = dataFrame.explode(colum_name_comma_value)\n",
    "    new_df = new_df.reset_index(drop=True)\n",
    "    new_df[colum_name_comma_value].str.strip()\n",
    "    new_df.drop_duplicates(inplace=True)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame=split_comma_column_values ('Facilities',dataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Plus</th>\n",
       "      <th>Currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9580</th>\n",
       "      <td>Block</td>\n",
       "      <td>Senior Data Analyst, Credit Policy</td>\n",
       "      <td>San Francisco, CA, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>Banking,Blockchain,Credit risk,Crypto,CX,Data ...</td>\n",
       "      <td>Health care</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4025</th>\n",
       "      <td>Block</td>\n",
       "      <td>Senior Software Engineer, Data Safety</td>\n",
       "      <td>Los Angeles, CA, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>156000.0</td>\n",
       "      <td>APIs,AWS,Banking,Big Data,Blockchain,Crypto</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3296</th>\n",
       "      <td>Fastly, Inc.</td>\n",
       "      <td>Senior People Data Analyst - Workday</td>\n",
       "      <td>New York City, NY</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>113000.0</td>\n",
       "      <td>Agile,APIs,Business Analytics,Business Intelli...</td>\n",
       "      <td>Health care</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>GOURMEY</td>\n",
       "      <td>Data Science Intern</td>\n",
       "      <td>Paris, √éle-de-France, France</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Agile,Data Analytics,Data management,Engineeri...</td>\n",
       "      <td>Health care</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8422</th>\n",
       "      <td>Deezer</td>\n",
       "      <td>Data Engineer Intern m/f/d - Industry Team</td>\n",
       "      <td>Paris, France</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>APIs,Big Data,BigQuery,Data pipelines,Engineer...</td>\n",
       "      <td></td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3321</th>\n",
       "      <td>Jellyfish</td>\n",
       "      <td>Senior data analyst</td>\n",
       "      <td>Paris, France</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>92000.0</td>\n",
       "      <td>Agile,AWS,Azure,Data analysis,Data Analytics,D...</td>\n",
       "      <td>Salary bonus</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9647</th>\n",
       "      <td>Sertis</td>\n",
       "      <td>Data Analyst - Business Insights</td>\n",
       "      <td>Bangkok</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>92000.0</td>\n",
       "      <td>Banking,Computer Vision,Consulting,Excel,Marke...</td>\n",
       "      <td></td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9338</th>\n",
       "      <td>Beyond Finance</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>141000.0</td>\n",
       "      <td>Airflow,Ansible,Architecture,AWS,BigQuery,Comp...</td>\n",
       "      <td>Health care</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6321</th>\n",
       "      <td>Snyk</td>\n",
       "      <td>Director, Engineering - ML / AI</td>\n",
       "      <td>London</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Executive-level</td>\n",
       "      <td>73000.0</td>\n",
       "      <td>Engineering,Machine Learning,R,R&amp;D,Research,Se...</td>\n",
       "      <td>Flex hours</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10264</th>\n",
       "      <td>Nextdoor</td>\n",
       "      <td>Senior/Staff Machine Learning Engineer - Ads</td>\n",
       "      <td>US Remote</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>Biology,Computer Science,Engineering,Machine L...</td>\n",
       "      <td>Equity</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Company                                     Job Title  \\\n",
       "9580            Block            Senior Data Analyst, Credit Policy   \n",
       "4025            Block         Senior Software Engineer, Data Safety   \n",
       "3296     Fastly, Inc.          Senior People Data Analyst - Workday   \n",
       "3261          GOURMEY                           Data Science Intern   \n",
       "8422           Deezer    Data Engineer Intern m/f/d - Industry Team   \n",
       "3321        Jellyfish                           Senior data analyst   \n",
       "9647           Sertis              Data Analyst - Business Insights   \n",
       "9338   Beyond Finance                          Senior Data Engineer   \n",
       "6321             Snyk               Director, Engineering - ML / AI   \n",
       "10264        Nextdoor  Senior/Staff Machine Learning Engineer - Ads   \n",
       "\n",
       "                               Location    Job Type Experience level  \\\n",
       "9580   San Francisco, CA, United States   Full Time     Senior-level   \n",
       "4025     Los Angeles, CA, United States   Full Time     Senior-level   \n",
       "3296                  New York City, NY   Full Time     Senior-level   \n",
       "3261       Paris, √éle-de-France, France  Internship      Entry-level   \n",
       "8422                      Paris, France  Internship      Entry-level   \n",
       "3321                      Paris, France   Full Time     Senior-level   \n",
       "9647                            Bangkok   Full Time     Senior-level   \n",
       "9338                        Chicago, IL   Full Time     Senior-level   \n",
       "6321                             London   Full Time  Executive-level   \n",
       "10264                         US Remote   Full Time     Senior-level   \n",
       "\n",
       "         Salary                         Requirment of the company   \\\n",
       "9580   110000.0  Banking,Blockchain,Credit risk,Crypto,CX,Data ...   \n",
       "4025   156000.0        APIs,AWS,Banking,Big Data,Blockchain,Crypto   \n",
       "3296   113000.0  Agile,APIs,Business Analytics,Business Intelli...   \n",
       "3261        0.0  Agile,Data Analytics,Data management,Engineeri...   \n",
       "8422        0.0  APIs,Big Data,BigQuery,Data pipelines,Engineer...   \n",
       "3321    92000.0  Agile,AWS,Azure,Data analysis,Data Analytics,D...   \n",
       "9647    92000.0  Banking,Computer Vision,Consulting,Excel,Marke...   \n",
       "9338   141000.0  Airflow,Ansible,Architecture,AWS,BigQuery,Comp...   \n",
       "6321    73000.0  Engineering,Machine Learning,R,R&D,Research,Se...   \n",
       "10264  180000.0  Biology,Computer Science,Engineering,Machine L...   \n",
       "\n",
       "         Facilities   Plus Currency  \n",
       "9580    Health care  False      USD  \n",
       "4025      Insurance  False      USD  \n",
       "3296    Health care  False      USD  \n",
       "3261    Health care  False      NaN  \n",
       "8422                 False      NaN  \n",
       "3321   Salary bonus   True      USD  \n",
       "9647                  True      USD  \n",
       "9338    Health care  False      USD  \n",
       "6321     Flex hours   True      USD  \n",
       "10264        Equity  False      USD  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of unique Facilities : ['', 'Career development', 'Flex hours', 'Flex vacation', 'Parental leave', 'Unlimited paid time off', '401(k) matching', 'Competitive pay', 'Equity', 'Gear', 'Health care', 'Medical leave', 'Salary bonus', 'Startup environment', 'Team events', 'Home office stipend', 'Insurance', 'Fitness / gym', 'Relocation support', 'Fertility benefits', 'Conferences', 'Cell phone stipend', 'Wellness', 'Transparency', 'Lunch / meals', 'Yoga', 'Flexible spending account', 'Travel', 'Snacks / Drinks', 'Paid sabbatical', 'Pet friendly', 'Flat hierarchy', 'Signing bonus', 'Contract', 'Freelance']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 'Length :35')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"list of unique Facilities :\",dataFrame[\"Facilities\"].unique().tolist()),\"Length :\"+str(len(dataFrame[\"Facilities\"].unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Youcode\\AppData\\Local\\Temp\\ipykernel_90516\\2557170505.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataFrame['Facilities'][dataFrame['Facilities'].str.fullmatch('')]=dataFrame['Facilities'][dataFrame['Facilities'].str.fullmatch('')].str.replace('', 'no-Facilities')\n"
     ]
    }
   ],
   "source": [
    "dataFrame['Facilities'][dataFrame['Facilities'].str.fullmatch('')]=dataFrame['Facilities'][dataFrame['Facilities'].str.fullmatch('')].str.replace('', 'no-Facilities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Plus</th>\n",
       "      <th>Currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGS</td>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Richardson, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Computer Science,Data quality,Genetics,Mathema...</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ocorian</td>\n",
       "      <td>AML/CFT &amp; Data Analyst</td>\n",
       "      <td>Eb√®ne, Mauritius</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Agile,Data management,Finance,Security,,</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bosch Group</td>\n",
       "      <td>Application Developer &amp; Data Analyst</td>\n",
       "      <td>Nonantola, Italy</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Engineering,Industrial,Oracle,Power BI,R,R&amp;D</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Publicis Groupe</td>\n",
       "      <td>Data Engineer Full time (Public Sector) USA</td>\n",
       "      <td>Arlington, VA, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Mid-level</td>\n",
       "      <td>108000.0</td>\n",
       "      <td>AWS,Azure,Computer Science,Consulting,Dataflow...</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NielsenIQ</td>\n",
       "      <td>Intern (Business Intelligence Service Support)</td>\n",
       "      <td>Bangkok, Thailand</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Business Intelligence,Excel,Genetics,,,</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11117</th>\n",
       "      <td>C3.ai</td>\n",
       "      <td>Lead Data Scientist - Healthcare</td>\n",
       "      <td>London, UK</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>Architecture,Classification,Computer Science,D...</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11123</th>\n",
       "      <td>C3.ai</td>\n",
       "      <td>Data Scientist / Senior Data Scientist (Federal)</td>\n",
       "      <td>Tysons, VA; Dayton, OH; Redwood City, CA</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>123000.0</td>\n",
       "      <td>Architecture,Classification,Computer Science,C...</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11133</th>\n",
       "      <td>C3.ai</td>\n",
       "      <td>Data Science Instructor</td>\n",
       "      <td>Redwood City, California</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>109000.0</td>\n",
       "      <td>Architecture,Clustering,ETL,Jupyter,Machine Le...</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11157</th>\n",
       "      <td>Publicis Groupe</td>\n",
       "      <td>Associate Director, Data Science</td>\n",
       "      <td>New York City, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Mid-level</td>\n",
       "      <td>106000.0</td>\n",
       "      <td>Bayesian,Classification,Clustering,Data analys...</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11168</th>\n",
       "      <td>ATB Financial</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Edmonton, Alberta, Canada</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>39000.0</td>\n",
       "      <td>Computer Science,Data Analytics,Data Mining,Ec...</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1515 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company                                         Job Title  \\\n",
       "0                  SGS                             Clinical Data Analyst   \n",
       "1              Ocorian                            AML/CFT & Data Analyst   \n",
       "3          Bosch Group              Application Developer & Data Analyst   \n",
       "8      Publicis Groupe       Data Engineer Full time (Public Sector) USA   \n",
       "15           NielsenIQ    Intern (Business Intelligence Service Support)   \n",
       "...                ...                                               ...   \n",
       "11117            C3.ai                  Lead Data Scientist - Healthcare   \n",
       "11123            C3.ai  Data Scientist / Senior Data Scientist (Federal)   \n",
       "11133            C3.ai                           Data Science Instructor   \n",
       "11157  Publicis Groupe                  Associate Director, Data Science   \n",
       "11168    ATB Financial                                    Data Scientist   \n",
       "\n",
       "                                       Location    Job Type Experience level  \\\n",
       "0                 Richardson, TX, United States   Full Time      Entry-level   \n",
       "1                              Eb√®ne, Mauritius   Full Time      Entry-level   \n",
       "3                              Nonantola, Italy   Full Time      Entry-level   \n",
       "8                  Arlington, VA, United States   Full Time        Mid-level   \n",
       "15                            Bangkok, Thailand  Internship      Entry-level   \n",
       "...                                         ...         ...              ...   \n",
       "11117                                London, UK   Full Time     Senior-level   \n",
       "11123  Tysons, VA; Dayton, OH; Redwood City, CA   Full Time     Senior-level   \n",
       "11133                  Redwood City, California   Full Time     Senior-level   \n",
       "11157              New York City, United States   Full Time        Mid-level   \n",
       "11168                 Edmonton, Alberta, Canada   Full Time      Entry-level   \n",
       "\n",
       "         Salary                         Requirment of the company   \\\n",
       "0       48000.0  Computer Science,Data quality,Genetics,Mathema...   \n",
       "1       48000.0           Agile,Data management,Finance,Security,,   \n",
       "3       48000.0       Engineering,Industrial,Oracle,Power BI,R,R&D   \n",
       "8      108000.0  AWS,Azure,Computer Science,Consulting,Dataflow...   \n",
       "15          0.0            Business Intelligence,Excel,Genetics,,,   \n",
       "...         ...                                                ...   \n",
       "11117  129000.0  Architecture,Classification,Computer Science,D...   \n",
       "11123  123000.0  Architecture,Classification,Computer Science,C...   \n",
       "11133  109000.0  Architecture,Clustering,ETL,Jupyter,Machine Le...   \n",
       "11157  106000.0  Bayesian,Classification,Clustering,Data analys...   \n",
       "11168   39000.0  Computer Science,Data Analytics,Data Mining,Ec...   \n",
       "\n",
       "          Facilities   Plus Currency  \n",
       "0      no-Facilities   True      USD  \n",
       "1      no-Facilities   True      USD  \n",
       "3      no-Facilities   True      USD  \n",
       "8      no-Facilities  False      USD  \n",
       "15     no-Facilities  False      NaN  \n",
       "...              ...    ...      ...  \n",
       "11117  no-Facilities   True      USD  \n",
       "11123  no-Facilities  False      USD  \n",
       "11133  no-Facilities  False      USD  \n",
       "11157  no-Facilities  False      USD  \n",
       "11168  no-Facilities   True      USD  \n",
       "\n",
       "[1515 rows x 10 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame[dataFrame['Facilities']=='no-Facilities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame=split_comma_column_values (\"Requirment of the company \",dataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Plus</th>\n",
       "      <th>Currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGS</td>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Richardson, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGS</td>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Richardson, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Data quality</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGS</td>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Richardson, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Genetics</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGS</td>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Richardson, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGS</td>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Richardson, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>SAS</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60325</th>\n",
       "      <td>ATB Financial</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Edmonton, Alberta, Canada</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>39000.0</td>\n",
       "      <td>Data Analytics</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60326</th>\n",
       "      <td>ATB Financial</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Edmonton, Alberta, Canada</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>39000.0</td>\n",
       "      <td>Data Mining</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60327</th>\n",
       "      <td>ATB Financial</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Edmonton, Alberta, Canada</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>39000.0</td>\n",
       "      <td>Economics</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60328</th>\n",
       "      <td>ATB Financial</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Edmonton, Alberta, Canada</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>39000.0</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60329</th>\n",
       "      <td>ATB Financial</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Edmonton, Alberta, Canada</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>39000.0</td>\n",
       "      <td>GCP</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58950 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Company              Job Title                       Location  \\\n",
       "0                SGS  Clinical Data Analyst  Richardson, TX, United States   \n",
       "1                SGS  Clinical Data Analyst  Richardson, TX, United States   \n",
       "2                SGS  Clinical Data Analyst  Richardson, TX, United States   \n",
       "3                SGS  Clinical Data Analyst  Richardson, TX, United States   \n",
       "4                SGS  Clinical Data Analyst  Richardson, TX, United States   \n",
       "...              ...                    ...                            ...   \n",
       "60325  ATB Financial         Data Scientist      Edmonton, Alberta, Canada   \n",
       "60326  ATB Financial         Data Scientist      Edmonton, Alberta, Canada   \n",
       "60327  ATB Financial         Data Scientist      Edmonton, Alberta, Canada   \n",
       "60328  ATB Financial         Data Scientist      Edmonton, Alberta, Canada   \n",
       "60329  ATB Financial         Data Scientist      Edmonton, Alberta, Canada   \n",
       "\n",
       "        Job Type Experience level   Salary Requirment of the company   \\\n",
       "0      Full Time      Entry-level  48000.0           Computer Science   \n",
       "1      Full Time      Entry-level  48000.0               Data quality   \n",
       "2      Full Time      Entry-level  48000.0                   Genetics   \n",
       "3      Full Time      Entry-level  48000.0                Mathematics   \n",
       "4      Full Time      Entry-level  48000.0                        SAS   \n",
       "...          ...              ...      ...                        ...   \n",
       "60325  Full Time      Entry-level  39000.0             Data Analytics   \n",
       "60326  Full Time      Entry-level  39000.0                Data Mining   \n",
       "60327  Full Time      Entry-level  39000.0                  Economics   \n",
       "60328  Full Time      Entry-level  39000.0                Engineering   \n",
       "60329  Full Time      Entry-level  39000.0                        GCP   \n",
       "\n",
       "          Facilities  Plus Currency  \n",
       "0      no-Facilities  True      USD  \n",
       "1      no-Facilities  True      USD  \n",
       "2      no-Facilities  True      USD  \n",
       "3      no-Facilities  True      USD  \n",
       "4      no-Facilities  True      USD  \n",
       "...              ...   ...      ...  \n",
       "60325  no-Facilities  True      USD  \n",
       "60326  no-Facilities  True      USD  \n",
       "60327  no-Facilities  True      USD  \n",
       "60328  no-Facilities  True      USD  \n",
       "60329  no-Facilities  True      USD  \n",
       "\n",
       "[58950 rows x 10 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of unique Requirment of the company : ['Computer Science', 'Data quality', 'Genetics', 'Mathematics', 'SAS', 'Statistics', 'Agile', 'Data management', 'Finance', 'Security', '', 'Architecture', 'AWS', 'Computer Vision', 'Deep Learning', 'Engineering', 'Industrial', 'Oracle', 'Power BI', 'R', 'R&D', 'Azure', 'Consulting', 'Dataflow', 'Data pipelines', 'Machine Learning', 'NLP', 'NumPy', 'Banking', 'Excel', 'Business Intelligence', 'Big Data', 'Matlab', 'APIs', 'Data analysis', 'Keras', 'PhD', 'Business Analytics', 'Economics', 'Data Analytics', 'Market research', 'Privacy', 'Spark', 'BigQuery', 'LLMs', 'Pandas', 'Python', 'CUDA', 'Docker', 'Git', 'GitHub', 'GitLab', 'Redshift', 'Data warehouse', 'Looker', 'Data visualization', 'Metabase', 'E-commerce', 'Airflow', 'Clustering', 'Data governance', 'Data Mining', 'Blockchain', 'Databricks', 'SQL', 'CI/CD', 'DevOps', 'ETL', 'Crypto', 'Fraud risk', 'Tableau', 'Cybernetics', 'DataRobot', 'A/B testing', 'Angular', 'JavaScript', 'Data Warehousing', 'KPIs', 'ML models', 'Pipelines', 'Classification', 'Bigtable', 'Distributed Systems', 'GCP', 'Generative modeling', 'DataOps', 'Research', 'Testing', 'Hadoop', 'Dagster', 'Physics', 'Causal inference', 'CX', 'Autonomous Driving', 'Linux', 'Matplotlib', 'MongoDB', 'Jira', 'React', 'Consulting firm', 'MySQL', 'GANs', 'Athena', 'Cassandra', 'ELT', 'Snowflake', 'Econometrics', 'Biology', 'BERT', 'Chatbots', 'Dataproc', 'NoSQL', 'ASR', 'FinTech', 'Prototyping', 'Ansible', 'Elasticsearch', 'Credit risk', 'Google Cloud', 'Feature engineering', 'EDA', 'Data strategy', 'JSON', 'Model design', 'Airtable', 'PostgreSQL', 'DynamoDB', 'Bayesian', 'EC2', 'Kubernetes', 'OOP', 'Grafana', 'Diffusion models', 'Drug discovery', 'Kafka', 'AI strategy', 'GPT', 'Drones', 'Bitbucket', 'MLFlow', 'Conversational AI', 'ICLR', 'ICML', 'FiveTran', 'AI governance', 'Robotics', 'Scrum', 'Scala', 'Model training', 'SLAM', 'Streaming', 'Chemistry', 'CAD', 'HuggingFace', 'Cluster analysis', 'Qlik', 'Data Studio', 'Nonprofit', 'Avro', 'MS SQL', 'Healthcare technology', 'API Development', 'UX', 'Ruby', 'CMake', 'Open Source', 'Golang', 'Linear algebra', 'Machine intelligence', 'Caffe', 'VR', 'Jupyter', 'Lambda', 'Predictive modeling', 'Amplitude', 'MXNet', 'ChatGPT', 'Kinesis', 'TypeScript', 'DICOM', 'LangChain', 'Unstructured data', 'PHP', 'GPT-3', 'GPT-4', 'Azkaban', 'GPU', 'RDBMS', 'Flink', 'Haystack', 'Driver\\x92s license', 'Flask', 'Kanban', 'Parquet', 'OpenCV', 'STEM', 'MLOps', 'Plotly', 'D3', 'Circuit Design', 'EMNLP', 'ML infrastructure', 'Kubeflow', '3D Reconstruction', 'CSV', 'Elixir', 'OLAP', 'Julia', 'HPC', 'DB2', 'ECS', 'Content creation', 'Perl', 'Teaching', 'TensorFlow', 'ITIL', 'PyTorch', 'Lua', 'OpenAI', 'OCR', 'Pentaho', 'XML', 'XSD', 'AGI', 'DALL-E', 'Model inference', 'GloVe', 'Node.js', 'Informatica', 'OKR', 'Lidar', 'Periscope', 'SharePoint', 'HBase', 'PySpark', 'SSIS', 'NLTK', 'AIStats', 'Autoregressive models', 'Microservices', 'Minitab', 'SDLC', 'LookML', 'Core ML', 'Django', 'cuDNN', 'Anaconda', 'AI art', 'JAX', 'QlikView', '3D graphics', 'SDL', 'Vue', 'Biochemistry', 'AI content', 'REST API', 'KNIME', 'Alpaca', 'NLG', 'ANN', 'NeurIPS', 'Fortran', 'Transformers', 'Clinical NLP', 'Teradata', 'Kibana', 'HDFS', 'Arrow', 'C++', '.NET', 'Travel', 'fastai', 'Horovod', 'ISO 27001', 'Copywriting', 'HiveQL', 'Splunk', 'LightGBM', 'Clojure', 'SIMD', 'ELK', 'Model deployment', 'CoreML', 'TDD', 'Recommender systems', 'Maven']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 'Length :286')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"list of unique Requirment of the company :\",dataFrame[\"Requirment of the company \"].unique().tolist()),\"Length :\"+str(len(dataFrame[\"Requirment of the company \"].unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Plus</th>\n",
       "      <th>Currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ocorian</td>\n",
       "      <td>AML/CFT &amp; Data Analyst</td>\n",
       "      <td>Eb√®ne, Mauritius</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Agile</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ocorian</td>\n",
       "      <td>AML/CFT &amp; Data Analyst</td>\n",
       "      <td>Eb√®ne, Mauritius</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Data management</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ocorian</td>\n",
       "      <td>AML/CFT &amp; Data Analyst</td>\n",
       "      <td>Eb√®ne, Mauritius</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Finance</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ocorian</td>\n",
       "      <td>AML/CFT &amp; Data Analyst</td>\n",
       "      <td>Eb√®ne, Mauritius</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Security</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ocorian</td>\n",
       "      <td>AML/CFT &amp; Data Analyst</td>\n",
       "      <td>Eb√®ne, Mauritius</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td></td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44472</th>\n",
       "      <td>Ocorian</td>\n",
       "      <td>AML/CFT &amp; Data Analyst</td>\n",
       "      <td>Eb√®ne, Mauritius</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>Agile</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44473</th>\n",
       "      <td>Ocorian</td>\n",
       "      <td>AML/CFT &amp; Data Analyst</td>\n",
       "      <td>Eb√®ne, Mauritius</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>Data management</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44474</th>\n",
       "      <td>Ocorian</td>\n",
       "      <td>AML/CFT &amp; Data Analyst</td>\n",
       "      <td>Eb√®ne, Mauritius</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>Finance</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44475</th>\n",
       "      <td>Ocorian</td>\n",
       "      <td>AML/CFT &amp; Data Analyst</td>\n",
       "      <td>Eb√®ne, Mauritius</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>Security</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44476</th>\n",
       "      <td>Ocorian</td>\n",
       "      <td>AML/CFT &amp; Data Analyst</td>\n",
       "      <td>Eb√®ne, Mauritius</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>42000.0</td>\n",
       "      <td></td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Company               Job Title          Location   Job Type  \\\n",
       "6      Ocorian  AML/CFT & Data Analyst  Eb√®ne, Mauritius  Full Time   \n",
       "7      Ocorian  AML/CFT & Data Analyst  Eb√®ne, Mauritius  Full Time   \n",
       "8      Ocorian  AML/CFT & Data Analyst  Eb√®ne, Mauritius  Full Time   \n",
       "9      Ocorian  AML/CFT & Data Analyst  Eb√®ne, Mauritius  Full Time   \n",
       "10     Ocorian  AML/CFT & Data Analyst  Eb√®ne, Mauritius  Full Time   \n",
       "44472  Ocorian  AML/CFT & Data Analyst  Eb√®ne, Mauritius  Full Time   \n",
       "44473  Ocorian  AML/CFT & Data Analyst  Eb√®ne, Mauritius  Full Time   \n",
       "44474  Ocorian  AML/CFT & Data Analyst  Eb√®ne, Mauritius  Full Time   \n",
       "44475  Ocorian  AML/CFT & Data Analyst  Eb√®ne, Mauritius  Full Time   \n",
       "44476  Ocorian  AML/CFT & Data Analyst  Eb√®ne, Mauritius  Full Time   \n",
       "\n",
       "      Experience level   Salary Requirment of the company      Facilities  \\\n",
       "6          Entry-level  48000.0                      Agile  no-Facilities   \n",
       "7          Entry-level  48000.0            Data management  no-Facilities   \n",
       "8          Entry-level  48000.0                    Finance  no-Facilities   \n",
       "9          Entry-level  48000.0                   Security  no-Facilities   \n",
       "10         Entry-level  48000.0                             no-Facilities   \n",
       "44472      Entry-level  42000.0                      Agile  no-Facilities   \n",
       "44473      Entry-level  42000.0            Data management  no-Facilities   \n",
       "44474      Entry-level  42000.0                    Finance  no-Facilities   \n",
       "44475      Entry-level  42000.0                   Security  no-Facilities   \n",
       "44476      Entry-level  42000.0                             no-Facilities   \n",
       "\n",
       "       Plus Currency  \n",
       "6      True      USD  \n",
       "7      True      USD  \n",
       "8      True      USD  \n",
       "9      True      USD  \n",
       "10     True      USD  \n",
       "44472  True      USD  \n",
       "44473  True      USD  \n",
       "44474  True      USD  \n",
       "44475  True      USD  \n",
       "44476  True      USD  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame[dataFrame[\"Job Title\"]=='AML/CFT & Data Analyst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Plus</th>\n",
       "      <th>Currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGS</td>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Richardson, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGS</td>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Richardson, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Data quality</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGS</td>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Richardson, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Genetics</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGS</td>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Richardson, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGS</td>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Richardson, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>SAS</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SGS</td>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Richardson, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Statistics</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ocorian</td>\n",
       "      <td>AML/CFT &amp; Data Analyst</td>\n",
       "      <td>Eb√®ne, Mauritius</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Agile</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ocorian</td>\n",
       "      <td>AML/CFT &amp; Data Analyst</td>\n",
       "      <td>Eb√®ne, Mauritius</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Data management</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ocorian</td>\n",
       "      <td>AML/CFT &amp; Data Analyst</td>\n",
       "      <td>Eb√®ne, Mauritius</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Finance</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ocorian</td>\n",
       "      <td>AML/CFT &amp; Data Analyst</td>\n",
       "      <td>Eb√®ne, Mauritius</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Security</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Cricut</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>South Jordan, UT, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>not-specified</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>Agile</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cricut</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>South Jordan, UT, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>not-specified</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>Architecture</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Cricut</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>South Jordan, UT, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>not-specified</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>AWS</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cricut</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>South Jordan, UT, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>not-specified</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Cricut</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>South Jordan, UT, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>not-specified</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>Computer Vision</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Company                  Job Title                         Location  \\\n",
       "0       SGS      Clinical Data Analyst    Richardson, TX, United States   \n",
       "1       SGS      Clinical Data Analyst    Richardson, TX, United States   \n",
       "2       SGS      Clinical Data Analyst    Richardson, TX, United States   \n",
       "3       SGS      Clinical Data Analyst    Richardson, TX, United States   \n",
       "4       SGS      Clinical Data Analyst    Richardson, TX, United States   \n",
       "5       SGS      Clinical Data Analyst    Richardson, TX, United States   \n",
       "6   Ocorian     AML/CFT & Data Analyst                 Eb√®ne, Mauritius   \n",
       "7   Ocorian     AML/CFT & Data Analyst                 Eb√®ne, Mauritius   \n",
       "8   Ocorian     AML/CFT & Data Analyst                 Eb√®ne, Mauritius   \n",
       "9   Ocorian     AML/CFT & Data Analyst                 Eb√®ne, Mauritius   \n",
       "12   Cricut  Machine Learning Engineer  South Jordan, UT, United States   \n",
       "13   Cricut  Machine Learning Engineer  South Jordan, UT, United States   \n",
       "14   Cricut  Machine Learning Engineer  South Jordan, UT, United States   \n",
       "15   Cricut  Machine Learning Engineer  South Jordan, UT, United States   \n",
       "16   Cricut  Machine Learning Engineer  South Jordan, UT, United States   \n",
       "\n",
       "     Job Type Experience level   Salary Requirment of the company   \\\n",
       "0   Full Time      Entry-level  48000.0           Computer Science   \n",
       "1   Full Time      Entry-level  48000.0               Data quality   \n",
       "2   Full Time      Entry-level  48000.0                   Genetics   \n",
       "3   Full Time      Entry-level  48000.0                Mathematics   \n",
       "4   Full Time      Entry-level  48000.0                        SAS   \n",
       "5   Full Time      Entry-level  48000.0                 Statistics   \n",
       "6   Full Time      Entry-level  48000.0                      Agile   \n",
       "7   Full Time      Entry-level  48000.0            Data management   \n",
       "8   Full Time      Entry-level  48000.0                    Finance   \n",
       "9   Full Time      Entry-level  48000.0                   Security   \n",
       "12  Full Time    not-specified  90000.0                      Agile   \n",
       "13  Full Time    not-specified  90000.0               Architecture   \n",
       "14  Full Time    not-specified  90000.0                        AWS   \n",
       "15  Full Time    not-specified  90000.0           Computer Science   \n",
       "16  Full Time    not-specified  90000.0            Computer Vision   \n",
       "\n",
       "            Facilities  Plus Currency  \n",
       "0        no-Facilities  True      USD  \n",
       "1        no-Facilities  True      USD  \n",
       "2        no-Facilities  True      USD  \n",
       "3        no-Facilities  True      USD  \n",
       "4        no-Facilities  True      USD  \n",
       "5        no-Facilities  True      USD  \n",
       "6        no-Facilities  True      USD  \n",
       "7        no-Facilities  True      USD  \n",
       "8        no-Facilities  True      USD  \n",
       "9        no-Facilities  True      USD  \n",
       "12  Career development  True      USD  \n",
       "13  Career development  True      USD  \n",
       "14  Career development  True      USD  \n",
       "15  Career development  True      USD  \n",
       "16  Career development  True      USD  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_index = dataFrame[(dataFrame[\"Requirment of the company \"] == '') & (dataFrame['Facilities'] == 'no-Facilities')].index\n",
    "dataFrame.drop(df_index , inplace=True)\n",
    "dataFrame.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Plus</th>\n",
       "      <th>Currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Company, Job Title, Location, Job Type, Experience level, Salary, Requirment of the company , Facilities, Plus, Currency]\n",
       "Index: []"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame[(dataFrame[\"Requirment of the company \"] == '') & (dataFrame['Facilities'] == 'no-Facilities')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Youcode\\AppData\\Local\\Temp\\ipykernel_90516\\658576616.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dataFrame['Currency'][dataFrame[\"Salary\"] == 0]=dataFrame['Currency'].fillna('--')\n"
     ]
    }
   ],
   "source": [
    "dataFrame['Currency'][dataFrame[\"Salary\"] == 0]=dataFrame['Currency'].fillna('--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Plus</th>\n",
       "      <th>Currency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGS</td>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Richardson, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGS</td>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Richardson, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Data quality</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGS</td>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Richardson, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Genetics</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGS</td>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Richardson, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGS</td>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Richardson, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>SAS</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60325</th>\n",
       "      <td>ATB Financial</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Edmonton, Alberta, Canada</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>39000.0</td>\n",
       "      <td>Data Analytics</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60326</th>\n",
       "      <td>ATB Financial</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Edmonton, Alberta, Canada</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>39000.0</td>\n",
       "      <td>Data Mining</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60327</th>\n",
       "      <td>ATB Financial</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Edmonton, Alberta, Canada</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>39000.0</td>\n",
       "      <td>Economics</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60328</th>\n",
       "      <td>ATB Financial</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Edmonton, Alberta, Canada</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>39000.0</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60329</th>\n",
       "      <td>ATB Financial</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Edmonton, Alberta, Canada</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>39000.0</td>\n",
       "      <td>GCP</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55520 rows √ó 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Company              Job Title                       Location  \\\n",
       "0                SGS  Clinical Data Analyst  Richardson, TX, United States   \n",
       "1                SGS  Clinical Data Analyst  Richardson, TX, United States   \n",
       "2                SGS  Clinical Data Analyst  Richardson, TX, United States   \n",
       "3                SGS  Clinical Data Analyst  Richardson, TX, United States   \n",
       "4                SGS  Clinical Data Analyst  Richardson, TX, United States   \n",
       "...              ...                    ...                            ...   \n",
       "60325  ATB Financial         Data Scientist      Edmonton, Alberta, Canada   \n",
       "60326  ATB Financial         Data Scientist      Edmonton, Alberta, Canada   \n",
       "60327  ATB Financial         Data Scientist      Edmonton, Alberta, Canada   \n",
       "60328  ATB Financial         Data Scientist      Edmonton, Alberta, Canada   \n",
       "60329  ATB Financial         Data Scientist      Edmonton, Alberta, Canada   \n",
       "\n",
       "        Job Type Experience level   Salary Requirment of the company   \\\n",
       "0      Full Time      Entry-level  48000.0           Computer Science   \n",
       "1      Full Time      Entry-level  48000.0               Data quality   \n",
       "2      Full Time      Entry-level  48000.0                   Genetics   \n",
       "3      Full Time      Entry-level  48000.0                Mathematics   \n",
       "4      Full Time      Entry-level  48000.0                        SAS   \n",
       "...          ...              ...      ...                        ...   \n",
       "60325  Full Time      Entry-level  39000.0             Data Analytics   \n",
       "60326  Full Time      Entry-level  39000.0                Data Mining   \n",
       "60327  Full Time      Entry-level  39000.0                  Economics   \n",
       "60328  Full Time      Entry-level  39000.0                Engineering   \n",
       "60329  Full Time      Entry-level  39000.0                        GCP   \n",
       "\n",
       "          Facilities  Plus Currency  \n",
       "0      no-Facilities  True      USD  \n",
       "1      no-Facilities  True      USD  \n",
       "2      no-Facilities  True      USD  \n",
       "3      no-Facilities  True      USD  \n",
       "4      no-Facilities  True      USD  \n",
       "...              ...   ...      ...  \n",
       "60325  no-Facilities  True      USD  \n",
       "60326  no-Facilities  True      USD  \n",
       "60327  no-Facilities  True      USD  \n",
       "60328  no-Facilities  True      USD  \n",
       "60329  no-Facilities  True      USD  \n",
       "\n",
       "[55520 rows x 10 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame[dataFrame[\"Salary\"] >12000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame[['City_State_Location', 'Country_Location']] = dataFrame['Location'].str.split(\",\",n=1, expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Plus</th>\n",
       "      <th>Currency</th>\n",
       "      <th>City_State_Location</th>\n",
       "      <th>Country_Location</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2K</th>\n",
       "      <td>Senior Data Engineer, Platforms</td>\n",
       "      <td>United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>Airflow</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>United States</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2U</th>\n",
       "      <td>Data Engineer III</td>\n",
       "      <td>US-MD-Lanham//US-Remote</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>115000.0</td>\n",
       "      <td>AWS</td>\n",
       "      <td>401(k) matching</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>US-MD-Lanham//US-Remote</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3Cloud</th>\n",
       "      <td>QA Data Engineer</td>\n",
       "      <td>Remote in Philippines</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>not-specified</td>\n",
       "      <td>96000.0</td>\n",
       "      <td>Agile</td>\n",
       "      <td>Competitive pay</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Remote in Philippines</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3Pillar Global</th>\n",
       "      <td>Senior Software Engineer - Data analytics</td>\n",
       "      <td>India</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>49000.0</td>\n",
       "      <td>Agile</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6sense Insights, Inc.</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>India</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>APIs</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>India</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iTech Media</th>\n",
       "      <td>Commercial Data Analyst</td>\n",
       "      <td>London or Remote UK</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>92000.0</td>\n",
       "      <td>APIs</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>London or Remote UK</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>komoot</th>\n",
       "      <td>Senior Analytics Engineer</td>\n",
       "      <td>Germany - Remote</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>110000.0</td>\n",
       "      <td>Airflow</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Germany - Remote</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>myAgro</th>\n",
       "      <td>Data Analytics Manager</td>\n",
       "      <td>Remote</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>not-specified</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>Business Analytics</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Remote</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>takealot.com</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Cape Town</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>not-specified</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>AWS</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Cape Town</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiket.com</th>\n",
       "      <td>Data Engineer Intern</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Airflow</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>False</td>\n",
       "      <td>--</td>\n",
       "      <td>Jakarta</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>346 rows √ó 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       Job Title  \\\n",
       "Company                                                            \n",
       "2K                               Senior Data Engineer, Platforms   \n",
       "2U                                             Data Engineer III   \n",
       "3Cloud                                          QA Data Engineer   \n",
       "3Pillar Global         Senior Software Engineer - Data analytics   \n",
       "6sense Insights, Inc.                      Senior Data Scientist   \n",
       "...                                                          ...   \n",
       "iTech Media                              Commercial Data Analyst   \n",
       "komoot                                 Senior Analytics Engineer   \n",
       "myAgro                                    Data Analytics Manager   \n",
       "takealot.com                                        Data Analyst   \n",
       "tiket.com                                   Data Engineer Intern   \n",
       "\n",
       "                                      Location    Job Type Experience level  \\\n",
       "Company                                                                       \n",
       "2K                               United States   Full Time     Senior-level   \n",
       "2U                     US-MD-Lanham//US-Remote   Full Time     Senior-level   \n",
       "3Cloud                   Remote in Philippines   Full Time    not-specified   \n",
       "3Pillar Global                           India   Full Time     Senior-level   \n",
       "6sense Insights, Inc.                    India   Full Time     Senior-level   \n",
       "...                                        ...         ...              ...   \n",
       "iTech Media                London or Remote UK   Full Time     Senior-level   \n",
       "komoot                        Germany - Remote   Full Time     Senior-level   \n",
       "myAgro                                  Remote   Full Time    not-specified   \n",
       "takealot.com                         Cape Town   Full Time    not-specified   \n",
       "tiket.com                              Jakarta  Internship      Entry-level   \n",
       "\n",
       "                         Salary Requirment of the company   \\\n",
       "Company                                                      \n",
       "2K                     115000.0                    Airflow   \n",
       "2U                     115000.0                        AWS   \n",
       "3Cloud                  96000.0                      Agile   \n",
       "3Pillar Global          49000.0                      Agile   \n",
       "6sense Insights, Inc.  129000.0                       APIs   \n",
       "...                         ...                        ...   \n",
       "iTech Media             92000.0                       APIs   \n",
       "komoot                 110000.0                    Airflow   \n",
       "myAgro                 120000.0         Business Analytics   \n",
       "takealot.com            80000.0                        AWS   \n",
       "tiket.com                   0.0                    Airflow   \n",
       "\n",
       "                               Facilities   Plus Currency  \\\n",
       "Company                                                     \n",
       "2K                     Career development   True      USD   \n",
       "2U                        401(k) matching   True      USD   \n",
       "3Cloud                    Competitive pay   True      USD   \n",
       "3Pillar Global         Career development   True      USD   \n",
       "6sense Insights, Inc.  Career development   True      USD   \n",
       "...                                   ...    ...      ...   \n",
       "iTech Media            Career development   True      USD   \n",
       "komoot                 Career development   True      USD   \n",
       "myAgro                 Career development   True      USD   \n",
       "takealot.com           Career development   True      USD   \n",
       "tiket.com                   no-Facilities  False       --   \n",
       "\n",
       "                           City_State_Location Country_Location  \n",
       "Company                                                          \n",
       "2K                               United States             None  \n",
       "2U                     US-MD-Lanham//US-Remote             None  \n",
       "3Cloud                   Remote in Philippines             None  \n",
       "3Pillar Global                           India             None  \n",
       "6sense Insights, Inc.                    India             None  \n",
       "...                                        ...              ...  \n",
       "iTech Media                London or Remote UK             None  \n",
       "komoot                        Germany - Remote             None  \n",
       "myAgro                                  Remote             None  \n",
       "takealot.com                         Cape Town             None  \n",
       "tiket.com                              Jakarta             None  \n",
       "\n",
       "[346 rows x 11 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locationgrop=dataFrame[(dataFrame['Country_Location'].isna()) | (dataFrame['City_State_Location'].isna())].groupby('Company')\n",
    "locationgrop.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pycountry\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canada\n"
     ]
    }
   ],
   "source": [
    "import pycountry\n",
    "text = dataFrame[\"Location\"][60325]\n",
    "for country in pycountry.countries:\n",
    "    if country.name in text:\n",
    "        print(country.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Edmonton, Alberta, Canada'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame[\"Location\"][60325]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Job Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fuzzywuzzyNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n"
     ]
    }
   ],
   "source": [
    "pip install fuzzywuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def find_job_title(text):\n",
    "    data_scientist_job_titles = [\n",
    "        \"Data Scientist\", \"Machine Learning Engineer\", \"Data Analyst\", \n",
    "        \"Data Engineer\", \"Business Intelligence Analyst\", \"Data Science Lead\", \n",
    "        \"Data Modeler\", \"Data Visualization Analyst\", \"Senior Data Scientist\", \n",
    "        \"Data Product Owner\", \"Data Scientist Intern\", \"Data Management Consultant\", \n",
    "        \"Junior Data Scientist\", \"Lead Data Scientist\", \"Staff Data Scientist\", \n",
    "        \"Principal Data Scientist\", \"Data Scientist II\", \"Data Science Manager\", \n",
    "        \"Data Science Analyst\", \"Data Science Intern\", \"Associate Data Scientist\", \n",
    "        \"Big Data Engineer\", \"Senior Machine Learning Engineer\", \"Senior Data Engineer\",\n",
    "        \"Senior Business Intelligence Analyst\", \"Machine Learning Research Engineer\",\n",
    "        \"Artificial Intelligence Lead\", \"Junior Data Analyst\", \"Senior Data Analyst\"\n",
    "        # Add more job titles as needed\n",
    "    ]\n",
    "    \n",
    "    best_matched_title = None\n",
    "    best_matched_score = 0\n",
    "    \n",
    "    for job_title in data_scientist_job_titles:\n",
    "        score = fuzz.WRatio(text, job_title)\n",
    "        if score > best_matched_score:\n",
    "            best_matched_score = score\n",
    "            best_matched_title = job_title\n",
    "            \n",
    "    if best_matched_score >= 90:\n",
    "        return best_matched_title\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "df['Job Title'] = df['Job Title'].apply(find_job_title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "                                              0.0/981.5 kB ? eta -:--:--\n",
      "     -                                     30.7/981.5 kB 660.6 kB/s eta 0:00:02\n",
      "     ----                                   122.9/981.5 kB 1.4 MB/s eta 0:00:01\n",
      "     -------                                194.6/981.5 kB 1.5 MB/s eta 0:00:01\n",
      "     -----------                            307.2/981.5 kB 1.7 MB/s eta 0:00:01\n",
      "     --------------                         368.6/981.5 kB 1.5 MB/s eta 0:00:01\n",
      "     ----------------                       430.1/981.5 kB 1.6 MB/s eta 0:00:01\n",
      "     -------------------                    512.0/981.5 kB 1.7 MB/s eta 0:00:01\n",
      "     ----------------------                 573.4/981.5 kB 1.6 MB/s eta 0:00:01\n",
      "     ----------------------                 593.9/981.5 kB 1.6 MB/s eta 0:00:01\n",
      "     --------------------------             675.8/981.5 kB 1.5 MB/s eta 0:00:01\n",
      "     ----------------------------           737.3/981.5 kB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------        809.0/981.5 kB 1.6 MB/s eta 0:00:01\n",
      "     --------------------------------       839.7/981.5 kB 1.4 MB/s eta 0:00:01\n",
      "     ----------------------------------     901.1/981.5 kB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------  972.8/981.5 kB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------  972.8/981.5 kB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 981.5/981.5 kB 1.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six in c:\\users\\lenovo\\miniconda3\\envs\\scraping_brief\\lib\\site-packages (from langdetect) (1.16.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993253 sha256=f9a57e952a53cfde3ea78ab445f82db245534932f45a871dd3878ced1ea135dd\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\0a\\f2\\b2\\e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:03,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:06,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:08,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:09,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:10,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:11,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23it [00:12,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25it [00:13,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [00:15,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37it [00:19,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [00:22,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [00:23,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53it [00:25,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [00:26,  3.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [00:27,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [00:33,  3.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "73it [00:34,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:40,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "85it [00:40,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "87it [00:41,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90it [00:42,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "98it [00:46,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "108it [00:49,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112it [00:51,  3.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "118it [00:54,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "129it [00:57,  5.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "132it [00:58,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "137it [01:01,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "140it [01:01,  2.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "146it [01:03,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "149it [01:05,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "153it [01:06,  2.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "158it [01:07,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "159it [01:07,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166it [01:09,  5.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167it [01:09,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "170it [01:10,  3.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "178it [01:14,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "179it [01:14,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "183it [01:16,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "188it [01:17,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "194it [01:19,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "196it [01:20,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "204it [01:21,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "208it [01:21, 11.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "213it [01:21,  9.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "215it [01:22,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "217it [01:23,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "222it [01:24,  4.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [01:25,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "227it [01:26,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "230it [01:26,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "233it [01:27,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "238it [01:31,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "241it [01:32,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "251it [01:37,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "255it [01:39,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "258it [01:40,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "260it [01:40,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "265it [01:41,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "267it [01:41,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "269it [01:42,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "273it [01:43,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "274it [01:43,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "279it [01:45,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "285it [01:47,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "286it [01:48,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "289it [01:49,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "292it [01:50,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "299it [01:53,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "302it [01:54,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "304it [01:55,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "307it [01:56,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [01:57,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "317it [01:59,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "326it [02:03,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "328it [02:03,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "334it [02:06,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "341it [02:07,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "348it [02:10,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "353it [02:13,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "357it [02:14,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "359it [02:15,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "364it [02:16,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "365it [02:17,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "368it [02:17,  3.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "370it [02:18,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "373it [02:19,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "376it [02:21,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "379it [02:22,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "383it [02:23,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "388it [02:25,  3.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "389it [02:25,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "395it [02:26,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "397it [02:27,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "398it [02:28,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "404it [02:31,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "406it [02:32,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "410it [02:33,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "411it [02:33,  3.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "414it [02:34,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "419it [02:36,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "422it [02:37,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "425it [02:38,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "429it [02:40,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "433it [02:40,  4.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "435it [02:41,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "442it [02:43,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "444it [02:43,  3.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "446it [02:44,  3.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "448it [02:44,  3.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "457it [02:47,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "465it [02:49,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "474it [02:52,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "483it [02:53,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "487it [02:54,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "490it [02:56,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "492it [02:57,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "495it [02:57,  3.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "499it [02:58,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "504it [02:59,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "508it [03:00,  5.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "509it [03:00,  3.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "511it [03:01,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "514it [03:02,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "516it [03:03,  2.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "520it [03:04,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "521it [03:05,  2.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "528it [03:07,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "534it [03:10,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "538it [03:12,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "541it [03:12,  3.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "545it [03:14,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "548it [03:15,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "551it [03:17,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "559it [03:18,  5.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "564it [03:20,  3.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "565it [03:21,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "573it [03:25,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "575it [03:26,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "578it [03:26,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "581it [03:27,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "583it [03:27,  3.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "585it [03:28,  3.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "588it [03:29,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "591it [03:30,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "596it [03:33,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "599it [03:34,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "603it [03:36,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "611it [03:38,  3.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "613it [03:39,  3.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "614it [03:39,  3.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "617it [03:41,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "621it [03:42,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "624it [03:44,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "631it [03:47,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "634it [03:48,  2.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "640it [03:50,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "642it [03:51,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "646it [03:52,  4.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "650it [03:53,  5.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "654it [03:53,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "657it [03:54,  4.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "659it [03:55,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "663it [03:56,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "668it [03:57,  4.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "671it [03:58,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "677it [04:00,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "683it [04:02,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "687it [04:04,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "694it [04:06,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "699it [04:08,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "701it [04:09,  3.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "702it [04:10,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "705it [04:10,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "708it [04:11,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "710it [04:11,  4.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "714it [04:12,  3.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "719it [04:13,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "720it [04:13,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "723it [04:14,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "729it [04:15,  5.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "730it [04:15,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "733it [04:16,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "736it [04:17,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "738it [04:17,  3.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "742it [04:18,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "748it [04:20,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "749it [04:20,  3.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "751it [04:21,  3.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "753it [04:21,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "756it [04:22,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "760it [04:22,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "761it [04:23,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "764it [04:24,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "767it [04:24,  4.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "778it [04:30,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "780it [04:30,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "785it [04:31,  4.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "787it [04:34,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "795it [04:37,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n",
      "Skipping translation for TEXT as it is already in English.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "797it [04:37,  2.87it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'description' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39m# i comment it just to see what is hapning\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(text, \u001b[39mfloat\u001b[39m):\n\u001b[1;32m---> 24\u001b[0m             text \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(description)\n\u001b[0;32m     26\u001b[0m     \u001b[39mif\u001b[39;00m text \u001b[39mand\u001b[39;00m text\u001b[39m.\u001b[39mstrip():  \u001b[39m# Skip empty or whitespace-only descriptions\u001b[39;00m\n\u001b[0;32m     28\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_english(text):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'description' is not defined"
     ]
    }
   ],
   "source": [
    "from mtranslate import translate\n",
    "import langdetect\n",
    "from tqdm import tqdm  \n",
    "\n",
    "\n",
    "def translate_with_retry(text):\n",
    "    return translate(str(text), 'en')\n",
    "\n",
    "def is_english(text):\n",
    "    try:\n",
    "       #remove imojis befor virifying language\n",
    "        lang = langdetect.detect(text)\n",
    "        return lang == 'en'\n",
    "    except langdetect.LangDetectException:\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "translated_lines = []\n",
    "for index, line in tqdm(dataFrame.iterrows()):\n",
    "    text =line['Job Title']\n",
    "# i comment it just to see what is hapning\n",
    "    if isinstance(text, float):\n",
    "            text = str(description)\n",
    "\n",
    "    if text and text.strip():  # Skip empty or whitespace-only descriptions\n",
    "        \n",
    "        if not is_english(text):\n",
    "            try:\n",
    "                    # Translate the non-English description with retry logic\n",
    "                translated_text = translate_with_retry(text)\n",
    "                line['Job Title'] = translated_text\n",
    "            except Exception as e:\n",
    "                print(f\"Translation failed for TEXT: {text}. Error: {str(e)}\")\n",
    "        else:\n",
    "            print(\"Skipping translation for TEXT as it is already in English.\")\n",
    "    else:\n",
    "        print(\"Skipping translation for empty or whitespace-only TEXT.\")\n",
    "\n",
    "    translated_lines.append(line)\n",
    "description_trn={'Job Title':translated_lines}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_dataFrame=pd.DataFrame(translated_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_dataFrame.to_csv('translated_dataFrame.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clinical data analyst',\n",
       " 'aml/cft & data analyst',\n",
       " 'machine learning engineer',\n",
       " 'application developer & data analyst',\n",
       " 'data engineer full time (public sector) usa',\n",
       " 'sr staff data scientist - atg',\n",
       " 'vendor management and data quality lead',\n",
       " 'intern (business intelligence service support)',\n",
       " 'summer 2023 data engineering intern',\n",
       " 'principal cloud data engineer (prisma access)',\n",
       " 'data scientist (te-crg-glo-2023-19-grap)',\n",
       " 'data analyst - revenue optimizer',\n",
       " 'graduate power bi developer',\n",
       " 'sap consultant - product data management',\n",
       " 'premaster programm - data analytics and visualization',\n",
       " 'staff data scientist - atg',\n",
       " 'machine learning engineer',\n",
       " 'senior data analyst - sales',\n",
       " 'bi analyst',\n",
       " 'data scientist | insights (f/m/d) - ger, uk, nl, pl',\n",
       " 'senior data analyst (remote within emea)',\n",
       " 'senior data engineer (evergreen)',\n",
       " 'data management scrum master',\n",
       " 'rotational development program - artificial intelligence and machine learning trainee',\n",
       " 'data engineer scientist',\n",
       " 'data scientist (elasticsearch)',\n",
       " 'data engineer f/h',\n",
       " 'bi developer',\n",
       " 'data scientist - fraud risk',\n",
       " 'quintoandar - senior data analyst',\n",
       " 'ml research engineer',\n",
       " 'principal engineer, data project management',\n",
       " 'senior data engineer',\n",
       " '(senior) digital analytics engineer',\n",
       " 'senior software engineer (data pipeline)',\n",
       " 'senior data scientist',\n",
       " 'data science lead (hybrid)',\n",
       " 'business intelligence analyst',\n",
       " 'lead business intelligence analyst',\n",
       " 'senior data scientist',\n",
       " 'sr data engineer',\n",
       " 'data modeler',\n",
       " 'data engineer',\n",
       " 'vp, actuarial modeling and data management',\n",
       " 'junior data science engineer (m/w/x)',\n",
       " 'healthcare data analyst',\n",
       " 'data scientist',\n",
       " 'data analyst | marketing or sales (f/m/d) - ger, uk, nl, pl',\n",
       " 'business intelligence expert',\n",
       " 'data engineer',\n",
       " 'senior data analyst',\n",
       " 'principle mlops engineer',\n",
       " 'senior data scientist',\n",
       " 'machine learning research engineer, generative ai',\n",
       " 'data analyst - product innovation',\n",
       " 'lead data scientist',\n",
       " 'data product owner',\n",
       " 'become analyst jr -',\n",
       " 'html developer',\n",
       " 'business intelligence developer',\n",
       " 'data scientist, marketing analytics',\n",
       " 'senior manager - aml/cft & data analyst',\n",
       " 'senior data visualization analyst',\n",
       " 'senior data engineer (remote)',\n",
       " 'customer data engineer',\n",
       " 'data engineer- data platform',\n",
       " 'digital marketing lead (zibraai)',\n",
       " 'staff data scientist - marketing',\n",
       " 'senior sales business intelligence manager',\n",
       " 'data analyst, customer experience',\n",
       " 'machine learning engineer',\n",
       " 'etas test lead - autonomous driving solutions',\n",
       " 'sr. data engineer',\n",
       " 'specialist solutions architect - mlops',\n",
       " 'data scientist, terminal',\n",
       " 'data analyst intern',\n",
       " 'react native engineer - mobile (dubai)',\n",
       " 'artificial intelligence lead | kpmg futures',\n",
       " 'jr. crm data quality specialist',\n",
       " 'senior data analyst',\n",
       " 'data management consultant banking (f/d/m) financial services data platform fsdm',\n",
       " 'director, artificial intelligence (ai)',\n",
       " 'intermediate bi developer',\n",
       " 'senior business intelligence analyst',\n",
       " 'data analyst',\n",
       " 'staff machine learning engineer',\n",
       " 'data analyst (remote)',\n",
       " 'lead applied data scientist (experience with media mix modeling)',\n",
       " 'data engineer i',\n",
       " 'cloud database analyst',\n",
       " 'senior machine learning engineer',\n",
       " 'junior data analyst',\n",
       " 'financial data analyst',\n",
       " 'data engineer',\n",
       " 'senior consultant in data science',\n",
       " 'staff clinical data manager # 3073',\n",
       " 'hr data analyst',\n",
       " 'consultant in data science',\n",
       " 'machine learning engineer',\n",
       " 'staff engineer, data platform',\n",
       " 'staff engineer, data platform',\n",
       " 'data engineer',\n",
       " 'data engineer',\n",
       " 'senior data scientist, marketing analytics',\n",
       " 'director, iva and ai solutions - professional services practice lead',\n",
       " 'lead data analyst(marketing/growth analytics)',\n",
       " 'data analyst, service analytics',\n",
       " 'amazon robotics - hardware engineer co-op (july-december 2023), amazon robotics',\n",
       " 'senior/staff data engineer',\n",
       " 'data engineer',\n",
       " 'data product manager',\n",
       " 'fsa (fintech) - quantitative machine learning specialist & software developer',\n",
       " 'data engineer analyst',\n",
       " 'software engineer (data pipeline)',\n",
       " 'senior data scientist',\n",
       " 'associate data scientist',\n",
       " 'data engineering analyst',\n",
       " 'talan consulting \\x96 consultant senior/manager \\x96 data strategy (h/f)',\n",
       " 'enterprise data architect - 6 month contract',\n",
       " 'data engineer ii',\n",
       " 'data scientist/machine learning engineer',\n",
       " 'data engineer',\n",
       " 'data analyst',\n",
       " 'senior data scientist, product',\n",
       " 'senior technical support engineer, dataset',\n",
       " 'finance business intelligence , operations finance',\n",
       " 'staff machine learning modeler, financial crimes',\n",
       " 'machine learning engineer',\n",
       " 'senior business intelligence analyst',\n",
       " 'data scientist',\n",
       " 'data engineer - music',\n",
       " 'data manager',\n",
       " 'machine learning engineer',\n",
       " 'salesforce administrator/data specialist',\n",
       " 'data engineer (starlink)',\n",
       " 'data engineer',\n",
       " 'data engineer confirm√© bi - big data',\n",
       " 'director, spark technical solutions',\n",
       " 'data engineer',\n",
       " 'middle data engineer (healthcare domain)',\n",
       " 'senior data analyst (pricing)',\n",
       " 'people analytics data visualization senior associate (open to remote)',\n",
       " 'power bi developer - m/f',\n",
       " 'data engineer',\n",
       " 'product manager - experts & artificial intelligence',\n",
       " 'group manager data analytics india',\n",
       " 'data analyst',\n",
       " 'senior data engineer',\n",
       " 'vice president director, data scientist',\n",
       " 'business intelligence analyst, aws cloud logistics',\n",
       " 'scientist/senior scientist, machine learning',\n",
       " 'principal site reliability engineer, datastores (hybrid)',\n",
       " 'data scientist',\n",
       " 'machine learning manager (systems)',\n",
       " 'consultant data engineer',\n",
       " 'machine learning engineer l3',\n",
       " 'data analyst coches.net',\n",
       " 'senior product marketing manager, conversational intelligence & ai products',\n",
       " 'graduate data analyst',\n",
       " 'analytics engineer',\n",
       " 'specialist solutions architect - data engineering (public sector)',\n",
       " 'senior machine learning engineer',\n",
       " 'data scientist',\n",
       " 'senior data quality assurance specialist',\n",
       " 'senior site reliability engineer, datastores (hybrid)',\n",
       " 'customer success junior ml engineer, onboarding specialist',\n",
       " 'senior data science engineer',\n",
       " 'digital analytics engineer',\n",
       " 'senior big data engineer',\n",
       " 'senior data scientist, marketing',\n",
       " 'analytics engineer intern',\n",
       " 'master data team manager',\n",
       " 'senior data engineer, enterprise engineering',\n",
       " 'data operations associate',\n",
       " 'data analyst',\n",
       " 'staff ml engineer (8627)',\n",
       " 'specialist architect : big data',\n",
       " 'research engineer in multi agent path finding for mobile robots (f/m/div.)',\n",
       " 'product marketing manager, data engineering',\n",
       " 'machine learning engineer',\n",
       " 'cv/ml engineer for 3d virtual humans - remote europe',\n",
       " 'senior data engineer - data bricks',\n",
       " 'director ai science',\n",
       " 'researcher- business intelligence',\n",
       " 'machine learning research scientist',\n",
       " 'staff database reliability engineer, datastores',\n",
       " 'senior data scientist - viator, london, oxford, uk remote',\n",
       " 'data engineer',\n",
       " 'data analyst (bangkok based, relocation provided)',\n",
       " 'associate ai/ml engineer',\n",
       " 'azure data architect',\n",
       " 'senior applied data scientist',\n",
       " 'senior scientist, decision sciences',\n",
       " 'data scientist',\n",
       " 'data operations & insights manager',\n",
       " 'principal ml engineer - ai platform',\n",
       " 'principal product marketing manager, ai & machine learning',\n",
       " 'technical support specialist (robotics) - eu - remote',\n",
       " 'data architect',\n",
       " 'operations data analyst (tableau)',\n",
       " 'head of applied ai/ml',\n",
       " 'data analytics engineer',\n",
       " 'software engineer - autonomy metrics',\n",
       " 'product manager- data visualization & analytics',\n",
       " 'data science in product design engineering',\n",
       " 'senior director of product - machine learning',\n",
       " 'senior data analyst (bangkok based, relocation provided)',\n",
       " 'operations planner data management technician',\n",
       " 'senior associate data engineering',\n",
       " 'data operations client onboarding',\n",
       " 'machine learning research scientist - reinforcement learning',\n",
       " 'machine learning engineer, generative ai',\n",
       " 'machine learning engineer',\n",
       " 'data management internship',\n",
       " 'sr big data engineer',\n",
       " 'consulting - robotics process automation (rpa) developer',\n",
       " 'data engineer',\n",
       " 'data analyst intern',\n",
       " 'data engineer',\n",
       " 'data analyst',\n",
       " 'data engineer with databricks - empower (remote/costa rica-based)',\n",
       " 'databricks and scala engineer geospatial',\n",
       " 'software engineer, data platform',\n",
       " 'senior manager data engineering',\n",
       " 'senior data engineer (p3949).',\n",
       " 'junior data engineer customer analytics',\n",
       " 'chief engineer, autonomy (r2020)',\n",
       " 'senior research data analyst',\n",
       " 'sport data operator',\n",
       " 'associate director | artificial intelligence lead | kpmg futures',\n",
       " 'research scientist',\n",
       " 'data engineering manager',\n",
       " 'principal engineer - data integrations',\n",
       " 'python engineer - machine learning specialist (remote)',\n",
       " 'senior applied scientist - document intelligence',\n",
       " 'data analyst, go live',\n",
       " 'senior data scientist (m/f)',\n",
       " 'data engineer',\n",
       " 'researcher/senior researcher \\x96 natural language processing and text analytics',\n",
       " 'data scientist',\n",
       " 'data scientist',\n",
       " 'data analyst (customer service industry, mandarin support)',\n",
       " 'manager data strategy',\n",
       " 'business partner, data analysis',\n",
       " 'data engineer - remote',\n",
       " 'bi analyst',\n",
       " 'data analyst',\n",
       " 'data engineer',\n",
       " 'marketing data analyst',\n",
       " 'post-doctoral fellow or associate - agronomy data scientist',\n",
       " 'sr. data scientist',\n",
       " 'researcher- computer vision',\n",
       " 'data science lead',\n",
       " 'senior data engineer',\n",
       " 'senior data scientist, product analytics',\n",
       " 'software engineer - machine learning, granica screen',\n",
       " 'data engineer - T√ºrkiye',\n",
       " 'senior data scientist',\n",
       " 'machine learning engineer',\n",
       " 'sde-iii, data engineering',\n",
       " 'oracle data modeler / pl/sql - data warehouse',\n",
       " 'product data specialist (hw)',\n",
       " 'sparkcognition director of accounting - controller',\n",
       " 'senior machine learning scientist (usa remote)',\n",
       " 'senior data scientist (p171).',\n",
       " 'cloud data analyst engineer (finops)',\n",
       " 'data ops engineer',\n",
       " 'robotic research engineer - mechatronics',\n",
       " 'manager - applied data scientist',\n",
       " '??¬∑????/business intelligence engineer, japan operations finance',\n",
       " 'senior data engineer - (christchurch)',\n",
       " 'senior software engineer - data architecture skills',\n",
       " 'bi developer, analytics',\n",
       " 'business intelligence oversight (media/communication focus)',\n",
       " 'senior manager, perception deep learning',\n",
       " 'sme consultant for data analytics',\n",
       " 'senior data strategist',\n",
       " 'data scientist',\n",
       " 'data engineer',\n",
       " 'data analyst (oslo-based)',\n",
       " 'senior ai engineer',\n",
       " 'sql data engineers',\n",
       " 'subsurface data manager',\n",
       " 'senior data analyst with python sql - ms- bangalore',\n",
       " 'data analyst supply chain management (f/m/d)',\n",
       " 'senior data quality developer',\n",
       " 'remote intermediate fullstack engineer (ai team)',\n",
       " 'ios engineer (dubai)',\n",
       " 'business intelligence data strategist',\n",
       " 'data engineer customer analytics',\n",
       " 'Sr. bi Analyst',\n",
       " 'data scientist generalist',\n",
       " 'business intelligence analyst - sales operations',\n",
       " 'senior developer - data engineer (aws/python/node)',\n",
       " 'data engineer',\n",
       " 'senior data scientist: nlp',\n",
       " 'data analyst (allegro pay)',\n",
       " 'data analyst (dea)',\n",
       " 'senior data engineer',\n",
       " 'ai research engineer',\n",
       " 'data analyst',\n",
       " 'data engineer',\n",
       " 'ai research scientist',\n",
       " 'html developer',\n",
       " 'manager, business operations - diagnostic imaging and laboratory',\n",
       " 'data engineer',\n",
       " 'data science consultant',\n",
       " 'customer master data analyst',\n",
       " 'senior data quality engineer',\n",
       " 'senior data analyst - hybrid',\n",
       " 'computer vision researcher',\n",
       " 'machine learning engineer',\n",
       " 'research scientist - machine learning and algorithms',\n",
       " 'senior applied scientist',\n",
       " 'tableau/bi developer',\n",
       " 'data engineer',\n",
       " 'data scientist (real-time ops)',\n",
       " 'data science/ analytics intern- long term',\n",
       " 'senior data engineer',\n",
       " 'master data management plants (f/m/div.)',\n",
       " 'coordinator of data operations',\n",
       " 'data science team lead',\n",
       " 'ai programmer vr (ue)',\n",
       " 'data engineer (python) - payments',\n",
       " 'master data management plants (f/m/div.) (salary: ~81.000 eur p.a.*)',\n",
       " 'data analyst pleno',\n",
       " 'research engineer pem electrolyzer (f/m/div.)',\n",
       " 'consulting - data engineer',\n",
       " 'data analyst intern - product analytics',\n",
       " 'system reliability engineer (big data)',\n",
       " 'senior data analyst',\n",
       " 'azure data architect',\n",
       " 'enterprise data architect',\n",
       " 'ttgp fleet data manager/senior jico',\n",
       " 'staff machine learning engineer',\n",
       " 'senior software engineer - data analytics',\n",
       " 'staff technical product manager, ai platform and solutions',\n",
       " 'big data engineer - pyspark',\n",
       " 'consultant / sr consultant - qa data engineer',\n",
       " 'computational biologist, translational science - location flexible',\n",
       " 'lead software engineer, ml infrastructure',\n",
       " 'senior insurance data scientist',\n",
       " 'principal engineer, data systems',\n",
       " 'clinical data manager',\n",
       " 'data analyst i - fraud',\n",
       " 'senior data scientist, operations',\n",
       " 'software engineer - data platform (python, cloud, big data)',\n",
       " 'senior cloud data analyst engineer (finops)',\n",
       " 'data engineer - bulgaria',\n",
       " 'power bi developer',\n",
       " 'consultant, data analytics',\n",
       " 'junior mlops - intern',\n",
       " 'senior data analyst',\n",
       " 'business intelligence internship (summer 23/24)',\n",
       " 'business analyst (tech/ai)',\n",
       " 'data scientist',\n",
       " 'senior applied scientist, amazon',\n",
       " 'specialist solutions architect - data engineering (financial services)',\n",
       " 'data scientist ebike systems (f/m/div.)',\n",
       " 'senior machine learning engineer',\n",
       " 'senior data engineer',\n",
       " 'graduate data scientist',\n",
       " 'data engineer',\n",
       " 'robotics engineer, sensors',\n",
       " 'contract: data infrastructure engineer',\n",
       " 'ai/ml modeling, simulation and analysis engineer (senior)',\n",
       " 'analytics engineer',\n",
       " 'cloud data engineer',\n",
       " 'head of data science, analytics and bi',\n",
       " 'clinical data reporter',\n",
       " 'staff+ machine learning engineer - generative ai',\n",
       " 'junior data analyst',\n",
       " 'internal audit specialist - data analytics',\n",
       " 'engineering team lead, imaging tech',\n",
       " 'senior ml engineer - nlp',\n",
       " 'data analyst (aberdeen-based)',\n",
       " 'research scientist',\n",
       " 'principal engineer, data and control systems',\n",
       " 'data scientist (pricing)',\n",
       " 'head of aml operations (m/f/d)',\n",
       " 'data engineer - 14072',\n",
       " 'senior data engineer',\n",
       " 'senior data engineer',\n",
       " 'data analyst (reporting and insights)',\n",
       " 'sr. manager (ai/ml)',\n",
       " 'data scientist, decisions - rider',\n",
       " 'data architect - sme',\n",
       " 'senior sw engineer (machine learning)',\n",
       " 'data engineer',\n",
       " '(global) senior research scientist',\n",
       " 'staff data scientist, model risk management',\n",
       " 'senior data analyst',\n",
       " 'graduate imaging geophysicist',\n",
       " 'architecte plateforme big data / devops - f/h',\n",
       " 'analytics engineer',\n",
       " 'data engineer',\n",
       " 'data analyst - retention',\n",
       " 'data analyst',\n",
       " 'lead machine learning engineer',\n",
       " 'data developer',\n",
       " 'data analyst - digital marketing (all genders)',\n",
       " 'android engineer (dubai)',\n",
       " 'data specialist - governance',\n",
       " 'senior robotics process automation developer',\n",
       " 'technical product manager, data engineering',\n",
       " 'sr. data developer (remote), experian consumer services',\n",
       " 'senior data analyst with python sql - bangalore',\n",
       " 'manager, measurement innovation & data science',\n",
       " 'data analytics engineer',\n",
       " 'cloud data architect',\n",
       " 'business intelligence engineering manager',\n",
       " 'senior business intelligence analyst',\n",
       " 'data manager',\n",
       " 'devops engineer (dubai)',\n",
       " 'data analytics internship (summer 23/24)',\n",
       " 'confirmed data analyst - data pro supply',\n",
       " 'senior data analyst',\n",
       " 'senior machine learning engineer (modeling)',\n",
       " 'stage: robotics',\n",
       " 'data scientist / data analyst',\n",
       " 'senior product data analyst (m/f) on permanent contract in paris',\n",
       " 'data analyst - stage',\n",
       " 'senior analytics engineer',\n",
       " 'data analyst intern',\n",
       " 'sr. software engineer, data engineering',\n",
       " 'senior machine learning engineer i',\n",
       " 'data engineer sr.software engineer dx',\n",
       " 'senior staff data engineer',\n",
       " 'data engineer',\n",
       " 'natural language processing intern',\n",
       " 'senior data engineers',\n",
       " 'coordinateur projets genotypage data analyse (h/f)',\n",
       " 'machine learning & software engineer, infrastructure - us remote',\n",
       " 'customer-facing deep learning solutions architect',\n",
       " 'data engineering manager - allegro pay',\n",
       " 'senior business intelligence developer (database architect & etl developer)',\n",
       " 'data analyst',\n",
       " 'technical mentor (independent contractor) - data engineering nanodegree (us timezone)',\n",
       " 'data architect',\n",
       " 'data analyst, business optimisation',\n",
       " 'machine learning force fields scientist (materials science)',\n",
       " 'principal machine learning engineer - atg',\n",
       " 'senior associate data sciences',\n",
       " 'senior data engineer (all genders) ai',\n",
       " 'intermediate / senior fullstack engineer (ai team)',\n",
       " 'data quality analyst - stage',\n",
       " 'senior software engineer - ai/ml team (.net + python)',\n",
       " 'software engineer, data platform, data management',\n",
       " 'senior machine learning engineer (modeling), financial crimes technology',\n",
       " 'research analyst',\n",
       " 'backend / data engineers ii, cerebro',\n",
       " 'junior data manager',\n",
       " 'data infrastructure engineer',\n",
       " 'senior data scientist',\n",
       " 'backend engineer (dubai)',\n",
       " 'senior software engineer i, machine learning, retrieval sciences',\n",
       " 'sr. staff machine learning engineer',\n",
       " 'staff systems engineer, autonomy & simulation',\n",
       " '[??-??&???] senior, data analyst (channel analytics)',\n",
       " 'senior machine learning expert (on-site, brussels / belgium)',\n",
       " 'specialist, business intelligence / specialist, business intelligence',\n",
       " 'senior product manager | api & data products',\n",
       " 'senior data analyst',\n",
       " 'senior analyst, data science and analytics',\n",
       " 'senior product manager - data management & search',\n",
       " 'accounting professor- data analytics/ais- 90k+ salary',\n",
       " 'senior data engineer - healthgrades',\n",
       " 'sr applied data scientist',\n",
       " 'business intelligence engineer',\n",
       " 'assistant mgr - data sciences',\n",
       " 'data scientist',\n",
       " 'data analyst - end-of-studies internship - paris 2nd',\n",
       " 'trading bi developer',\n",
       " 'data analytics intern - le cubs 2023',\n",
       " 'product data analyst -  f/h',\n",
       " 'data scientist (crypto)',\n",
       " '[job- 10639] senior data engineer developer, brazil',\n",
       " 'business intelligence associate',\n",
       " 'analyst, reporting and business intelligence',\n",
       " 'data science software engineer',\n",
       " 'product owner with tableau/power bi(6 to 10 years)',\n",
       " 'machine learning & software engineer, infrastructure - emea remote',\n",
       " 'sr ai solution developer (servicenow developer)',\n",
       " 'data integrations engineer',\n",
       " 'data scientist',\n",
       " 'data engineer ii',\n",
       " 'lead software engineer - ai/ml team (.net + python)',\n",
       " 'transportation data analyst coordinator',\n",
       " 'senior applied data scientist (all genders) ai',\n",
       " 'power bi analyst',\n",
       " 'senior machine learning engineer',\n",
       " 'senior cloud devops engineer (data & ai) bei ebike systems (w/m/div.)',\n",
       " 'business intelligence analyst i',\n",
       " 'power bi data visualization analyst',\n",
       " 'data engineer',\n",
       " 'data analyst (ceo office)',\n",
       " 'senior data science analyst- model validation',\n",
       " 'machine learning engineer',\n",
       " 'sr. revenue operations specialist - data analytics',\n",
       " 'phd position - neuro-symbolic ai for scene understanding in autonomous driving',\n",
       " 'staff data analyst, product analytics',\n",
       " 'senior product manager, large language model',\n",
       " 'quintoandar - analytics engineer',\n",
       " 'vp, data products',\n",
       " 'machine learning engineer',\n",
       " 'data science director, adoption & enterprise',\n",
       " 'data platform developer, machine learning',\n",
       " 'senior vision engineer (english version)',\n",
       " 'lead data scientist (p3436)',\n",
       " '(canada) business intelligence engineer',\n",
       " 'data engineer',\n",
       " 'lead ml platform engineer',\n",
       " 'staff data engineer',\n",
       " 'transportation data analyst (tableau)',\n",
       " 'robotics software developer intern fall 2023',\n",
       " 'senior data architect',\n",
       " 'software engineer, computer vision program',\n",
       " 'data engineer - tempcover',\n",
       " 'data engineer',\n",
       " 'ml phd intern - llms & generative ai',\n",
       " 'work-study - \"data analyst\" or \"business intelligence team\" (m/f)',\n",
       " 'software engineer - structured data strategies',\n",
       " 'data science intern',\n",
       " 'data scientist',\n",
       " 'institution data analyst',\n",
       " 'senior solutions engineer - big data',\n",
       " 'machine learning engineer',\n",
       " 'principal machine learning (ml) engineer',\n",
       " 'product data engineer',\n",
       " 'data engineer - end-of-studies internship - paris 2nd',\n",
       " 'data engineer',\n",
       " 'senior data engineer/scientist',\n",
       " 'data scientist',\n",
       " 'principal data scientist, machine learning',\n",
       " 'sr director - project implementation - medical imaging / pacs',\n",
       " 'big data bi engineer',\n",
       " 'principal data scientist (spain, full-remote)',\n",
       " 'have programmed',\n",
       " 'business intelligence data analyst',\n",
       " 'machine learning for natural language processing intern',\n",
       " 'data scientist engineer',\n",
       " 'ml postdoc researcher - llms & generative ai',\n",
       " 'principal engineer, data management engineering',\n",
       " 'lead data scientist - pricing',\n",
       " 'data scientist, product analytics',\n",
       " 'senior infrastructure software engineer, ml platform',\n",
       " 'alumio solution engineer (data integration)',\n",
       " 'senior data engineer',\n",
       " 'senior ai research scientist \\x96 perception and machine learning',\n",
       " 'data scientist',\n",
       " 'field sample specialist (air samples) - eurofins environment testing \\x96 pueblo, co',\n",
       " 'senior research scientist \\x96 ai-based planning for autonomous systems',\n",
       " 'internship: business intelligence and finance excellence',\n",
       " 'senior data engineer, php',\n",
       " 'head of data science & predictive modeling',\n",
       " 'business and commercial banking (bcb) business intelligence and analytics graduate programme - gauteng',\n",
       " 'data scientist - data analytics and infrastructure',\n",
       " '(senior) machine learning engineer - mlops',\n",
       " 'team lead data science (f/m/x)',\n",
       " 'data analyst',\n",
       " 'senior data engineer',\n",
       " 'senior data scientist - monetization',\n",
       " 'lead machine learning research engineer, generative ai',\n",
       " 'course associate, data analysis and visualization in sustainability (fall 2023)',\n",
       " 'senior data scientist',\n",
       " 'robotics engineer',\n",
       " 'data modeler and/or tech data engineer - f/m',\n",
       " 'biomedical data scientist',\n",
       " 'product analyst - remote (mumbai)',\n",
       " 'databricks administrator',\n",
       " 'analyst, data engineering',\n",
       " 'lead data engineer- bangalore',\n",
       " 'marketing data scientist',\n",
       " 'insight analyst',\n",
       " 'senior data engineer',\n",
       " 'data analyst junior f/h',\n",
       " 'senior applied scientist i',\n",
       " 'data manager consultant',\n",
       " 'foundation models lead',\n",
       " 'machine learning engineer',\n",
       " 'consultant big data & machine learning',\n",
       " 'senior machine learning scientist (8304)',\n",
       " 'data scientist',\n",
       " 'senior product manager (ai team)',\n",
       " 'principal applied scientist',\n",
       " 'director of data science',\n",
       " 'data analyst consultant',\n",
       " 'data analyst',\n",
       " 'senior market research analyst',\n",
       " 'senior manager of master data management (hybrid)',\n",
       " 'mid data scientist (f/m/x), remote (eu) / berlin',\n",
       " 'sr. product manager (ai team)',\n",
       " 'data analyst (pricing)',\n",
       " 'principal data strategist consultant',\n",
       " 'senior vehicle data analyst',\n",
       " 'machine learning engineer (m/w/x)',\n",
       " 'principal engineer, datacenter software systems',\n",
       " 'business intelligence (qlik) developer',\n",
       " 'staff data scientist, credit card',\n",
       " 'head of product data science',\n",
       " 'data engineer / data analyst - end-of-studies internship - paris 2nd (m/f)',\n",
       " 'data scientist',\n",
       " 'junior data engineer',\n",
       " 'machine learning research engineer - federal',\n",
       " 'lead data engineer (p3796)',\n",
       " 'senior ml engineer',\n",
       " 'senior data strategist',\n",
       " 'bi engineer & data visualisation',\n",
       " 'senior machine learning engineer (8031)',\n",
       " 'python machine learning engineer (adlight)',\n",
       " 'research engineer in text analytics (direct contract with bosch)',\n",
       " 'data engineer',\n",
       " 'senior machine learning engineer',\n",
       " 'consultant data scientist / operational research',\n",
       " 'sr. quantitative research analyst',\n",
       " 'data analyst',\n",
       " 'senior data manager',\n",
       " 'staff infrastructure software engineer, ml platform',\n",
       " 'data engineer (aws)',\n",
       " 'data engineer - veeva link',\n",
       " 'senior data engineer (8307)',\n",
       " '(mid level) business intelligence analyst scm (f/m/x)',\n",
       " 'data analyst - end-of-studies internship - paris 2nd (m/f)',\n",
       " 'senior ai programmer',\n",
       " 'ai research scientist \\x96 perception and machine learning',\n",
       " 'data engineer 2',\n",
       " 'scientist/sr. scientist, computational biology',\n",
       " 'data scientist consultant',\n",
       " 'manager, data engineering',\n",
       " 'consultant | data analyst | kpmg futures',\n",
       " 'data scientist',\n",
       " 'research scientist \\x96 ai-based planning for autonomous systems',\n",
       " 'data architect',\n",
       " 'financial data analyst (m/f/d)',\n",
       " 'analyst - organizational effectiveness (data management & modelling, m&a)',\n",
       " 'data architect - talent pipeline',\n",
       " 'senior data analyst',\n",
       " 'data analytics hub manager',\n",
       " 'senior data analyst',\n",
       " 'manager, business intelligence',\n",
       " 'senior data analyst, marketing & enrollment - hybrid',\n",
       " 'data architect - decision-making and health data warehouse - data architect',\n",
       " 'middle product manager (data analysis, fintech)',\n",
       " 'director, data science',\n",
       " 'principal machine learning engineer',\n",
       " 'imaging geophysicist - cdi permanent contract',\n",
       " 'junior business intelligence analyst',\n",
       " 'lead data analyst',\n",
       " 'senior technical integration consultant- mft, migrations, etl experience- us based remote',\n",
       " 'senior data analyst (flights team, bangkok-based, relocation provided)',\n",
       " 'machine learning engineer',\n",
       " 'data engineer, operations (adscribe)',\n",
       " 'lead bi analyst (supply analytics, bangkok-based)',\n",
       " 'sr. cloud & data engineer (hybrid)',\n",
       " 'instructor- data analytics',\n",
       " 'data analyst (procurement)',\n",
       " 'technical program manager, artificial intelligence & data',\n",
       " 'staff machine learning platform engineer',\n",
       " 'data scientist',\n",
       " 'junior data and insight analyst',\n",
       " 'business intelligence manager',\n",
       " 'senior data engineer',\n",
       " 'data nobody',\n",
       " 'analytics engineer',\n",
       " 'monetization data analyst, marketing analytics',\n",
       " 'principal software engineer, applied ml',\n",
       " 'azure data engineer',\n",
       " 'electrical design engineer, data center design engineering',\n",
       " 'ai architect, it',\n",
       " 'data science intern - large language models',\n",
       " 'data engineer',\n",
       " 'deployment specialist -(travel, early career robotics)-central to east coast - us',\n",
       " 'staff software engineer, machine learning acceleration',\n",
       " 'senior bi developer',\n",
       " 'senior data engineer, data engineering',\n",
       " 'product data specialist',\n",
       " 'data manager business market',\n",
       " 'business intelligence specialist',\n",
       " 'data science consultant - lyon office',\n",
       " 'associate director, data engineering',\n",
       " 'consultant(e) senior data science',\n",
       " 'data science consultant - marseille office',\n",
       " 'data engineer',\n",
       " 'business intelligence manager',\n",
       " 'staff data scientist, business - sales & customer success',\n",
       " 'copywriter (zibraai)',\n",
       " 'senior product manager, data infrastructure',\n",
       " 'data analyst (flights team, bangkok-based, relocation provided)',\n",
       " 'senior data scientist- creator content',\n",
       " 'staff data scientist',\n",
       " 'data scientist',\n",
       " 'data engineer - h/f',\n",
       " 'machine learning engineer',\n",
       " 'senior software engineer (power bi) -election-46',\n",
       " 'sr staff data scientist - atg',\n",
       " 'us master data manager',\n",
       " 'senior data analyst',\n",
       " 'data analyst',\n",
       " '(senior) digital analytics engineer',\n",
       " 'senior data science consultant - Marseille office',\n",
       " 'data analyst f/h',\n",
       " 'data scientist',\n",
       " 'senior business intelligence analyst (bangkok-based, relocation provided)',\n",
       " 'instructor, ai/machine learning (part-time)',\n",
       " 'big data engineer (spark/ hadoop/ scala)',\n",
       " 'staff software engineer, machine learning infrastructure',\n",
       " 'research scientist',\n",
       " 'wind master data manager',\n",
       " 'senior applied scientist ii',\n",
       " 'data science analyst',\n",
       " 'machine learning engineer - llm',\n",
       " 'product data analyst - gaming analytics',\n",
       " 'senior data science consultant - nantes office',\n",
       " 'chatbot engineer',\n",
       " 'machine learning scientist (l6) - product',\n",
       " 'imaging coordinator',\n",
       " 'people analytics senior data analyst (remote)',\n",
       " 'information security & data management trainer',\n",
       " 'senior machine learning modeler, financial crimes',\n",
       " 'lead analyst (bi data development)',\n",
       " 'principal machine learning engineer - personalization',\n",
       " 'staff software engineer, data platform',\n",
       " 'consultant(e) data science',\n",
       " 'senior insight analyst - digital experience',\n",
       " 'alternance consultant(e) data analytics - h/f',\n",
       " 'data science consultant - nantes office',\n",
       " '302 - data analytics specialist - cms end stage renal disease (esrd)',\n",
       " 'analytics engineer',\n",
       " 'senior software engineer - data visualization',\n",
       " 'senior mlops engineer',\n",
       " 'senior ml engineer (remote)',\n",
       " 'research engineer - research',\n",
       " 'principal software engineer, data engineering',\n",
       " 'product owner - data visualization specialist and quality',\n",
       " 'senior data engineer - dataops / aws / distributed architecture (f/m/x)',\n",
       " 'senior ai data engineer (usa remote)',\n",
       " 'principal machine learning engineer- economy',\n",
       " 'data quality management specialist',\n",
       " 'machine learning implementation engineer',\n",
       " 'robotics software engineer',\n",
       " 'data management system general support coordinator, consultancy',\n",
       " 'senior data scientist (deep learning specialist)',\n",
       " 'machine learning engineer / senior machine learning engineer',\n",
       " 'managing director, data engineering, reporting, visualization',\n",
       " 'principal deep learning engineer - computer vision',\n",
       " 'data engineer - team data platform (f/m/x)',\n",
       " 'as a developer (sap price & qlik)',\n",
       " 'technical director, machine learning (individual contributor)',\n",
       " 'staff data scientist - atg',\n",
       " 'senior analyst, data science (r-14532)',\n",
       " 'sr. ml engineer (infrastructure)',\n",
       " 'senior machine learning engineer',\n",
       " 'data analyst ii',\n",
       " 'director, business intelligence',\n",
       " 'senior platform data engineer, people analytics',\n",
       " 'data analyst',\n",
       " 'sr machine learning engineer',\n",
       " 'data scientist (mmm)',\n",
       " 'machine learning engineer',\n",
       " 'senior spark technical solutions engineer',\n",
       " 'support ops manager i, ml data operations, fba support operations',\n",
       " 'head of business intelligence and analytics',\n",
       " 'senior analyst - business intelligence (bangkok-based, relocation provided)',\n",
       " 'lead data developer',\n",
       " 'program manager, operations finance business intelligence, japan operations finance',\n",
       " 'engineering manager, chatgpt for business',\n",
       " 'ai data engineering and data science manager (usa remote)',\n",
       " 'consultant (german speaking) - data analytics',\n",
       " 'research scientist, responsible ai',\n",
       " 'data engineer',\n",
       " 'data scientist, generative ai',\n",
       " 'senior data engineer',\n",
       " 'data analytics manager',\n",
       " 'data engineer (melbourne)',\n",
       " 'sr. product designer - data management (uk)',\n",
       " 'nlp engineer',\n",
       " '#659 data engineer',\n",
       " 'senior data visualization analyst',\n",
       " 'specialist solutions architect - data engineering & azure',\n",
       " 'data scientist intern',\n",
       " 'people data analyst',\n",
       " 'data scientist',\n",
       " 'senior/ lead data analytics',\n",
       " 'data product owner',\n",
       " 'head of health data science',\n",
       " 'senior data scientist - discovery experiences',\n",
       " 'data engineer - nbc sports next',\n",
       " 'senior researcher (postdoc) for big data processing (m/f/x)',\n",
       " 'applied scientist ii',\n",
       " 'senior data scientist - creator success',\n",
       " 'jr. crm data quality specialist',\n",
       " 'senior data engineer',\n",
       " 'head of data science (f/m/x)',\n",
       " 'director of machine learning platform engineering',\n",
       " 'staff research scientist/engineer',\n",
       " 'data analyst and bi developer',\n",
       " 'staff machine learning modeler, financial crimes',\n",
       " nan,\n",
       " 'data engineer databricks',\n",
       " 'senior data analyst',\n",
       " 'senior software engineer (data engineering)',\n",
       " 'hris & data analytics specialist',\n",
       " 'group manager, technical data science',\n",
       " 'expert data scientist (f/m/x)',\n",
       " 'sr. data engineer',\n",
       " 'research analyst (rpa engineer)',\n",
       " 'data engineer, clearing and custody',\n",
       " 'data analyst intern',\n",
       " 'senior/staff data engineer',\n",
       " 'analytics engineer - analytics hub',\n",
       " 'internship - data analyst',\n",
       " 'data scientist, ipc - specialized selection',\n",
       " '(mid level) business intelligence analyst scm (f/m/x)',\n",
       " 'prompt engineering internship',\n",
       " 'partner data specialist',\n",
       " 'lead applied data scientist (experience with media mix modeling)',\n",
       " 'azure data engineer (sql/python)',\n",
       " 'analyste-programmeur sp√©cialiste etl',\n",
       " 'data engineer',\n",
       " 'data engineer, creative media operations',\n",
       " 'digital analytics engineer',\n",
       " 'talan consulting \\x96 consultant senior/manager \\x96 data strategy (h/f)',\n",
       " 'executive training coach, artificial intelligence',\n",
       " 'enterprise data architect - 6 month contract',\n",
       " 'adjunct instructors - data science program - 2023/2024',\n",
       " 'specialist solutions architect - mlops',\n",
       " 'senior smwdc data analytics team lead',\n",
       " 'data analytics engineer',\n",
       " 'senior data scientist',\n",
       " 'data analyst',\n",
       " 'data analyst',\n",
       " 'senior data engineer i',\n",
       " 'data visualisation consultant',\n",
       " 'data analyst (bangkok based, relocation provided)',\n",
       " 'head of data',\n",
       " 'senior dataops engineer (kafka)',\n",
       " 'principal ml engineer - ai platform',\n",
       " 'operations data analyst (tableau)',\n",
       " 'financial data analyst',\n",
       " 'stage ing√©nieur machine learning (f/h)',\n",
       " 'data analyst',\n",
       " 'senior/staff machine learning engineer - ecommerce fraud detection',\n",
       " 'lead-data analyst',\n",
       " 'senior applied scientist, prime video',\n",
       " 'product data management manager (hybrid)',\n",
       " 'data scientist for reliability engineering (m/f/d)',\n",
       " 'd√©veloppeur etl (h/f)',\n",
       " 'power bi engineer',\n",
       " 'senior data engineer',\n",
       " 'senior backend engineer, ml research',\n",
       " 'salesforce administrator/data specialist',\n",
       " 'data engineer - remote (req. #515)',\n",
       " 'vp engineering - machine learning',\n",
       " 'senior product manager, automation & machine learning',\n",
       " 'data analyst (remote | uk)',\n",
       " 'senior data analyst (bangkok based, relocation provided)',\n",
       " 'director, trust & panel data integrity',\n",
       " 'data scientist (data science hub)',\n",
       " 'machine learning engineer intern',\n",
       " 'marketing data analyst',\n",
       " 'graduate analytics engineer',\n",
       " 'business intelligence engineer, advertising trust data',\n",
       " 'senior research scientist',\n",
       " 'ai solution cluster manager',\n",
       " 'senior battery modeling engineer, data',\n",
       " 'software engineer \\x96 model inference',\n",
       " 'backend software engineer, data engineering',\n",
       " 'clinical data manager',\n",
       " 'senior/principal ml engineer, content understanding',\n",
       " 'data science intern',\n",
       " 'delivery solutions architect : big data',\n",
       " 'sr data product manager - trading experience',\n",
       " 'data scientist, poland',\n",
       " 'staff machine learning engineer (modeling), risk',\n",
       " 'business intelligence analyst',\n",
       " 'hr ( data analyst)  - junior manager',\n",
       " 'senior people data analyst - workday',\n",
       " 'logistics lead - imaging',\n",
       " 'machine learning researcher (internship)',\n",
       " 'function developer - artificial intelligence/machine learning in automobile applications',\n",
       " 'sr research analyst - lng',\n",
       " 'sr. business analyst, digital services business intelligence (dsbi)',\n",
       " 'data scientist',\n",
       " 'senior data analyst',\n",
       " 'data engineer',\n",
       " 'lead ai programmer - remote',\n",
       " 'lead data scientist',\n",
       " 'engineer (mid- data engineer)',\n",
       " 'data scientist (machine learning modelling)',\n",
       " '4295 senior data analyst',\n",
       " 'senior manager (project & data management)',\n",
       " 'senior spark data engineer',\n",
       " 'pessoa engenheira de machine learning s√™nior',\n",
       " 'senior software engineer, data platform - remote',\n",
       " 'senior applied data scientist',\n",
       " 'senior data engineer',\n",
       " 'senior data engineer',\n",
       " 'lead data analyst',\n",
       " 'senior machine learning engineer- price freeze (100% remote)',\n",
       " 'data engineer',\n",
       " 'data architect',\n",
       " '(senior) director data science for pricing / yield management  (m/f/d)',\n",
       " 'data analyst',\n",
       " 'big data engineer \\x96 hadoop',\n",
       " 'senior machine learning engineer - search',\n",
       " 'databricks and scala engineer geospatial',\n",
       " 'data analyst coches.net',\n",
       " 'senior associate data engineering l1',\n",
       " 'big data infrastructure engineer',\n",
       " '[job- 10566] senior data visualization analyst, brazil',\n",
       " 'natural language processing intern',\n",
       " 'satellite image processing and ai engineer',\n",
       " 'data engineer (hybrid)',\n",
       " 'lead/principal product manager, ai/ml',\n",
       " 'senior data engineer - data scientist  (f/m/div.)',\n",
       " 'machine learning / ai engineer (indonesia)',\n",
       " 'research scientist',\n",
       " 'senior analytics engineer',\n",
       " 'lead partner commerce analyst (business intelligence)',\n",
       " 'data science consultant',\n",
       " 'bi developer',\n",
       " 'senior manager, data engineering',\n",
       " 'junior data scientist',\n",
       " 'data engineer \\x96 oracle',\n",
       " 'data engineer',\n",
       " 'data analyst (s&op)',\n",
       " 'graduate motorsport data analyse and engineer',\n",
       " 'data operations manager - link',\n",
       " 'vp of data science',\n",
       " 'manager, data science (machine learning)',\n",
       " 'data scientist iv',\n",
       " 'data science - machine learning engineer',\n",
       " 'principal machine learning engineer (dlp)',\n",
       " 'data engineer i (bld)',\n",
       " 'senior data science manager, marketing',\n",
       " 'scientist i, computational biology',\n",
       " 'data analytics architect, multi-instance',\n",
       " 'research scientist',\n",
       " 'head of data ops & render support',\n",
       " 'senior data analyst',\n",
       " 'senior data engineer',\n",
       " 'sr. security analytics engineer',\n",
       " 'senior devops engineer \"big data platform - hadoop\" (f/m/div.)',\n",
       " 'data analyst',\n",
       " 'principal  - data science',\n",
       " 'data scientist, product growth',\n",
       " 'staff machine learning engineer',\n",
       " 'principal applied scientist, sponsored products',\n",
       " 'senior machine learning architect',\n",
       " 'sport data operator',\n",
       " 'credit risk decision scientist - afterpay',\n",
       " 'python/etl developer',\n",
       " 'data analyst',\n",
       " 'staff data scientist',\n",
       " 'business intelligence associate manager(client facing)',\n",
       " 'intern (business intelligence service support)',\n",
       " 'data analyst',\n",
       " 'business intelligence mba associate',\n",
       " 'data scientist',\n",
       " 'data scientist, research',\n",
       " 'vacation work - (ais) actuarial & insurance solutions 2023- johannesburg',\n",
       " 'applied scientist- search query recommendation, search assistance',\n",
       " 'director, data science',\n",
       " 'senior robotics software engineer',\n",
       " 'senior product manager, supplier advertising (machine learning)',\n",
       " 'pessoa engenheira de machine learning j√∫nior',\n",
       " 'quantitative research analyst',\n",
       " 'system reliability engineer (big data)',\n",
       " 'business intelligence engineer, analytics',\n",
       " 'gruppenleitung supply chain management & data analytics (w/m/div.)',\n",
       " 'senior data engineer',\n",
       " 'staff data engineer (spark, python, hadoop)',\n",
       " 'data architect (optional relocation to montenegro)',\n",
       " 'data science intern - large language model',\n",
       " 'staff data scientist - nlp',\n",
       " 'senior etl datastage developer',\n",
       " 'junior data analyst',\n",
       " 'data analyst, product',\n",
       " 'data scientist, decisions - rider',\n",
       " 'mlops engineer, llm',\n",
       " 'data engineer - data warehousing (sql/python) ref1478z-german speaking',\n",
       " 'senior ml engineer - nlp',\n",
       " 'senior data engineer',\n",
       " 'business intelligence analyst',\n",
       " 'senior consultant - azure data engineer',\n",
       " 'director, data engineering',\n",
       " 'business intelligence analytics lead, (permanent remote)',\n",
       " 'data engineer',\n",
       " 'recruitment data analyst',\n",
       " 'data analyst',\n",
       " 'senior data analyst',\n",
       " 'data scientist',\n",
       " 'technical leader of computer vision',\n",
       " 'ai product owner - manufacturing (f/m/div.)',\n",
       " 'senior data scientist',\n",
       " 'stage - nlp engineer (h/f)',\n",
       " 'machine learning ops specialist',\n",
       " 'machine learning engineer',\n",
       " 'manager of growth data science',\n",
       " 'customer success & insight analyst',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame['Job Title'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame[\"Job Title\"]=dataFrame[\"Job Title\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of unique Facilities : ['clinical data analyst', 'aml/cft & data analyst', 'machine learning engineer', 'application developer & data analyst', 'data engineer full time (public sector) usa', 'sr staff data scientist - atg', 'vendor management and data quality lead', 'intern (business intelligence service support)', 'summer 2023 data engineering intern', 'principal cloud data engineer (prisma access)', 'data scientist (te-crg-glo-2023-19-grap)', 'data analyst - revenue optimizer', 'graduate power bi developer', 'sap consultant - product data management', 'premaster programm - data analytics and visualization', 'staff data scientist - atg', 'senior data analyst - sales', 'bi analyst', 'data scientist | insights (f/m/d) - ger, uk, nl, pl', 'senior data analyst (remote within emea)', 'senior data engineer (evergreen)', 'data management scrum master', 'rotational development program - artificial intelligence and machine learning trainee', 'data engineer scientist', 'data scientist (elasticsearch)', 'data engineer f/h', 'bi developer', 'data scientist - fraud risk', 'quintoandar - senior data analyst', 'ml research engineer', 'principal engineer, data project management', 'senior data engineer', '(senior) digital analytics engineer', 'senior software engineer (data pipeline)', 'senior data scientist', 'data science lead (hybrid)', 'business intelligence analyst', 'lead business intelligence analyst', 'sr data engineer', 'data modeler', 'data engineer', 'vp, actuarial modeling and data management', 'junior data science engineer (m/w/x)', 'healthcare data analyst', 'data scientist', 'data analyst | marketing or sales (f/m/d) - ger, uk, nl, pl', 'business intelligence expert', 'senior data analyst', 'principle mlops engineer', 'machine learning research engineer, generative ai', 'data analyst - product innovation', 'lead data scientist', 'data product owner', 'bi analyst jr - 24170', 'html developer', 'business intelligence developer', 'data scientist, marketing analytics', 'senior manager - aml/cft & data analyst', 'senior data visualization analyst', 'senior data engineer (remote)', 'customer data engineer', 'data engineer- data platform', 'digital marketing lead (zibraai)', 'staff data scientist - marketing', 'senior sales business intelligence manager', 'data analyst, customer experience', 'etas test lead - autonomous driving solutions', 'sr. data engineer', 'specialist solutions architect - mlops', 'data scientist, terminal', 'data analyst intern', 'react native engineer - mobile (dubai)', 'artificial intelligence lead | kpmg futures', 'jr. crm data quality specialist', 'data management consultant banking (f/d/m) financial services data platform fsdm', 'director, artificial intelligence (ai)', 'intermediate bi developer', 'senior business intelligence analyst', 'data analyst', 'staff machine learning engineer', 'data analyst (remote)', 'lead applied data scientist (experience with media mix modeling)', 'data engineer i', 'cloud database analyst', 'senior machine learning engineer', 'junior data analyst', 'financial data analyst', 'senior consultant in data science', 'staff clinical data manager # 3073', 'hr data analyst', 'consultant in data science', 'staff engineer, data platform', 'senior data scientist, marketing analytics', 'director, iva and ai solutions - professional services practice lead', 'lead data analyst(marketing/growth analytics)', 'data analyst, service analytics', 'amazon robotics - hardware engineer co-op (july-december 2023), amazon robotics', 'senior/staff data engineer', 'data product manager', 'fsa (fintech) - quantitative machine learning specialist & software developer', 'data engineer analyst', 'software engineer (data pipeline)', 'associate data scientist', 'data engineering analyst', 'talan consulting \\x96 consultant senior/manager \\x96 data strategy (h/f)', 'enterprise data architect - 6 month contract', 'data engineer ii', 'data scientist/machine learning engineer', 'senior data scientist, product', 'senior technical support engineer, dataset', 'finance business intelligence , operations finance', 'staff machine learning modeler, financial crimes', 'data engineer - music', 'data manager', 'salesforce administrator/data specialist', 'data engineer (starlink)', 'data engineer confirm√© bi - big data', 'director, spark technical solutions', 'middle data engineer (healthcare domain)', 'senior data analyst (pricing)', 'people analytics data visualization senior associate (open to remote)', 'd√©veloppeur power bi - h/f', 'product manager - experts & artificial intelligence', 'group manager data analytics india', 'vice president director, data scientist', 'business intelligence analyst, aws cloud logistics', 'scientist/senior scientist, machine learning', 'principal site reliability engineer, datastores (hybrid)', 'machine learning manager (systems)', 'consultant data engineer', 'machine learning engineer l3', 'data analyst coches.net', 'senior product marketing manager, conversational intelligence & ai products', 'graduate data analyst', 'analytics engineer', 'specialist solutions architect - data engineering (public sector)', 'senior data quality assurance specialist', 'senior site reliability engineer, datastores (hybrid)', 'customer success junior ml engineer, onboarding specialist', 'senior data science engineer', 'digital analytics engineer', 'senior big data engineer', 'senior data scientist, marketing', 'analytics engineer intern', 'master data team manager', 'senior data engineer, enterprise engineering', 'data operations associate', 'staff ml engineer (8627)', 'specialist architect : big data', 'research engineer in multi agent path finding for mobile robots (f/m/div.)', 'product marketing manager, data engineering', 'cv/ml engineer for 3d virtual humans - remote europe', 'senior data engineer - data bricks', 'director ai science', 'researcher- business intelligence', 'machine learning research scientist', 'staff database reliability engineer, datastores', 'senior data scientist - viator, london, oxford, uk remote', 'data analyst (bangkok based, relocation provided)', 'associate ai/ml engineer', 'azure data architect', 'senior applied data scientist', 'senior scientist, decision sciences', 'data operations & insights manager', 'principal ml engineer - ai platform', 'principal product marketing manager, ai & machine learning', 'technical support specialist (robotics) - eu - remote', 'data architect', 'operations data analyst (tableau)', 'head of applied ai/ml', 'data analytics engineer', 'software engineer - autonomy metrics', 'product manager- data visualization & analytics', 'data science in product design engineering', 'senior director of product - machine learning', 'senior data analyst (bangkok based, relocation provided)', 'operations planner data management technician', 'senior associate data engineering', 'data operations client onboarding', 'machine learning research scientist - reinforcement learning', 'machine learning engineer, generative ai', 'data management internship', 'sr big data engineer', 'consulting - robotics process automation (rpa) developer', 'data engineer with databricks - empower (remote/costa rica-based)', 'databricks and scala engineer geospatial', 'software engineer, data platform', 'senior manager data engineering', 'senior data engineer (p3949).', 'junior data engineer customer analytics', 'chief engineer, autonomy (r2020)', 'senior research data analyst', 'sport data operator', 'associate director | artificial intelligence lead | kpmg futures', 'research scientist', 'data engineering manager', 'principal engineer - data integrations', 'python engineer - machine learning specialist (remote)', 'senior applied scientist - document intelligence', 'data analyst, go live', 'senior data scientist (m/f)', 'researcher/senior researcher \\x96 natural language processing and text analytics', 'data analyst (customer service industry, mandarin support)', 'manager data strategy', 'business partner, data analysis', 'data engineer - remote', 'marketing data analyst', 'post-doctoral fellow or associate - agronomy data scientist', 'sr. data scientist', 'researcher- computer vision', 'data science lead', 'senior data scientist, product analytics', 'software engineer - machine learning, granica screen', 'data engineer - t√ºrkiye', 'sde-iii, data engineering', 'oracle data modeler / pl/sql - data warehouse', 'product data specialist (hw)', 'sparkcognition director of accounting - controller', 'senior machine learning scientist (usa remote)', 'senior data scientist (p171).', 'cloud data analyst engineer (finops)', 'dataops engineer', 'robotic research engineer - mechatronics', 'manager - applied data scientist', '??¬∑????/business intelligence engineer, japan operations finance', 'senior data engineer - (christchurch)', 'senior software engineer - data architecture skills', 'bi developer, analytics', 'supervis√£o de business intelligence (foco em m√≠dia/comunica√ß√£o)', 'senior manager, perception deep learning', 'sme consultant for data analytics', 'senior data strategist', 'data analyst (oslo-based)', 'senior ai engineer', 'sql data engineers', 'subsurface data manager', 'senior data analyst with python sql - ms- bangalore', 'data analyst supply chain management (f/m/d)', 'senior data quality developer', 'remote intermediate fullstack engineer (ai team)', 'ios engineer (dubai)', 'business intelligence data strategist', 'data engineer customer analytics', 'sr. bi analyst', 'data scientist generalist', 'business intelligence analyst - sales operations', 'senior developer - data engineer (aws/python/node)', 'senior data scientist: nlp', 'data analyst (allegro pay)', 'data analyst (dea)', 'ai research engineer', 'ai research scientist', 'manager, business operations - diagnostic imaging and laboratory', 'data science consultant', 'customer master data analyst', 'senior data quality engineer', 'senior data analyst - hybrid', 'computer vision researcher', 'research scientist - machine learning and algorithms', 'senior applied scientist', 'tableau/bi developer', 'data scientist (real-time ops)', 'data science/ analytics intern- long term', 'master data management plants (f/m/div.)', 'coordinator of data operations', 'data science team lead', 'ai programmer vr (ue)', 'data engineer (python) - payments', 'master data management plants (f/m/div.) (salary: ~81.000 eur p.a.*)', 'data analyst pleno', 'research engineer pem electrolyzer (f/m/div.)', 'consulting - data engineer', 'data analyst intern - product analytics', 'system reliability engineer (big data)', 'enterprise data architect', 'ttgp fleet data manager/senior jico', 'senior software engineer - data analytics', 'staff technical product manager, ai platform and solutions', 'big data engineer - pyspark', 'consultant / sr consultant - qa data engineer', 'computational biologist, translational science - location flexible', 'lead software engineer, ml infrastructure', 'senior insurance data scientist', 'principal engineer, data systems', 'clinical data manager', 'data analyst i - fraud', 'senior data scientist, operations', 'software engineer - data platform (python, cloud, big data)', 'senior cloud data analyst engineer (finops)', 'data engineer - bulgaria', 'power bi developer', 'consultant, data analytics', 'junior mlops - intern', 'business intelligence internship (summer 23/24)', 'business analyst (tech/ai)', 'senior applied scientist, amazon', 'specialist solutions architect - data engineering (financial services)', 'data scientist ebike systems (f/m/div.)', 'graduate data scientist', 'robotics engineer, sensors', 'contract: data infrastructure engineer', 'ai/ml modeling, simulation and analysis engineer (senior)', 'cloud data engineer', 'head of data science, analytics and bi', 'clinical data reporter', 'staff+ machine learning engineer - generative ai', 'especialista em auditoria interna - data analytics', 'engineering team lead, imaging tech', 'senior ml engineer - nlp', 'data analyst (aberdeen-based)', 'principal engineer, data and control systems', 'data scientist (pricing)', 'head of aml operations (m/f/d)', 'data engineer - 14072', 'data analyst (reporting and insights)', 'sr. manager (ai/ml)', 'data scientist, decisions - rider', 'data architect - sme', 'senior sw engineer (machine learning)', '(global) senior research scientist', 'staff data scientist, model risk management', 'graduate imaging geophysicist', 'architecte plateforme big data / devops - f/h', 'data analyst - retention', 'lead machine learning engineer', 'data developer', 'data analyst - digital marketing (all genders)', 'android engineer (dubai)', 'data specialist - governance', 'senior robotics process automation developer', 'technical product manager, data engineering', 'sr. data developer (remote), experian consumer services', 'senior data analyst with python sql - bangalore', 'manager, measurement innovation & data science', 'cloud data architect', 'business intelligence engineering manager', 'devops engineer (dubai)', 'data analytics internship (summer 23/24)', 'confirmed data analyst - data pro supply', 'senior machine learning engineer (modeling)', 'stage: robotics', 'data scientist / data analyst', 'product data analyst s√©nior (h/f) en cdi √† paris', 'data analyst - stage', 'senior analytics engineer', 'sr. software engineer, data engineering', 'senior machine learning engineer i', 'data engineer sr.software engineer dx', 'senior staff data engineer', 'natural language processing intern', 'senior data engineers', 'coordinateur projets genotypage data analyse (h/f)', 'machine learning & software engineer, infrastructure - us remote', 'customer-facing deep learning solutions architect', 'data engineering manager - allegro pay', 'senior business intelligence developer (database architect & etl developer)', 'technical mentor (independent contractor) - data engineering nanodegree (us timezone)', 'data analyst, business optimisation', 'machine learning force fields scientist (materials science)', 'principal machine learning engineer - atg', 'senior associate data sciences', 'senior data engineer (all genders) ai', 'intermediate / senior fullstack engineer (ai team)', 'data quality analyst - stage', 'senior software engineer - ai/ml team (.net + python)', 'software engineer, data platform, data management', 'senior machine learning engineer (modeling), financial crimes technology', 'research analyst', 'backend / data engineers ii, cerebro', 'junior data manager', 'data infrastructure engineer', 'backend engineer (dubai)', 'senior software engineer i, machine learning, retrieval sciences', 'sr. staff machine learning engineer', 'staff systems engineer, autonomy & simulation', '[??-??&???] senior, data analyst (channel analytics)', 'senior machine learning expert (on-site, brussels / belgium)', \"sp√©cialiste, intelligence d'affaires / specialist, business intelligence\", 'senior product manager | api & data products', 'senior analyst, data science and analytics', 'senior product manager - data management & search', 'accounting professor- data analytics/ais- 90k+ salary', 'senior data engineer - healthgrades', 'sr applied data scientist', 'business intelligence engineer', 'assistant mgr - data sciences', \"data analyst - stage de fin d'√©tudes - paris 2e\", 'trading bi developer', 'data analytics intern - le cubs 2023', 'product data analyst -  f/h', 'data scientist (crypto)', '[job- 10639] senior data engineer developer, brazil', 'business intelligence associate', 'analyst, reporting and business intelligence', 'data science software engineer', 'product owner with tableau/power bi(6 to 10 years)', 'machine learning & software engineer, infrastructure - emea remote', 'sr ai solution developer (servicenow developer)', 'data integrations engineer', 'lead software engineer - ai/ml team (.net + python)', 'transportation data analyst coordinator', 'senior applied data scientist (all genders) ai', 'power bi analyst', 'senior cloud devops engineer (data & ai) bei ebike systems (w/m/div.)', 'business intelligence analyst i', 'power bi data visualization analyst', 'data analyst (ceo office)', 'senior data science analyst- model validation', 'sr. revenue operations specialist - data analytics', 'phd position - neuro-symbolic ai for scene understanding in autonomous driving', 'staff data analyst, product analytics', 'senior product manager, large language model', 'quintoandar - analytics engineer', 'vp, data products', 'data science director, adoption & enterprise', 'data platform developer, machine learning', 'senior vision engineer (english version)', 'lead data scientist (p3436)', '(canada) business intelligence engineer', 'lead ml platform engineer', 'staff data engineer', 'transportation data analyst (tableau)', 'robotics software developer intern fall 2023', 'senior data architect', 'software engineer, computer vision program', 'data engineer - tempcover', 'ml phd intern - llms & generative ai', 'alternance - ¬´ data analyst ¬ª ou ¬´ equipe business intelligence ¬ª (h/f)', 'software engineer - structured data strategies', 'data science intern', 'institution data analyst', 'senior solutions engineer - big data', 'principal machine learning (ml) engineer', 'product data engineer', \"data engineer - stage de fin d'√©tudes - paris 2e\", 'senior data engineer/scientist', 'principal data scientist, machine learning', 'sr director - project implementation - medical imaging / pacs', 'big data bi engineer', 'principal data scientist (spain, full-remote)', 'ai programmer', 'business intelligence data analyst', 'machine learning for natural language processing intern', 'data scientist engineer', 'ml postdoc researcher - llms & generative ai', 'principal engineer, data management engineering', 'lead data scientist - pricing', 'data scientist, product analytics', 'senior infrastructure software engineer, ml platform', 'alumio solution engineer (data integration)', 'senior ai research scientist \\x96 perception and machine learning', 'field sample specialist (air samples) - eurofins environment testing \\x96 pueblo, co', 'senior research scientist \\x96 ai-based planning for autonomous systems', 'internship: business intelligence and finance excellence', 'senior data engineer, php', 'head of data science & predictive modeling', 'business and commercial banking (bcb) business intelligence and analytics graduate programme - gauteng', 'data scientist - data analytics and infrastructure', '(senior) machine learning engineer - mlops', 'team lead data science (f/m/x)', 'senior data scientist - monetization', 'lead machine learning research engineer, generative ai', 'course associate, data analysis and visualization in sustainability (fall 2023)', 'robotics engineer', 'ing√©nieur data modeler et/ou tech data - f/h', 'biomedical data scientist', 'product analyst - remote (mumbai)', 'databricks administrator', 'analyst, data engineering', 'lead data engineer- bangalore', 'marketing data scientist', 'insight analyst', 'data analyst junior f/h', 'senior applied scientist i', 'data manager consultant', 'foundation models lead', 'consultant big data & machine learning', 'senior machine learning scientist (8304)', 'senior product manager (ai team)', 'principal applied scientist', 'director of data science', 'data analyst consultant', 'senior market research analyst', 'senior manager of master data management (hybrid)', 'mid data scientist (f/m/x), remote (eu) / berlin', 'sr. product manager (ai team)', 'data analyst (pricing)', 'principal data strategist consultant', 'senior vehicle data analyst', 'machine learning engineer (m/w/x)', 'principal engineer, datacenter software systems', 'business intelligence (qlik) developer', 'staff data scientist, credit card', 'head of product data science', \"data engineer / data analyst - stage de fin d'√©tudes - paris 2e (h/f)\", 'junior data engineer', 'machine learning research engineer - federal', 'lead data engineer (p3796)', 'senior ml engineer', 'bi engineer & data visualisation', 'senior machine learning engineer (8031)', 'python machine learning engineer (adlight)', 'research engineer in text analytics (direct contract with bosch)', 'consultant(e) data scientist / recherche op√©rationnelle', 'sr. quantitative research analyst', 'senior data manager', 'staff infrastructure software engineer, ml platform', 'data engineer (aws)', 'data engineer - veeva link', 'senior data engineer (8307)', '(mid level) business intelligence analyst scm (f/m/x)', \"data analyst - stage de fin d'√©tudes - paris 2e (h/f)\", 'senior ai programmer', 'ai research scientist \\x96 perception and machine learning', 'data engineer 2', 'scientist/sr. scientist, computational biology', 'data scientist consultant', 'manager, data engineering', 'consultant | data analyst | kpmg futures', 'research scientist \\x96 ai-based planning for autonomous systems', 'financial data analyst (m/f/d)', 'analyst - organizational effectiveness (data management & modelling, m&a)', 'data architect - talent pipeline', 'data analytics hub manager', 'manager, business intelligence', 'senior data analyst, marketing & enrollment - hybrid', 'architecte data - d√©cisionnel et entrep√¥t donn√©es sant√© - data architect', 'middle product manager (data analysis, fintech)', 'director, data science', 'principal machine learning engineer', 'imaging geophysicist - cdi permanent contract', 'junior business intelligence analyst', 'lead data analyst', 'senior technical integration consultant- mft, migrations, etl experience- us based remote', 'senior data analyst (flights team, bangkok-based, relocation provided)', 'data engineer, operations (adscribe)', 'lead bi analyst (supply analytics, bangkok-based)', 'sr. cloud & data engineer (hybrid)', 'instructor- data analytics', 'data analyst (procurement)', 'technical program manager, artificial intelligence & data', 'staff machine learning platform engineer', 'junior data and insight analyst', 'business intelligence manager', 'data enginner', 'monetization data analyst, marketing analytics', 'principal software engineer, applied ml', 'azure data engineer', 'electrical design engineer, data center design engineering', 'ai architect, it', 'data science intern - large language models', 'deployment specialist -(travel, early career robotics)-central to east coast - us', 'staff software engineer, machine learning acceleration', 'senior bi developer', 'senior data engineer, data engineering', 'product data specialist', 'data manager zakelijke markt', 'business intelligence specialist', 'consultant(e) data science - bureau de lyon', 'associate director, data engineering', 'consultant(e) senior data science', 'consultant(e) data science - bureau de marseille', 'staff data scientist, business - sales & customer success', 'copywriter (zibraai)', 'senior product manager, data infrastructure', 'data analyst (flights team, bangkok-based, relocation provided)', 'senior data scientist- creator content', 'staff data scientist', 'data engineer - h/f', 'senior software engineer (power bi) -election-46', 'us master data manager', 'consultant(e) senior data science - bureau de marseille', 'data analyst f/h', 'senior business intelligence analyst (bangkok-based, relocation provided)', 'instructor, ai/machine learning (part-time)', 'big data engineer (spark/ hadoop/ scala)', 'staff software engineer, machine learning infrastructure', 'wind master data manager', 'senior applied scientist ii', 'data science analyst', 'machine learning engineer - llm', 'product data analyst - gaming analytics', 'consultant(e) senior data science - bureau de nantes', 'chatbot engineer', 'machine learning scientist (l6) - product', 'imaging coordinator', 'people analytics senior data analyst (remote)', 'information security & data management trainer', 'senior machine learning modeler, financial crimes', 'lead analyst (bi data development)', 'principal machine learning engineer - personalization', 'staff software engineer, data platform', 'consultant(e) data science', 'senior insight analyst - digital experience', 'alternance consultant(e) data analytics - h/f', 'consultant(e) data science - bureau de nantes', '302 - data analytics specialist - cms end stage renal disease (esrd)', 'senior software engineer - data visualization', 'senior mlops engineer', 'senior ml engineer (remote)', 'research engineer - research', 'principal software engineer, data engineering', 'product owner - data visualization specialist and quality', 'data engineer senior - dataops / aws / archi distribu√©e (f/m/x)', 'senior ai data engineer (usa remote)', 'principal machine learning engineer- economy', 'data quality management specialist', 'machine learning implementation engineer', 'robotics software engineer', 'data management system general support coordinator, consultancy', 'senior data scientist (deep learning specialist)', 'machine learning engineer / senior machine learning engineer', 'managing director, data engineering, reporting, visualization', 'principal deep learning engineer - computer vision', 'data engineer - team data platform (f/m/x)', 'bi developer (sap bo & qlik)', 'technical director, machine learning (individual contributor)', 'senior analyst, data science (r-14532)', 'sr. ml engineer (infrastructure)', 'data analyst ii', 'director, business intelligence', 'senior platform data engineer, people analytics', 'sr machine learning engineer', 'data scientist (mmm)', 'senior spark technical solutions engineer', 'support ops manager i, ml data operations, fba support operations', 'head of business intelligence and analytics', 'senior analyst - business intelligence (bangkok-based, relocation provided)', 'lead data developer', 'program manager, operations finance business intelligence, japan operations finance', 'engineering manager, chatgpt for business', 'ai data engineering and data science manager (usa remote)', 'consultant (german speaking) - data analytics', 'research scientist, responsible ai', 'data scientist, generative ai', 'data analytics manager', 'data engineer (melbourne)', 'sr. product designer - data management (uk)', 'nlp engineer', '#659 data engineer', 'specialist solutions architect - data engineering & azure', 'data scientist intern', 'people data analyst', 'senior/ lead data analytics', 'head of health data science', 'senior data scientist - discovery experiences', 'data engineer - nbc sports next', 'senior researcher (postdoc) for big data processing (m/f/x)', 'applied scientist ii', 'senior data scientist - creator success', 'head of data science (f/m/x)', 'director of machine learning platform engineering', 'staff research scientist/engineer', 'data analyst and bi developer', 'data engineer databricks', 'senior software engineer (data engineering)', 'hris & data analytics specialist', 'group manager, technical data science', 'expert data scientist (f/m/x)', 'research analyst (rpa engineer)', 'data engineer, clearing and custody', 'analytics engineer - analytics hub', 'internship - data analyst', 'data scientist, ipc - specialized selection', 'prompt engineering internship', 'partner data specialist', 'azure data engineer (sql/python)', 'analyste-programmeur sp√©cialiste etl', 'data engineer, creative media operations', 'executive training coach, artificial intelligence', 'adjunct instructors - data science program - 2023/2024', 'senior smwdc data analytics team lead', 'senior data engineer i', 'data visualisation consultant', 'head of data', 'senior dataops engineer (kafka)', 'stage ing√©nieur machine learning (f/h)', 'senior/staff machine learning engineer - ecommerce fraud detection', 'lead-data analyst', 'senior applied scientist, prime video', 'product data management manager (hybrid)', 'data scientist for reliability engineering (m/f/d)', 'd√©veloppeur etl (h/f)', 'power bi engineer', 'senior backend engineer, ml research', 'data engineer - remote (req. #515)', 'vp engineering - machine learning', 'senior product manager, automation & machine learning', 'data analyst (remote | uk)', 'director, trust & panel data integrity', 'data scientist (data science hub)', 'machine learning engineer intern', 'graduate analytics engineer', 'business intelligence engineer, advertising trust data', 'senior research scientist', 'ai solution cluster manager', 'senior battery modeling engineer, data', 'software engineer \\x96 model inference', 'backend software engineer, data engineering', 'senior/principal ml engineer, content understanding', 'delivery solutions architect : big data', 'sr data product manager - trading experience', 'data scientist, poland', 'staff machine learning engineer (modeling), risk', 'hr ( data analyst)  - junior manager', 'senior people data analyst - workday', 'logistics lead - imaging', 'machine learning researcher (internship)', 'function developer - artificial intelligence/machine learning in automobile applications', 'sr research analyst - lng', 'sr. business analyst, digital services business intelligence (dsbi)', 'lead ai programmer - remote', 'engineer (mid- data engineer)', 'data scientist (machine learning modelling)', '4295 senior data analyst', 'senior manager (project & data management)', 'senior spark data engineer', 'pessoa engenheira de machine learning s√™nior', 'senior software engineer, data platform - remote', 'senior machine learning engineer- price freeze (100% remote)', '(senior) director data science for pricing / yield management  (m/f/d)', 'big data engineer \\x96 hadoop', 'senior machine learning engineer - search', 'senior associate data engineering l1', 'big data infrastructure engineer', '[job- 10566] senior data visualization analyst, brazil', 'satellite image processing and ai engineer', 'data engineer (hybrid)', 'lead/principal product manager, ai/ml', 'senior data engineer - data scientist  (f/m/div.)', 'machine learning / ai engineer (indonesia)', 'lead partner commerce analyst (business intelligence)', 'senior manager, data engineering', 'junior data scientist', 'data engineer \\x96 oracle', 'data analyst (s&op)', 'graduate motorsport data analyse and engineer', 'data operations manager - link', 'vp of data science', 'manager, data science (machine learning)', 'data scientist iv', 'data science - machine learning engineer', 'principal machine learning engineer (dlp)', 'data engineer i (bld)', 'senior data science manager, marketing', 'scientist i, computational biology', 'data analytics architect, multi-instance', 'head of data ops & render support', 'sr. security analytics engineer', 'senior devops engineer \"big data platform - hadoop\" (f/m/div.)', 'principal  - data science', 'data scientist, product growth', 'principal applied scientist, sponsored products', 'senior machine learning architect', 'credit risk decision scientist - afterpay', 'python/etl developer', 'business intelligence associate manager(client facing)', 'business intelligence mba associate', 'data scientist, research', 'vacation work - (ais) actuarial & insurance solutions 2023- johannesburg', 'applied scientist- search query recommendation, search assistance', 'senior robotics software engineer', 'senior product manager, supplier advertising (machine learning)', 'pessoa engenheira de machine learning j√∫nior', 'quantitative research analyst', 'business intelligence engineer, analytics', 'gruppenleitung supply chain management & data analytics (w/m/div.)', 'staff data engineer (spark, python, hadoop)', 'data architect (optional relocation to montenegro)', 'data science intern - large language model', 'staff data scientist - nlp', 'senior etl datastage developer', 'data analyst, product', 'mlops engineer, llm', 'data engineer - data warehousing (sql/python) ref1478z-german speaking', 'senior consultant - azure data engineer', 'director, data engineering', 'business intelligence analytics lead, (permanent remote)', 'recruitment data analyst', 'technical leader of computer vision', 'ai product owner - manufacturing (f/m/div.)', 'stage - nlp engineer (h/f)', 'machine learning ops specialist', 'manager of growth data science', 'customer success & insight analyst', 'senior product manager - machine learning', 'data scientist (customer acquisition)', 'it data engineer', 'staff research scientist/engineer - atg', 'analista de sistemas | foco em power bi e sharepoint', 'staff applied scientist (open to remote across anz)', 'manager, product data analytics', 'applied scientist ii, aws ai', 'senior robotics engineer', 'scientist 1, data science', 'research engineering manager, unit 42 (remote)', 'act two program- sr. analyst, data quality', 'software engineer, robotics', 'staff software engineer - streaming data pipelines', 'sr. data engineer - (java + spark)', 'associate director, business intelligence', 'senior data scientist - retailer', 'senior data scientist, core', 'senior/lead data scientist', 'esrd data analyst and program/technical specialist (contract contingent)', 'ai/ml data labeling manager - uk', 'data scientist (job ref:1823)', 'data analyst i', 'staff bioinformatics scientist - machine learning/classifier research and development #2802 (seattle)', 'consultant(e) power bi', 'data engineer specialist', 'junior/mid data analyst', 'sr staff applied research scientist - atg core llm team', 'senior data modeler', 'data engineer-operations', 'business/data analyst', 'manager - ds-ai & machine learning', 'senior backend software engineer- big data analytics', 'staff product manager, machine learning and recommendations', 'bilingual data analyst', 'senior data developer aws redshift', 'analytics engineer - consumer & order and pay', 'sr. data engineer (remote)', 'staff machine learning engineer, entity understanding - nyc', '(senior) director data science for pricing / yield management & data science lead team portugal (m/f/d)', 'ai/ml data labeling manager - us', 'data scientist (s&op)', '[ea] ai tech lead (artificial intelligence)', 'data engineer - data platform', 'finance data analyst', 'sr sre/devops engineer (ai & machine learning)', 'business data analyst - dailymotion advertising (all genders)', 'data scientist - 4365', 'data engineer \\x96 data lake', 'engineer- data engineer', 'premaster programm - big data (analytics)', 'senior software engineer, data safety', 'sr. business intelligence analyst', 'big data engineer (it-da-ds-2023-76-ld)', 'staff bioinformatics scientist - machine learning/classifier research and development #2802 (san diego)', 'senior expert bigdata & ai public cloud (m/w/d) - open telekom cloud ref1768p', 'lead software engineer, machine learning platform', 'ai engineer', 'associate director/director of chemical data analytics', 'senior data engineer -remote', 'data scientist senior', 'director | master data management delivery lead| data & cloud - nv1 clearance', 'senior data analyst, international', 'data engineer pleno', 'data engineer, customer experience and business trends', 'ai compiler and performance engineer', '2023 power bi msbi developer bd/xai cob', 'staff data scientist, strategic planning & forecasting', 'big data specialist', 'data scientist (m/f)', 'data scientist (mid level)', 'sr staff devops - terraform, kubernetes, ci/cd, spark / kafka, linux, scripting', 'staff machine learning engineer - ads', 'engineer, computer vision', 'cnsp surface force training requirements & data analyst', 'etl developer - remote (usc, gc, gc ead)', 'data engineer (hong kong)', 'senior frontend software engineer, machine learning infrastructure', 'data engineer with top secret', 'senior data scientist (p3485)', 'data & analytics engineer', 'engineer, computer vision and graphics', 'senior clinical data manager', 'chatgpt & ai consultant (part time)', 'python ai developer (remote)', 'senior staff software engineer, machine learning', 'senior backend engineer, applied machine learning', 'oracle data analyst', 'staff data engineer (snowflake / kafka)', 'data scientist intern (end of studies)', 'vp of data science and analytics', 'business intelligence analyst - risk', 'senior scientist, machine learning', 'graduate data engineer', 'engineering manager 1 - data engineering developer experience', 'applied scientist ii, amazon search', 'lead engineer, mlops platform', 'machine learning engineer - simulation', 'workplace analytics engineer', 'machine learning intern/co-op (fall 2023)', 'artificial intelligence software library technical lead', 'business intelligence (bi) engineer', 'natois-0008 data scientist (ns) - tue 13 jun', 'applied research scientist', 'mid/sr machine learning engineer', 'staff software engineer - machine learning', 'data analyst - core\\xa0data', 'senior staff bi analyst', 'esg data operations senior manager', 'senior machine learning engineer ii, machine learning infrastructure', 'data analyst - contract - 1 day a week', 'ml engineer', 'artificial intelligence hardware architect (senior hardware architect)', 'senior analytics engineer - data engineer', 'data analytics manager, spear operations support & services (os2)', 'senior software engineer, perception, machine learning/computer vision', 'machine learning engineer - intelligent safety', 'artificial intelligence compiler engineer (software engineer)', 'senior data engineer, marketing data', 'ai algorithms - hardware codesign lead (senior ai software engineer)', 'research scientist intern', 'staff product designer, ai/ml', 'simulation and data engineer inductive sensors (m/f)', 'senior engineer, data management engineering', 'data analyst (jira & azure devops or hp alm) - remote', 'vice president data science, real world data lead', 'data engineer - bi developer', 'analyst, data science', 'engineering team lead, data modelling', 'associate director, data science', 'cloud/data engineer', 'senior staff/ staff engineer(python | spark | delta lake | graphdb | machine learning)', 'team leader - data engineering (ref462h)', 'data management consultant', 'senior data manager, product owner', 'director of delivery, data operations', '(senior) machine learning engineer \\x96 video analysis', 'student assistant for data management (m/f/d)', 'data scientist, risk', 'customer success support specialist (remote technical support, robotics) - u.s.', 'principal data scientist (seattle or u.s. remote)', 'data engineer - etl', 'data engineer - internship', 'market & business intelligence graduate', 'product data analyst', 'full stack engineer for computer vision products', 'senior data scientist (p3186)', 'senior machine learning engineer, perception', 'data analyst (internship)', 'senior data engineer (m/f/d)', 'senior data analyst, engineering excellence', 'business intelligence analytics manager', 'machine learning scientist (intern)', 'staff research engineer (req #r273)', 'senior machine learning scientist', 'data scientist, in-car ads', '[job-10530] senior data developer, brazil', 'deep learning field engineer', 'data analyst - spanish speaker', 'data stage etl', 'software engineer, data streaming platform', 'data analyst tech lead', '[??] ????? ??? (data specialist / ???)', 'knowledge management data specialist', 'machine learning engineer, fulfillment / supply chain', 'data engineer - technical lead', 'senior data engineer (h/f)', 'analyst, business intelligence', 'it manager, advanced business intelligence', 'revenue operations data analyst', 'data science manager', 'engineering manager - core ml & chatbot', 'data engineer (crypto)', 'associate data analyst (permanent remote)', 'economist, pricing and causal inference', 'customer data specialist', 'senior manager, personalization machine learning science', 'senior research analyst- corporate research team', 'summer machine learning engineer internship (skopje, bitola, ohrid)', 'assistant/associate professor in embedded artificial intelligence  at t√©l√©com paris - cdi', 'software developer in data science team', 'machine learning systems engineer', 'software engineer - c++ qt qml development', 'data engineer - kolkata', 'ai solution manager/senior ai solution manager', 'bi analyst \\x96 based in parsippany-troy hills, nj', 'machine learning trainee', 'senior data analyst, business insights - us, remote', 'insight analyst ii', 'in bgsw systemtester autonomoriving exm 2023 (cloe)', 'senior machine learning engineer / senior python developer', 'data specialist', 'data analyst - crm', 'junior, intermediate or senior data analyst', 'qa data engineer', 'head of business intelligence', 'autonomy software engineer - flight core', 'data operations manager', 'senior/lead data manager', 'data quality analyst/ test analyst', 'senior data analytics developer', 'data science manager (m/f/d)', 'lead data engineer', 'senior data engineer, analytics', 'senior data engineer, new initiatives', 'data scientist - product (u.s. only)', 'data analyst (intern)', 'data operations analyst', 'associate data analytics manager(cpg)', 'staff product data analyst', 'senior manager data engineering - houston (in office 2 days per week)', 'database engineer(elasticsearch/ opensearch)', 'software engineer - machine learning', 'bi development lead - india', 'sr business analyst, reporting & data analytics - (workforce planning) (hybrid/onsite)', 'senior data engineering developer', 'data engineer (h/f)', 'manager, internal audit - lending products, credit and models (chnw)', 'data engineer apprentice - data platform m/f/d', 'manager, data science', 'sr. data scientist - ads', 'staff data engineer (data acquisition)', 'data analyst - chinese speaker', 'senior hr systems & data analyst', 'data warehouse bi developer lead', 'data analyst 2 - optum', 'senior data engineer - driven data platforms', 'senior ai/ml consultant (federal)', 'quality assurance engineer, data center engineering', '(senior) cloud data engineer (m/f/d)', '(senior) cloud data engineer (m/w/d)', 'staff software engineer, data storage', 'data analyst, medicare advantage, remote', 'lead business intelligence developer', 'senior computer vision developer (c++, python)', 'staff data scientist-2', 'senior data analyst - marketing', 'business intelligence \\x96 data engineer (open to remote)', 'senior consultant - enterprise business intelligence and data analytics solution implementation', 'lead data architect consultant (aws, azure, gcp)', 'data analyst / data scientist ebike systems (w/m/div.)', 'entry level data scientist', 'insights & data specialist (growth)', 'data scientist (f/h)', 'senior methods and data analyst', 'project manager: customer outreach (data science)', 'clinical data manager/analyst', 'senior machine learning engineer, financial crimes', 'senior data scientist - uk ops', 'data analyst (permanent work from home)', 'pre-college instructor, big data, machine learning & their real world applications (on-campus) summer 2023', 'sp√©cialiste en science des donn√©es / data scientist', 'senior machine learning engineer, communication safety', 'senior data scientist (machine learning)', 'senior manager, data science', 'staff engineer, data infrastructure', 'principal applied scientist, spexsci', 'staff data engineer, data stewardship', 'senior systems engineer ii, autonomy and localization', 'head of data science and analytics', 'modelling / data science - lead analyst - analytics', 'senior geospatial machine learning engineer (f/m/d)', 'data scientist - digitalization, trading & origination', 'data integration support representative', 'head of dataops & render support', 'frontend developer (chatbot)', 'machine learning/ai engineer', 'data engineer (f/h)', 'data engineer - etl developer', 'data architect consultant (aws, azure, gcp)', 'product data analyst - experimentation', 'seismic imaging analyst', 'staff software engineer, datasets and ml infrastructure', 'data scientist ii', 'data analytics and insights analyst', 'associate client manager -  retail business intelligence', 'front end developer angular (ai/ml)', 'senior developer - data engineer (aws/node/typescript)', 'data product manager - safemine cloud', 'business intelligence analyst / analyste bi', 'security engineer, data security', 'power bi data analyst', 'software engineer, chatgpt product backend', 'hr data analyst (h/f)', 'd√©veloppeur.se big data (f/h)', 'phd machine learning engineer intern (fall 2023)', 'data scientist i, sdo privacy - pdc team', 'data analyst (dublin or paris)', 'staff software engineer ii-big data (remote)', 'applied scientist - reinforcement learning and foundation models', 'principal data engineer', 'software engineer, chatgpt product development', 'principal data scientist (deep learning)', 'ing√©nieur data / power bi (h/f)', 'intern junior marketing data analyst (12 month ftc)', 'data engineer (job ref: 1769)', 'senior people data analyst', 'data quality qa engineer', 'data scientist, analytics', 'business data analyst', 'sr. director, data science', 'machine learning scientist ii', 'lead-business intelligence&data warehousing', 'senior business intelligence engineer, dsp bi', 'data analyst, fulfillment network planning', 'power bi specialist', 'senior data scientist - social communications', 'senior business intelligence engineer', 'data engineer (enterprise master data management)', 'behavioral insights fraud data analyst', 'entry level (recent tech grads) business intelligence analyst \\x96 parsippany-troy hills, nj', 'data engineer, machine learning (remote)', 'data visualization specialist', 'data engineer scala / java (spark)', 'staff data engineer (actimize ais)', 'robotics software developer (multiple positions) - [bgsw]', 'data product owner h/f', 'artificial intelligence engineer', 'senior data scientist, afterpay product', '(senior) automotive research engineer for cloud computing (m/w/d)', 'wireless communication data scientist', 'bear robotics', 'sr. data analyst (partner analytics)', 'devops/ mlops engineer', 'chatgpt / ai consultant (part time)', 'compliance data analyst', 'engineer i, machine learning', 'engineering manager, ml platform', 'data analyst (digital analytics) intern', 'computer engineer, computer vision hardware (mid//sr)-m/f/d', 'senior research analyst - lng short term', 'business data analyst intern', 'data analyst - customer acquisition', 'senior bi analyst', 'data operations development team lead', 'data engineer - concepteur - d√©veloppeur sql - bigl', '[job-10533] senior, data developer python/spark, brazil', 'senior data product manager - link key people', 'senior data scientist - search & recommendation', \"machine learning engineer (master's/phd)\", 'research analyst \\x96 lng short-term', 'applied scientist, automated reasoning group for healthcare and payments security', 'senior implementation data scientist', 'data engineer i (r-14521)', 'databricks - sony', 'data engineer (midi and audio)', 'computer engineer, computer vision hardware (mid//sr)', 'senior cloud data scientist (finops)', 'computer vision engineer', 'senior product manager, data infrastructure and ml', 'senior software engineer - data infrastructure', 'staff applied research scientist', 'principal machine learning engineer - core infrastructure', 'implementation data scientist', 'methods and data analyst', 'machine learning engineer, payments ml accelerator', 'operations transformation manager (all genders) with focus on chat/chatbot', 'business intelligence lead/specialist', 'senior manager, product ops (business intelligence)', 'sr principal machine learning engineer', 'manager, clinical data management', 'senior data scientist, ml and algorithms (remote)', 'senior ml engineer (portugal based remote/hybrid)', 'sr. big data engineer', 'senior product manager  (ai & automation)', 'intern, data science', 'staff ml engineer, conversion', 'data engineer / machine learning engineer - spark, etl, pre-processing, pipeline, machine learning', 'consultant data analytics it digital impulse - h/f', 'data analyst trainee', 'machine learning engineer (speech) - ai (remote,india)', 'data science engineer', 'data analytics specialist', 'director, data science (engagement)', 'senior data analyst (merchant)', 'tech lead bi / power bi cdi - h/f', 'senior data science/ai engineer', 'staff software engineer- data production', 'senior data scientist (financial analysis)', 'data scientist, payments ml accelerator', 'head of product data management', 'sr. human resource business partner (technology, engineering and data science)', 'mlops engineer', 'app development project manager (chatbot)', 'junior data scientist (commercial)', 'software development manager - computer vision, amazon fulfillment technology', 'junior clinical trials data specialist', 'strong junior front end developer (justdone.ai)', 'machine learning engineer (associate)', 'senior lead, third party data strategy & governance', 'sap consultant for product data management', 'strong middle/senior data engineer (healthcare domain)', 'android developer (ai)', 'senior product data analyst, compliance', 'data lead - products / mobile apps  : green panda games (m/w/nb)', 'data analyst - h/f', 'senior data engineer - etl', 'eet data engineer', 'data scientist - stage h/f', 'data engineering, mid-level', 'senior data analyst, trading', 'data scientist | search & discovery', 'cloud data analyst', 'software engineer (sre in elasticsearch platform team)', 'hedis data analyst', 'working student data analytics & reporting (m/f/d)', 'senior analytics engineering manager (remote, americas)', 'data science director, analytics', 'senior software engineer (sre in elasticsearch platform team)', 'backend developer (ai)', 'research analyst i - defence data development', 'internship - data engineer', 'data scientist (ai)', 'senior backend engineer, ai', 'senior applied scientist ii, market optimization', 'hso gs - ai/ml | 5-7 years', 'computer engineer, computer vision software and hardware', 'data engineer - it corporate', 'machine learning (ml) engineers (ai)', 'systems data analyst', 'financial market data analyst', 'backend engineer, ai', 'applied research scientist - scientifique en recherche appliqu√©e', 'customs brokerage executive (air freight)', 'risk investigator - aml operations', 'staff software engineer - data products', 'data engineer (infrastructure)', 'server engineer - big data serving group', 'marketing data analyst intern', 'data quality analyst', 'data science intern/stagiaire en donn√©es - fall 2023/automne 2023', 'smart start data analyst | maintenance', 'data scientist (mica)', 'data analyst, freelance', 'experience & data analyst', 'staff machine learning engineer, revenue automation and data services', 'computational linguist (speech) - english usa native', 'senior cloud data scientist', 'senior staff applied research scientist, perception', 'mlops engineering intern', 'big data full stack software engineer (top secret), python - 1545', 'engineering manager (java / bigdata)', '[so] senior data analyst', 'sr. cloud engineer, data team', 'lead data engineer (part time)', 'junior business data analyst - events', 'software / data engineer, python, senior - 2690', 'senior machine learning engineer ii, perception', 'big - data engineer', 'working student - asset optimisation & hedging - business intelligence', 'senior data engineer for scada and the operational data platform', 'intelligence data analytics (data scientist), python - 2925', 'manager, software engineering (machine learning team)', 'group head - data architect', 'data engineer, analytics & insights', 'senior data scientist, large language models', 'data analytics architect (microsoft emphasis)', 'azure ai/ml expert', 'senior applied research scientist ii, perception', 'cloud data scientist', 'lead robotics engineer', 'fraud data scientist', 'big data engineer', 'data engineer - india', 'staff machine learning engineer, perception', 'robotics software team lead', 'data engineer - senior software engineer', 'research engineer, privacy', 'senior software engineer (ai asset mgmt team)', 'senior clinical data manager i', 'senior data analyst - terminology', 'expert in ai/ nlp/ ml - 4354', 'senior data engineer (hybrid)', 'technical support supervisor/manager - emea remote (robotics, amr, wms)', 'director, engineering - ml / ai', 'senior / staff data analyst (customer experience product analytics)', 'senior qa engineer (ai asset mgmt team)', 'senior data modeller (uk wide)', 'data science analyst | it | sb finance (makati)', 'senior product manager, attribution (data products)', 'ai data manager', 'constructability engineer, data center design engineering', 'data engineer (bengaluru)', '(sr.) scientist, computational protein design', 'data engineer spark/scala exp√©riment√© - h/f', 'machine learning intern (h/f/x)', 'data engineer (f/m/x)', 'ing√©nieur data scientist exp√©riment√© - f/h', 'lead data engineer (f/h)', 'flying data manager (m/f), 12 months (renewable)', 'research engineer- atmospheric perils vulnerability', 'azure data architect (f/h)', 'data strategy manager (crm & loyalty, consumer experience, ecommerce)', 'data integration analyst (west coast/chicago)', 'associate manager - data architect', 'senior manager data science', 'senior software engineer - data engineering (java/spark)', 'senior geoscience data scientist', 'director of data science (f/m/x)', 'db/etl developer', 'senior inhouse consultant data analytics & process mining (w/m/div.)', 'tech lead (db & etl)', 'imaging geophysicist / scientist - 2023 graduate programme', '(senior) machine learning engineer', 'research scientist, safety', 'director of business intelligence and data analytics', 'gameplay ai programmer', 'sr data engineer (java/ python/ react) - marketing (id:1432)', 'data quality & compliance analyst', 'technical support manager (robotics, wms)', 'information technology data analyst', 'analyst - data architect', 'modelling / data science - sr. analyst - analytics', 'etl developer', 'datawarehouse/data architect - d&a (remote, costa rica-based)', 'senior data scientist fmcg', 'data science manager, marketing', 'data scientist analyst', 'staff software engineer, database infrastructure', 'qa analyst  (db & etl)', 'it development lead with abap (sap / master data management)', 'lead data scientist - recommendation systems (p1922).', 'data engineer lead', 'senior analytics engineer (infosec)', 'backend engineer, data', 'it application architect (sap / master data management)', 'business intelligence engineer, finance', 'product manager - computer vision', 'sql data analyst', 'data science manager, risk interventions', 'consultant - data managed services', 'data engineer (h/f) - alternance', 'senior manager \\x96 data and ai', 'data engineer, finance', 'data engineer - d&a (remote/costa rica-based)', 'staff ml engineer', 'vice president, data strategy', '(senior) ml platform / devops engineer', 'senior data engineer - infrastructure, tidal', 'data scientist, afterpay product', 'data engineer: data platform team (remote)', 'senior machine learning engineer - editing ai (open to remote across anz)', 'business intelligence engineer, field - cs - consumer', 'product manager for healthcare ai products', 'technical lead data engineer - power bi', 'alternance - assistant data analyst h/f', 'machine learning - fresher', 'data engineer intern - industry/catalog team - m/f/d', 'data analyst, geochemistry', 'senior director, clinical data management', 'technical architect databricks', 'imaging geophysicist', 'manager data analyst', 'financial data analyst, emea', 'staff software engineer - data engineering (java/spark)', 'scientist 2, data science', 'staff researcher, machine learning', 'voice and data specialist', 'senior engineer software (ml applications nlp)', 'senior data scientist - fraud risk', 'entry level data analysts, manpower data analytics academy, july 2023', 'data quality consultant', 'business intelligence manager, finance', 'associate director, commercial data management lead', 'data architect (bangkok based, relocation provided)', 'mid data scientist', 'data engineer intern', 'technical lead data engineer - power bi, tableau', 'senior robotics research engineer', '[rpg] power bi data engineer', 'staff  engineer - machine learning', 'business intelligence analyst (remote)', 'senior software engineer, deep learning (ai)', 'data engineering lead/data architect, kms healthcare', 'machine learning engineer (mlops), fintech', 'senior data scientist, web security', 'data engineer - remote us', 'co-op/intern developer, machine learning - qa', 'senior machine learning engineer ii, simulation', 'software engineer -data analytics', 'content developer - ai and machine learning', 'product expert analyst (data engineer) - europe', 'teamlead logistics data analytics (m/w/d)', 'data engineer - cloud - remote (noida)', 'solutions architect : big data & ai', 'staff data scientist, core (manager) - korea', 'machine learning engineer, revenue and finance automation', 'sr. strategic financial data model analyst', 'business intelligence analyst (m/f/d)', 'lead data scientist/ data science manager (f/m/x)', 'data scientist, data & analytics', 'specification coordinator - data management', 'senior data scientist  (f/m/x), remote / berlin', 'project engineer, data center construction', 'manager, data engineering - nbc sports next', 'analyst - business intelligence', 'staff machine learning engineer, simulation', 'data engineer - cloud - remote (bangalore)', 'data scientist summer intern', 'user enablement learning technology and data manager', 'cloud data engineer: aws', 'sr. business intelligence engineer, buy with prime', 'staff data engineer (remote - austin, or u.s.)', 'clinical nlp engineer', 'data engineer - cloud - remote (cochin)', 'sr. data analyst, customer insights', 'personal assistant to the cio (ai asset mgmt team)', 'computer science expert ai training - data engineering (remote)', 'computer science expert ai training - machine learning (remote)', 'data scientist, marketing & sales', 'data analyst (h/f) - cdi', 'senior data scientist (f/m/x), albania', 'data scientist - 4350', 'data engineer - operations', 'program manager, data science', 'senior director, data management - remote', 'senior cloud finops (data analyst engineer)', 'data analyst (seattle or u.s. remote)', 'data architect, internal it (remote in us)', 'data pipeline engineer', 'data quality analyst internship', 'senior data product manager', 'senior analytics engineer (seattle or u.s. remote)', 'mid data scientist (f/m/x), albania', 'teamlead ai & analytics till afry x', 'data engineer (c#, python, elastic)', 'data analyst financial services talent pipeline', 'cloud computer vision engineer', 'senior financial and data analyst', 'expert cloud data (f/h)', 'sr data scientist', 'deep learning ai scientist', 'data engineer (remote)', 'fraud investigator - data analytics', 'data scientist & analytics engineer', 'manager, provincial data management', 'market data management/administration', 'senior software engineer with angular (ai/ml)', 'lead data scientist (p1606)', 'senior machine learning scientist - poi data', 'smts, machine vision engineer', 'senior product data scientist', 'sr.manager, data engineering', 'applied scientist, sponsored ads', 'senior director of machine learning', 'senior staff technical product manager, ai platform', 'database developer - databricks, data modeling', 'tech lead, data management', 'staff, data analyst(ecommerce product analytics)', 'associate research scientist - proteomics, phage display', 'portfolio data feeds - portfolio data analyst', 'principal applied scientist, search science and ai', 'director, data engineering and machine learning operations', 'senior product manager (machine learning)', 'software engineer (ai asset mgmt team)', 'ml & ai product manager', 'analytics engineer (remote)', 'machine learning engineer/devops engineer', 'data scientist, product', 'senior machine learning engineer - deep learning', 'research engineer life science - molecular diagnostic assay development and automation (f/m/div.)', 'power bi data engineer', 'digital data specialist', 'director, artificial intelligence and machine learning', 'research engineer for design, simulation and signal processing concepts for mems sensors and actuators (f/m/div.)', 'senior staff data scientist (remote)', 'etl (spark/scala) team lead - remote', 'data modeler/data architect w/databricks - empower (remote/virtual, canada-based)', 'senior software engineer - applied ai', 'application infrastructure consulting (aic) - 22662 - 22663', 'data engineer - cloud - remote (delhi)', 'data analyst (2030 clean power)', 'product data manager - 3d', 'data scientist, forest ecosystems', 'portfolio data feeds - associate portfolio data analyst', 'senior data analytics engineer (contractor)', 'engineering manager, machine learning team', 'technical lead - data science', 'senior data analyst - digital marketing (m/f/x)', 'lead data manager', 'it data engineer - private banking', 'data analyst (6 month internship) (m/f)', 'senior embedded software engineer base sw (posix) - off-road robotics core team', 'data scientist - iii', 'senior data product manager, trading experience', 'senior analyst, project management & data analytics', 'data engineer - cloud - remote (pune)', 'software engineer, machine learning infrastructure', 'staff data analytics | global analytics', 'machine learning scientist i - experiences', 'football data specialist', 'chatgpt consultant', 'data analyst \\x96 web and social (junior)', 'junior sw developer with nlp knowledge', 'data analyst / analytics engineer', 'senior data analyst - marketing analytics (12m ftc)', 'sw engineer: big data/risk systems, sr. consultant level', 'master data analyst', 'machine learning product owner', 'senior machine learning in nlp (productivity)', 'senior javascript engineer, ai tools', 'junior engineering data analyst', 'data engineer - python', 'data operations specialist', 'product manager, research - ai/ml & data science', 'data analyst \\x96 web and social (tourism)', 'data manager (m/w/d)', 'associate data engineer', 'applied scientist', 'data scientist (m/f/d)', 'senior data engineer - oilx', 'data analyst \\x96 web and social (telcommunication)', 'principal/lead software engineer - autonomy products', 'data quality team lead', 'program management data analytics internships \\x96 academic year', 'data science & analytics internships \\x96 academic year', 'senior bi data engineer', 'senior machine learning engineer, modeling', 'staff data scientist - algorithms, guest science', 'data analyst (finance)', 'data management intern (12 months internship)', 'data engineer & power bi developer', '[job-10452] data developer sr', 'junior data analyst (mlodszy analityk danych) w dziale doradztwa i badan rynku', 'data scientist | remote', 'senior staff data science engineer, ai and mlops', 'especialista machine learning', 'data analyst - london', 'analytics engineering manager', 'director, data analytics', 'be | analytics engineer', 'data analytics', 'senior business intelligence consultant', 'applied ai researcher', 'sr. business intel engineer, buy with prime', 'data analyst \\x96 crm', 'senior software engineer, data platform', 'head of data analytics', 'business intelligence engineer, buy with prime', 'senior software engineer i, machine learning', 'senior data analyst (remote)', 'principal data architect', 'senior engineering manager, data management', 'big data tech lead (devops) (bangkok based, relocation provided)', 'autonomous driving agile master lead (c++ oops) - exp 2023', 'senior principal data scientist', 'sharepoint / powerbi developer contractor', 'event manager (ai house)', 'business data analyst (new york based)', 'data engineer & architect azure cloud (w/m/div.)', 'solutions consultant (data specialist)', 'data analyst-trading team', 'business intelligence lead', 'vice president, business intelligence', 'data analytics engineer h/f', 'sr. data analyst (cmg)', 'data science consultant (ts/sci clearance)', 'lead data engineer (r-14415)', 'lead data strategy consultant', 'data modeling engineer (w/m/div.)', 'associate principal data architect', 'senior technical product manager - computer vision & ai', 'senior gameplay ai engineer - star wars', 'senior vice president, data science', 'senior data analyst (nz)', 'lead data engineer (p3947)', 'language enabled research analyst (chinese)', 'internship: business intelligence', 'business intelligence engineer ll, shipping and delivery support', 'ml engineer - senior software engineer', 'open - data analyst (digitas & publicis media)', 'senior data architect (ts/sci clearance)', 'vice president, data management', 'senior software engineer, machine learning for robotics', 'data engineer (ts/sci clearance)', 'director, computational biology', 'safety data engineer', 'data analyst 3', 'senior bi developer/analyst - d√©veloppeur/analyste bi senior', 'data analyst - operations', 'head of operations data analyst', 'data engineer - remote role', 'senior software engineer, data lake', 'chatbot conversational writer | pleno', 'data analyst developer (french speaker) - bpce si', 'html developer (2 months freelance contract)', 'sr. business intel engineer, consumables category productivity', 'data architect (ts/sci clearance)', 'aml operations specialist', 'data analytics project manager', 'power bi developer for power platform team', 'data engineer lead/data architect, kms healthcare', 'pyspark developer', 'junior data operations developer', 'data analyst (ts/sci clearance)', 'associate machine learning engineer', 'research engineer, safety', 'data analytics consultant', 'staff data engineer (data platform)', 'sr. data integrations engineer, it enterprise applications', 'live data operator', 'data analyst, nonprofit', 'data science graduate programme', 'staff machine learning software engineer, motion planning', 'data analyst 2', 'senior software engineer, computer vision', 'lead data scientist (atlanta)', 'consultant data analytics (m/w/d)', 'senior nlp scientist', 'principal data architect (london based)', 'senior financial data analyst', 'staff machine learning scientist', 'lead business intelligence analyst (tableau)', 'sr. business intelligence engineer, denied party screening', 'machine learning data engineer', 'head of data science', 'director, data engineer (p3946)', 'research analyst ii', 'principal software engineer - machine learning', 'senior manager, data engineer (remote)', 'ai alignment - research engineer', '(senior) consultant* - data management', 'senior data engineer (p3949)', 'senior data scientist, search', 'java full stack developer-robotics (colorado only)', 'senior manager, data science - performance marketing (toronto, on)', 'full stack data scientist', 'software engineer - data analytics', 'consultant senior data visualisation - h/f', 'programmatic data specialist', 'broadcast research analyst', 'sql server and etl support engineer (tier 1/tier 2)', 'senior machine learning engineer, ml platform', 'pricing data analyst', 'data analyst (trust, safety & cx automation products)', 'data scientist assistant \\x96 stage juillet 2023 (f/h/nb)', 'manager, decision sciences', 'consultant bi / azure data engineer h/f', 'snowflake dbt data engineer - remote job.', 'senior machine learning engineer ii, search retrieval', 'microsoft data analyst', 'deep learning engineer', 'hardware analysis engineer (airbag system)', 'senior cloud data engineer', 'graduate - data science, visa consulting & analytics, aunzsp', 'data analyst - ratings ops', 'decision scientist, risk', 'data management specialist', 'data science product owner', 'senior functional safety engineer - autonomous driving', 'image processing and computer vision for navigation intern', 'senior machine learning engineer, compliance engineering & technology', 'staff product manager, data pipelines', 'data engineering lead/data architect', 'data engineer intern m/f/d - industry team', 'sap data analyst', 'siaxperience web data analyst', 'research intern (multimodal language model) - summer 2023', 'sr data engineer (aws) - education technology (id: 1451)', 'data engineer (m/f/d)', 'freelancer (m/f/d) data engineering - join our tech community', 'senior business analyst, tax data management solutions', 'product data analyst (m/f/d) - hamburg', 'data engineer (san francisco)', 'business intelligence analyst supporting the operations and customer teams', 'data science - data engineer', 'senior engineer (machine learning engineer)', 'qlik senior data analyst', 'junior data engineer (f/m/x)', 'modelling / data science - manager- analytics', 'data analyst (advertising)', 'jitterbit data integration architect', 'data scientist iii', 'senior data scientist, growth analytics', 'staff / senior machine learning/data engineer', 'senior computer vision engineer', '80389998 - engineer, data', 'principal data scientist', 'growth data analyst', 'data reporting engineer', 'member of technical staff - research (deep learning)', 'senior solution architect (m/f/d) - data engineering', 'master or phd biomedical sciences - data manager clinical trials', 'staff devops engineer - big data - federal', 'reinforcement learning simulation software engineer intern', 'data infrastructure product manager', 'research analyst i', 'qlik senior data analyst (full remote)', 'senior engineer (data engineer)', 'machine learning engineer - nlp (remote, us)', 'sap senior data analyst (full remote)', 'senior insight analyst', 'ml engineer intern', 'unreal engine 3d developer (zibra ai)', 'senior game data analyst', 'qlik data analyst', 'associate director, laboratory data management and programming', 'sap data engineer', 'machine learning intern\\x97multi-modal models', 'data scientist - germany', 'ab-testing data analyst', 'sr. machine learning engineer', 'business intelligence developer 2', 'expert/data analyst (m/f/d) customer relationship management (crm)', 'senior engineer, database tools and replicator', 'product data analyst (m/f/d) - barcelona', 'microsoft senior data analyst', 'sap senior data analyst', 'digital commerce: senior supply chain data scientist (sixty60)', 'data analyst (jnr / mid / snr or lead)', 'sap senior data engineer', 'business intelligence engineer, its-bi', 'research engineer \\x96 electrolysis and fuel cell experiments', 'analytics engineer - ena london, warsaw (f/m)', 'senior data engineer, operations', 'senior project manager & product owner (m/f/d) - data engineering', '[job  10464] data scientist master, brazil', 'lead analytics engineer', 'data quality analyst - 12 month ftc', 'commercial data analyst', 'product data analyst (m/f/d) - berlin', 'data engineer (level 5), global analytics and insights (gain)', 'enterprise search - senior product manager- ai/ml', 'senior data scientist, commerce platform - inventory', 'machine learning platform lead', 'india fp&a - sr.manager (bangalore or mumbai)', 'data manager - airlock (18 month ftc)', 'computer vision intern', 'data scientist - stagiaire', '[job 10455] data developer senior, brazil', 'sr. system analyst (robotics process automations)', 'machine learning engineer, data analytics & ai', 'senior data engineer, customer data platform', 'manager, apparel data analytics & crm', 'data engineering lead', 'data scientist - media insights (p3459).', 'senior backend engineer - core data team', 'senior enterprise architect, data quality', 'middle ml engineer/developer (graai)', 'head of data privacy', 'sr. data engineer - asm analytics', 'data engineer - team data discovery (f/m/x)', 'aws analytics and machine learning engineer', 'business intelligence engineer (looker)', 'sales b2b (zibraai)', 'consultant(e) confirm√©(e) etl', 'data & ai engineer', 'analytics engineer ii', 'senior databricks developer', 'team lead, mlops', 'machine learning engineer (zibra ai)', 'data scientist - english speaker (remote)', 'trainee, business intelligence', 'software developer / data analyst (remote)', 'software/data engineer', 'senior manager, data science (foursquare labs, inc., new york, ny)', 'senior data engineer (d/f/m)', 'associate analytics engineer', 'senior devops data engineer (dba)', 'senior data scientist (data products)', 'data analyst intern m/f/d - content', 'senior data analyst -  growth & customer engagement', 'data engineer - architecting and developing bosch-wide analytical solutions (m/f)', 'senior data analyst coches.net', 'senior machine learning engineer - recommendations/search/ai (open to remote across anz)', 'un.e ing√©nieur.e logiciel robotics', 'chatbot specialist', 'junior software engineer - python / java / ai / ml', 'senior machine learning engineer, community support platform', 'partner and growth data analyst', 'manager - data engineering', 'senior big data engineer \\x96 cib', 'staff machine learning engineer, llm', 'senior data engineer - architecting and developing bosch-wide analytical solutions (m/f)', 'senior research analyst -l48', 'senior machine learning engineer - retail media platform', 'data scientist (coaching)', 'analyst- data management', 'software / ml engineer (remote)', 'staff data scientist, invest', 'head of data & analytics', 'data analyst, marketing', 'lead data scientist (dl & ai modeling, forecasting) (canada)', 'cloud finops (data analyst engineer)', 'data analyst - chennai', 'data analyst (h/f) - alternance', 'manager, engineering (c#, .net core, sql, react, aws/azure, etl, sap systems)', 'consultant(e) power bi & azure - h/f', 'financial data analyst (power bi, english)', 'business intelligence architect', 'senior business analyst/data analytics', 'sdm, ml engineering, amazon', 'senior autonomy integration engineer - commercialization team', 'nutrition data management specialist', '[10418 ] data developer master, brazil', 'data scientist iii (data products)', 'data engineer - blablacar daily', 'sr data engineer - machine learning, data cleaning, streaming, pipelining, preprocessing, etl', 'junior data engineer m/w', 'product data strategist (hybrid)', 'db/etl tech lead', 'software engineer ii, machine learning', 'data operations administrator ( 3 month contract )', 'senior data analyst - business intelligence', 'data scientist - battery energy storage system', 'business intelligence analyst - supporting finance and commercial teams', 'data analyst w/ business intelligence - cib', 'senior data engineer, platforms', 'it intern, data integration services', 'deep learning (ai) lead', 'data scientist (remote usa only)', 'senior applied scientist, sponsored products, demand identification', 'artificial intelligence and machine learning developer', 'sr. manager, portfolio data engineering', 'senior research scientist/engineer -video understanding', 'data architect - 12 month ftc', 'data scientist | bees data', 'data scientist - senior manager (h/f)', 'data analytics, manager', 'senior master data engineer', 'senior data analyst - business insights', 'software qa engineer - machine learning qe', 'consultant(e) data analytics - h/f', 'power bi architect', 'artificial intelligence / machine learning engineer - sr', 'sr. data engineer, finance products (remote)', 'junior insight analyst', 'senior data analyst (wolt market)', 'data engineer - 12 month ftc - spark, glue', 'senior machine learning engineer (deep learning/computer vision)', 'senior business data analyst', 'manager-business intelligence&data warehousing', 'backend ai engineer  (remote, us)', 'data engineer consultant', 'data scientist (canada)', 'business intelligence expert - 4335', 'business intelligence', 'senior machine learning engineer (f/m/x)', 'senior product manager - ai & data products', 'senior machine learning engineer - afirmativa para pessoas negras', 'director of business intelligence', 'software engineer - machine learning infrastructure', 'sr / staff machine learning operations engineer', 'internship program: machine learning backend', 'senior business intelligence analyst, lead gen & seo reporting', 'data integration engineer', 'analista de business intelligence', 'research data analyst', 'machine learning scientist - eta & routing', 'computer vision researcher / engineer, localization', 'data analyst - flexible on location', 'senior manager - business intelligence', '(senior) energy data scientist', 'procurement data analyst', 'imaging & histology specialist', 'data engineer - thefork', 'sr. consultant - azure data engineer', 'senior data science consultant', 'head of ai, analytics and data', 'bi (business intelligence) developer (uk wide)', 'senior staff tlm, machine learning infrastructure', 'machine learning engineer - fraud', 'analyst - business intelligence (us remote in eastern time) fmcg, cpg and retail preferred', '(senior) business intelligence analyst scm (f/m/x)', 'vision engineer', 'dataops engineer, streaming', 'senior data scientist / nlp engineer', 'business intelligence engineer, subscribe and save', 'sr data engineer avec francaise', 'data analyst, borrowing', 'data developer, client experience metrics', 'applied data scientist', 'manufacturing data scientist', 'data science tech lead', 'senior bi analyst (hybrid)', 'senior quantitative researcher (ai asset mgmt team)', 'sql server bi developer', 'senior data analyst, credit policy', 'data analyst, quality assurance', 'business intelligence analyst (hybrid)', 'project manager, data analytics & ai', 'senior stability analytics engineer', 'senior data infrastructure engineer', 'quant researcher (ai asset mgmt team)', 'staff developer advocate - ai & machine learning', 'principal applied scientist, amazon search', 'data analyst - business insights', 'staff software engineer - sap data integration', 'gcs business intelligence analyst', 'senior machine learning engineer (15617) remote- canada', 'business intelligence analyst (d363)', 'data analyst - business intelligence', 'software engineer for real-driving data analysis applications', 'logistics data analyst', 'senior applied scientist, amazon search', 'principal engineer, data productivity', 'director, data analytics & insights', 'entry level (recent tech grads) bi analyst - must be us-based', 'business intelligence analyst- domo- remote (anywhere in the u.s.)', '(people) business intelligence analyst (f/m/x)', 'senior director of business intelligence and analytics', 'managing director data science', 'director (m/f/d) of business intelligence', 'stage robotics: integrating new sensors to improve localization (meewerk/afstudeer)', 'senior ml engineer i', 'staff business intelligence engineer, compliance engineering & technology', 'stage robotics: integrating lidar to improve navigation (meewerk/afstudeer)', 'artificial intelligence / machine learning engineer - jr', 'internship: robotics', 'data engineer (req id: 2331)', 'sr. software engineer, data (starshield)', 'developer - big data', 'senior software engineer, machine learning infrastructure', 'senior software engineer, ai / core optimization', 'senior backend engineer, ai (remote)', 'data engineer with web scraping expertise', 'procurement global data analyst', 'machine learning engineer ii', 'senior data scientist - nlp', 'smts - ml engineer', 'data scientist lead, square f&s', 'data scientist (data analyst)', 'senior data scientist - personalisation', 'data management supervisor', 'machine learning sales engineer', 'data analyst for an industry-leading management software for private practices', 'machine learning manager', 'director, data analytics and insights', 'ic19ds1 - associate data scientist - cleared', 'sr. data analyst - product analytics', 'data modeller', 'senior linux software engineer \\x96 robotics', 'bi solution designer', 'internship robotics: integrating new sensors to improve localization', 'data analyst - (ratings ops)', 'internship robotics: exploring different vision technologies', 'data engineer for an industry-leading management software for private practices', 'senior data scientist- search and recommendation', 'systems integration engineer, aircraft components', 'engineer i (mlops)', 'ic21d3 - sr data scientist - cleared', 'senior data engineer - remote us', 'project manager - software development for surgical data science', 'senior software engineer - java, bigdata, distributed, spark / kafka, nosql', 'lead research engineer, machine learning', 'data scientist, commerce platform - inventory', 'senior machine learning engineer: radar camera fusion', 'senior machine learning engineer (dlp)', 'business/data analyst intern (graduate student)', 'research engineer, medical nlp/llms', 'data scientist (ts/sci clearance)', 'senior marketing data analyst', 'ic22dsp - principal data scientist - cleared', 'staff data scientist, cashapp compliance engineering & technology', 'phd in radar deep learning perception', 'executive data manager (vaga afirmativa para mulheres)', 'machine learning solutions engineer', 'senior or staff+ software engineer - large language models', 'data engineer - data platform m/f/d', 'director, creative media operations (data engineer)', 'head of data - digital & cloud', 'legal and compliance data analyst', 'senior staff data scientist - inference, marketing technology', 'senior data scientist (ts/sci clearance)', 'sr. machine learning engineer, content discovery', 'attack surface data analyst (xpanse)', 'senior data engineer, finance', 'data engineer iii', 'geoint data scientist', 'data analytics lead', '(junior) data analyst (f/m/x)', 'data scientist, sr. consultant - cybersecurity ai research & products', 'data infrastructure engineer for a management software for private practices', 'product manager, ai/ml', 'machine learning specialist', 'principal software engineer  (ai/ml)', 'mid-level data engineer', 'stage robotics: exploring different vision technologies (meewerk/afstudeer)', 'machine learning engineer ii (user modelling & targeting)', 'ic20ds2 - mid level data scientist - cleared', 'master data management analyst', 'business intelligence engineer - india', 'senior robotics software engineer, research and development (remote in us or canada)', 'lead data engineer - remote us', 'director of data platform, data engineering', 'applied machine learning researcher', 'financial amendments data analyst', 'data analytics and reporting engineer', 'data integration specialist', 'data analyst/manager - last mile planning (m/f/d)', 'bigdata tester ii (r-14443)', 'senior research engineer, machine learning', 'staff engineer, robotics controls  (research & development, hybrid-  nashua, nh)', 'analytics engineer - ads business insights', 'senior/staff machine learning engineer - ads', 'c002854 it data analyst - sme/architect (ns) - fri 26 may', 'robotics engineer - tech lead', 'research scientist, safe, reliable & trustworthy ai', 'senior data analyst - argentina', 'junior bi analyst', 'sales data analyst', 'carbon data analyst', 'senior machine learning scientist, ml research', 'software engineer, data ingestion', 'assistant analytics engineer', 'environmental and sustainability data manager', 'senior machine learning scientist, cheminformatics', 'senior machine learning engineer (risk)', '(sr.) machine learning scientist', 'data analyst - ngls', 'senior bi & data analyst', 'head of data analyst operations', 'data visualization engineer', 'process and data analyst', 'ai/ml engineer', 'data engineer (east coast us hours)', 'sr. machine learning engineer, study', '? insurance verification specialist / artificial intelligence trainer', 'manager, data analytics', 'machine learning ops engineer (emea time zone - remote)', 'data engineer (frankfurt, gemany)', 'r&d data analyst', 'senior artificial intelligence\\xa0sme', 'senior engineering manager, machine learning', 'sr director - implementation quality - medical imaging/pacs', 'mlops engineer - ai (remote, india)', 'consultant dataops/devops', 'research engineer - allennlp', 'azure data developer', 'business intelligence engineer, data center position optimization (dcpo)', 'machine learning product manager (emea time zone - remote)', 'manager, cloud data operations', 'research engineer', 'assistant research associate (data analyst)', 'machine learning scientist, genomics', 'analyst (data integration)', 'staff product analytics engineer - madrid', 'operations research analyst', '3d data quality analyst - contract', 'staff data architect', 'machine learning engineer - data pre-processing, pipeline, streaming', 'consultant data visualisation - h/f', 'data analyst (citymapper)', 'senior cloud data operations engineer', 'machine learning engineer, genomics', '(senior) people data analyst (m/w/x)', 'senior data analyst - go to market analytics', 'analyst, decision sciences', 'director, machine vision & robotics', 'principal lead, autonomous manipulation', 'staff data engineer, data & ml products', 'data analyst & excel specialist', 'pdra in ai for autonomous systems', 'data analyst - risk management (cib)', 'data analyst, payments fraud', 'senior data scientist, invoices', 'data management - lead associate (hybrid)', 'finance data management manager (hybrid)', 'sr data analyst, marketing technology', 'cloud data engineer (ts/sci poly)', 'director- data science platform', 'presales data architect - streaming (remote us)', 'senior azure data architect w/databricks - d&a (remote, costa rica-based)', 'delivery manager - data and ai consulting services', 'data engineer with databricks - d&a (remote/costa rica-based)', 'sustainability data analyst', 'gtm data analyst', 'research analyst - lng', 'senior research analyst', 'data scientist - agronomie (h/f) - cdi', 'ml platform engineer', 'senior azure data engineer', 'cloud data engineer (m/w/d)', 'senior azure data architect w/databricks (remote, costa rica-based)', 'scientist, computational biology, omics data analysis', 'senior director - head of internal data science, visa europe', 'research engineer, safe, reliable & trustworthy ai', 'data scientist & bi developer', 'biomedical research/data scientist', 'data scientist (dl & ai modeling, forecasting) (canada)', 'senior staff software engineer, data storage', 'senior data engineer, kms healthcare', 'senior data engineer, infrastructure', 'senior manager data science - performance marketing (montreal, qc)', 'data specialist (engineering & analytics) - fintech', 'regional insight analyst, crm & loyalty', 'data engineer (m/f)', 'r&d packaging sustainability data specialist', 'sr. business intelligence engineer, corp - jp', 'engineer, autonomy systems & sensors', 'data engineer (senior)', 'senior analyst, data quality & analytics', 'senior data scientist marketplace (m/f/d) - dublin', 'software engineer, data infrastructure', 'machine learning engineer - motion planning', 'consultant(e) power bi confirm√©(e)', 'data science associate', 'mid-level software engineer - data team', 'ai intern (chatgpt specialist)', 'stage 6 mois - data scientist junior h/f', 'sr. data engineer - spark, python', 'ecq3 full stack machine learning developer', 'machine learning infrastructure engineer', 'research scientist, computational economics', 'scientist i/ii, computational biology - target biology', 'manager, business insights & data analytics', 'applied scientist, generative ai, creative x', 'generative ai engineer', 'data scientist in mobility', 'sr. principal engineer - data architecture', 'manager - data science', 'etl and data warehouse testing intern', 'senior clinical data scientist, real-world data (remote)', 'fair data lead', 'senior aml/cft & data analyst', 'senior manager, data engineering - radiomics (senior manager, multimodal r&d)', '80405862 - data engineer', 'agronomy data scientist (m/w) - cdi', 'stage: computer science, robotics, computer vision, wiskunde', 'senior data analytics engineer', 'senior data scientist marketplace (m/f/d) - london', 'software engineer, model inference', 'regional business data analyst', 'data analyst intern m/f/d - business', 'bi data analyst', 'senior data scientist marketplace (m/f/d) - berlin', 'data operations engineer', 'trainee data engineer - r-16792', 'senior manager of data analytics', 'data analytics manager - compliance, risk & internal audit', 'senior software engineer (python), data engineering (hybrid)', 'research and audience data analyst', 'data engineer (contractor)', 'staff etl developer', 'lead data scientist - healthcare', 'data scientist / senior data scientist (federal)', 'senior data engineer - martech (viator)', 'data science instructor', 'sr software qa engineer-machine learning qe', 'people data specialist', 'senior machine learning engineer (trip planning)', 'application integration engineer, computer vision program', 'senior software engineer, machine learning - ads intelligence', 'data scientist - new college graduate']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 'Length :2129')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"list of unique Facilities :\",dataFrame[\"Job Title\"].unique().tolist()),\"Length :\"+str(len(dataFrame[\"Job Title\"].unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intern=dataFrame[ (dataFrame[\"Experience level\"] == 'Entry-level') &  (dataFrame[\"Location\"].str.contains(\"United States\")) ].groupby('Job Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Plus</th>\n",
       "      <th>Currency</th>\n",
       "      <th>City_State_Location</th>\n",
       "      <th>Country_Location</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Job Title</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3d data quality analyst - contract</th>\n",
       "      <td>Geomagical Labs</td>\n",
       "      <td>Palo Alto, California, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>39000.0</td>\n",
       "      <td>3D graphics</td>\n",
       "      <td>Flex hours</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Palo Alto</td>\n",
       "      <td>California, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>act two program- sr. analyst, data quality</th>\n",
       "      <td>NBCUniversal</td>\n",
       "      <td>New York, NEW YORK, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Agile</td>\n",
       "      <td>Career development</td>\n",
       "      <td>False</td>\n",
       "      <td>--</td>\n",
       "      <td>New York</td>\n",
       "      <td>NEW YORK, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analyst - business intelligence (us remote in eastern time) fmcg, cpg and retail preferred</th>\n",
       "      <td>NielsenIQ</td>\n",
       "      <td>Atlanta, GA, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>39000.0</td>\n",
       "      <td>Business Intelligence</td>\n",
       "      <td>Flex hours</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analyst, business intelligence</th>\n",
       "      <td>Publicis Groupe</td>\n",
       "      <td>Philadelphia, PA, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>Business Intelligence</td>\n",
       "      <td>Startup environment</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analyst, data engineering</th>\n",
       "      <td>Publicis Groupe</td>\n",
       "      <td>New York City, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>AWS</td>\n",
       "      <td>Career development</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "      <td>New York City</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analyst, decision sciences</th>\n",
       "      <td>Publicis Groupe</td>\n",
       "      <td>New York City, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>Consulting</td>\n",
       "      <td>Health care</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "      <td>New York City</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analytics engineer</th>\n",
       "      <td>Oxfam America</td>\n",
       "      <td>Boston, MA, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>84000.0</td>\n",
       "      <td>Agile</td>\n",
       "      <td>Career development</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "      <td>Boston</td>\n",
       "      <td>MA, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bi analyst ¬ñ based in parsippany-troy hills, nj</th>\n",
       "      <td>NielsenIQ</td>\n",
       "      <td>Parsippany-Troy Hills, NJ, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Business Intelligence</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Parsippany-Troy Hills</td>\n",
       "      <td>NJ, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>broadcast research analyst</th>\n",
       "      <td>Sportradar</td>\n",
       "      <td>Remote, New York, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>45000.0</td>\n",
       "      <td>Data analysis</td>\n",
       "      <td>401(k) matching</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "      <td>Remote</td>\n",
       "      <td>New York, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>business/data analyst intern (graduate student)</th>\n",
       "      <td>Bosch Group</td>\n",
       "      <td>Burnsville, MN, United States</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Economics</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>False</td>\n",
       "      <td>--</td>\n",
       "      <td>Burnsville</td>\n",
       "      <td>MN, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clinical data analyst</th>\n",
       "      <td>SGS</td>\n",
       "      <td>Richardson, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Richardson</td>\n",
       "      <td>TX, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnsp surface force training requirements &amp; data analyst</th>\n",
       "      <td>Sigma Defense</td>\n",
       "      <td>San Diego, California, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>Excel</td>\n",
       "      <td>Career development</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>California, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>course associate, data analysis and visualization in sustainability (fall 2023)</th>\n",
       "      <td>Columbia University</td>\n",
       "      <td>New York City, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>Data analysis</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>New York City</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer success &amp; insight analyst</th>\n",
       "      <td>NielsenIQ</td>\n",
       "      <td>Knoxville, TN, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>Business Intelligence</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Knoxville</td>\n",
       "      <td>TN, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data analyst</th>\n",
       "      <td>Hitch</td>\n",
       "      <td>Austin, Texas, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Startup environment</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Texas, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data analyst (dea)</th>\n",
       "      <td>WWC Global</td>\n",
       "      <td>New York City, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Consulting</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>New York City</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data analyst (jira &amp; azure devops or hp alm) - remote</th>\n",
       "      <td>matchpoint solutions</td>\n",
       "      <td>California, California, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Azure</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>California</td>\n",
       "      <td>California, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data analyst intern</th>\n",
       "      <td>Bosch Group</td>\n",
       "      <td>Mount Prospect, IL, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Industrial</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>False</td>\n",
       "      <td>--</td>\n",
       "      <td>Mount Prospect</td>\n",
       "      <td>IL, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data architect, internal it (remote in us)</th>\n",
       "      <td>Resultant</td>\n",
       "      <td>Indianapolis, IN, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>APIs</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>IN, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data engineer</th>\n",
       "      <td>Adtalem Global Education</td>\n",
       "      <td>Remote, REMOTE, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>71000.0</td>\n",
       "      <td>Airflow</td>\n",
       "      <td>401(k) matching</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "      <td>Remote</td>\n",
       "      <td>REMOTE, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data engineering analyst</th>\n",
       "      <td>Publicis Groupe</td>\n",
       "      <td>New York City, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>AWS</td>\n",
       "      <td>Career development</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "      <td>New York City</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data integration support representative</th>\n",
       "      <td>Renaissance</td>\n",
       "      <td>Remote, REMOTE, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>401(k) matching</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "      <td>Remote</td>\n",
       "      <td>REMOTE, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data management supervisor</th>\n",
       "      <td>Eurofins</td>\n",
       "      <td>Saint Charles, MO, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>Data management</td>\n",
       "      <td>401(k) matching</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Saint Charles</td>\n",
       "      <td>MO, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data quality analyst</th>\n",
       "      <td>Qualtrics</td>\n",
       "      <td>Provo, Utah, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>APIs</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Provo</td>\n",
       "      <td>Utah, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data science &amp; analytics internships ¬ñ academic year</th>\n",
       "      <td>NBCUniversal</td>\n",
       "      <td>Universal City, CA, United States</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AWS</td>\n",
       "      <td>Career development</td>\n",
       "      <td>False</td>\n",
       "      <td>--</td>\n",
       "      <td>Universal City</td>\n",
       "      <td>CA, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data science intern</th>\n",
       "      <td>Equip Health</td>\n",
       "      <td>Remote United States</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AWS</td>\n",
       "      <td>Career development</td>\n",
       "      <td>False</td>\n",
       "      <td>--</td>\n",
       "      <td>Remote United States</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data science lead</th>\n",
       "      <td>Bosch Group</td>\n",
       "      <td>Mount Prospect, IL, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>A/B testing</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Mount Prospect</td>\n",
       "      <td>IL, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data scientist</th>\n",
       "      <td>NBCUniversal</td>\n",
       "      <td>New York, NEW YORK, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Career development</td>\n",
       "      <td>False</td>\n",
       "      <td>--</td>\n",
       "      <td>New York</td>\n",
       "      <td>NEW YORK, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data scientist (elasticsearch)</th>\n",
       "      <td>CGG</td>\n",
       "      <td>Houston, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>Agile</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data scientist (real-time ops)</th>\n",
       "      <td>Gridware</td>\n",
       "      <td>Walnut Creek, California, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>Data analysis</td>\n",
       "      <td>401(k) matching</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Walnut Creek</td>\n",
       "      <td>California, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data scientist - digitalization, trading &amp; origination</th>\n",
       "      <td>Statkraft</td>\n",
       "      <td>Stamford, CT, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>Ansible</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Stamford</td>\n",
       "      <td>CT, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data scientist intern</th>\n",
       "      <td>Zscaler</td>\n",
       "      <td>San Jose, CA, United States</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Agile</td>\n",
       "      <td>Career development</td>\n",
       "      <td>False</td>\n",
       "      <td>--</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>CA, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entry level (recent tech grads) bi analyst - must be us-based</th>\n",
       "      <td>NielsenIQ</td>\n",
       "      <td>Parsippany-Troy Hills, NJ, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Business Intelligence</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Parsippany-Troy Hills</td>\n",
       "      <td>NJ, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entry level (recent tech grads) business intelligence analyst ¬ñ parsippany-troy hills, nj</th>\n",
       "      <td>NielsenIQ</td>\n",
       "      <td>Parsippany-Troy Hills, NJ, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>Business Intelligence</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Parsippany-Troy Hills</td>\n",
       "      <td>NJ, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entry level data scientist</th>\n",
       "      <td>Eurofins</td>\n",
       "      <td>Lancaster, PA, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>401(k) matching</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Lancaster</td>\n",
       "      <td>PA, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>field sample specialist (air samples) - eurofins environment testing ¬ñ pueblo, co</th>\n",
       "      <td>Eurofins</td>\n",
       "      <td>Pueblo, CO, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>Career development</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "      <td>Pueblo</td>\n",
       "      <td>CO, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>information technology data analyst</th>\n",
       "      <td>OceanaGold</td>\n",
       "      <td>Kershaw, South Carolina, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Data management</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Kershaw</td>\n",
       "      <td>South Carolina, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>junior data analyst</th>\n",
       "      <td>Liquid Advertising</td>\n",
       "      <td>United States - Remote</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>Excel</td>\n",
       "      <td>401(k) matching</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "      <td>United States - Remote</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>junior software engineer - python / java / ai / ml</th>\n",
       "      <td>Captivation Software</td>\n",
       "      <td>Annapolis Junction, Maryland, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>401(k) matching</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "      <td>Annapolis Junction</td>\n",
       "      <td>Maryland, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead data scientist</th>\n",
       "      <td>Verisk</td>\n",
       "      <td>Jersey City, NJ, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>Big Data</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>NJ, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine learning engineer</th>\n",
       "      <td>CGG</td>\n",
       "      <td>Houston, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>Architecture</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine learning engineer intern</th>\n",
       "      <td>Firework</td>\n",
       "      <td>United States, Remote</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>AWS</td>\n",
       "      <td>Career development</td>\n",
       "      <td>False</td>\n",
       "      <td>--</td>\n",
       "      <td>United States</td>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>machine learning for natural language processing intern</th>\n",
       "      <td>Bosch Group</td>\n",
       "      <td>Sunnyvale, CA, United States</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Autonomous Driving</td>\n",
       "      <td>Conferences</td>\n",
       "      <td>False</td>\n",
       "      <td>--</td>\n",
       "      <td>Sunnyvale</td>\n",
       "      <td>CA, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural language processing intern</th>\n",
       "      <td>Bosch Group</td>\n",
       "      <td>Sunnyvale, CA, United States</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>APIs</td>\n",
       "      <td>Conferences</td>\n",
       "      <td>False</td>\n",
       "      <td>--</td>\n",
       "      <td>Sunnyvale</td>\n",
       "      <td>CA, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nlp engineer</th>\n",
       "      <td>CGG</td>\n",
       "      <td>Houston, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>Architecture</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>phd machine learning engineer intern (fall 2023)</th>\n",
       "      <td>Block</td>\n",
       "      <td>San Francisco, CA, United States</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Architecture</td>\n",
       "      <td>Career development</td>\n",
       "      <td>False</td>\n",
       "      <td>--</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pre-college instructor, big data, machine learning &amp; their real world applications (on-campus) summer 2023</th>\n",
       "      <td>Columbia University</td>\n",
       "      <td>New York City, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>Big Data</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>New York City</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product manager for healthcare ai products</th>\n",
       "      <td>John Snow Labs</td>\n",
       "      <td>Remote, REMOTE, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>39000.0</td>\n",
       "      <td>Big Data</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Remote</td>\n",
       "      <td>REMOTE, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>program management data analytics internships ¬ñ academic year</th>\n",
       "      <td>NBCUniversal</td>\n",
       "      <td>New York City, United States</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Business Analytics</td>\n",
       "      <td>Career development</td>\n",
       "      <td>False</td>\n",
       "      <td>--</td>\n",
       "      <td>New York City</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>research engineer- atmospheric perils vulnerability</th>\n",
       "      <td>Verisk</td>\n",
       "      <td>Boston, MA, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>Data Mining</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Boston</td>\n",
       "      <td>MA, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>research scientist - machine learning and algorithms</th>\n",
       "      <td>Granica</td>\n",
       "      <td>Mountain View, California, United States, Remote</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>401(k) matching</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "      <td>Mountain View</td>\n",
       "      <td>California, United States, Remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rotational development program - artificial intelligence and machine learning trainee</th>\n",
       "      <td>Bosch Group</td>\n",
       "      <td>Plymouth, MI, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>44000.0</td>\n",
       "      <td>Airflow</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Plymouth</td>\n",
       "      <td>MI, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seismic imaging analyst</th>\n",
       "      <td>CGG</td>\n",
       "      <td>Houston, TX, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>85000.0</td>\n",
       "      <td>Data analysis</td>\n",
       "      <td>401(k) matching</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>senior data scientist</th>\n",
       "      <td>Verisk</td>\n",
       "      <td>Jersey City, NJ, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>39000.0</td>\n",
       "      <td>Big Data</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>NJ, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>software engineer, computer vision program</th>\n",
       "      <td>CCRi</td>\n",
       "      <td>Charlottesville, Virginia, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>84000.0</td>\n",
       "      <td>Agile</td>\n",
       "      <td>401(k) matching</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "      <td>Charlottesville</td>\n",
       "      <td>Virginia, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>software engineer, data streaming platform</th>\n",
       "      <td>Block</td>\n",
       "      <td>Atlanta, GA, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>Airflow</td>\n",
       "      <td>Career development</td>\n",
       "      <td>False</td>\n",
       "      <td>USD</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>GA, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>specification coordinator - data management</th>\n",
       "      <td>Eurofins</td>\n",
       "      <td>Ithaca, NY, United States</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>39000.0</td>\n",
       "      <td>Data management</td>\n",
       "      <td>Flex hours</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Ithaca</td>\n",
       "      <td>NY, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>summer 2023 data engineering intern</th>\n",
       "      <td>Western Digital</td>\n",
       "      <td>San Jose, CA, United States</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Big Data</td>\n",
       "      <td>Career development</td>\n",
       "      <td>False</td>\n",
       "      <td>--</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>CA, United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                     Company  \\\n",
       "Job Title                                                                      \n",
       "3d data quality analyst - contract                           Geomagical Labs   \n",
       "act two program- sr. analyst, data quality                      NBCUniversal   \n",
       "analyst - business intelligence (us remote in e...                 NielsenIQ   \n",
       "analyst, business intelligence                               Publicis Groupe   \n",
       "analyst, data engineering                                    Publicis Groupe   \n",
       "analyst, decision sciences                                   Publicis Groupe   \n",
       "analytics engineer                                             Oxfam America   \n",
       "bi analyst ¬ñ based in parsippany-troy hills, nj                    NielsenIQ   \n",
       "broadcast research analyst                                        Sportradar   \n",
       "business/data analyst intern (graduate student)                  Bosch Group   \n",
       "clinical data analyst                                                    SGS   \n",
       "cnsp surface force training requirements & data...             Sigma Defense   \n",
       "course associate, data analysis and visualizati...       Columbia University   \n",
       "customer success & insight analyst                                 NielsenIQ   \n",
       "data analyst                                                           Hitch   \n",
       "data analyst (dea)                                                WWC Global   \n",
       "data analyst (jira & azure devops or hp alm) - ...      matchpoint solutions   \n",
       "data analyst intern                                              Bosch Group   \n",
       "data architect, internal it (remote in us)                         Resultant   \n",
       "data engineer                                       Adtalem Global Education   \n",
       "data engineering analyst                                     Publicis Groupe   \n",
       "data integration support representative                          Renaissance   \n",
       "data management supervisor                                          Eurofins   \n",
       "data quality analyst                                               Qualtrics   \n",
       "data science & analytics internships ¬ñ academic...              NBCUniversal   \n",
       "data science intern                                             Equip Health   \n",
       "data science lead                                                Bosch Group   \n",
       "data scientist                                                  NBCUniversal   \n",
       "data scientist (elasticsearch)                                           CGG   \n",
       "data scientist (real-time ops)                                      Gridware   \n",
       "data scientist - digitalization, trading & orig...                 Statkraft   \n",
       "data scientist intern                                                Zscaler   \n",
       "entry level (recent tech grads) bi analyst - mu...                 NielsenIQ   \n",
       "entry level (recent tech grads) business intell...                 NielsenIQ   \n",
       "entry level data scientist                                          Eurofins   \n",
       "field sample specialist (air samples) - eurofin...                  Eurofins   \n",
       "information technology data analyst                               OceanaGold   \n",
       "junior data analyst                                       Liquid Advertising   \n",
       "junior software engineer - python / java / ai / ml      Captivation Software   \n",
       "lead data scientist                                                   Verisk   \n",
       "machine learning engineer                                                CGG   \n",
       "machine learning engineer intern                                    Firework   \n",
       "machine learning for natural language processin...               Bosch Group   \n",
       "natural language processing intern                               Bosch Group   \n",
       "nlp engineer                                                             CGG   \n",
       "phd machine learning engineer intern (fall 2023)                       Block   \n",
       "pre-college instructor, big data, machine learn...       Columbia University   \n",
       "product manager for healthcare ai products                    John Snow Labs   \n",
       "program management data analytics internships ¬ñ...              NBCUniversal   \n",
       "research engineer- atmospheric perils vulnerabi...                    Verisk   \n",
       "research scientist - machine learning and algor...                   Granica   \n",
       "rotational development program - artificial int...               Bosch Group   \n",
       "seismic imaging analyst                                                  CGG   \n",
       "senior data scientist                                                 Verisk   \n",
       "software engineer, computer vision program                              CCRi   \n",
       "software engineer, data streaming platform                             Block   \n",
       "specification coordinator - data management                         Eurofins   \n",
       "summer 2023 data engineering intern                          Western Digital   \n",
       "\n",
       "                                                                                            Location  \\\n",
       "Job Title                                                                                              \n",
       "3d data quality analyst - contract                              Palo Alto, California, United States   \n",
       "act two program- sr. analyst, data quality                         New York, NEW YORK, United States   \n",
       "analyst - business intelligence (us remote in e...                        Atlanta, GA, United States   \n",
       "analyst, business intelligence                                       Philadelphia, PA, United States   \n",
       "analyst, data engineering                                               New York City, United States   \n",
       "analyst, decision sciences                                              New York City, United States   \n",
       "analytics engineer                                                         Boston, MA, United States   \n",
       "bi analyst ¬ñ based in parsippany-troy hills, nj             Parsippany-Troy Hills, NJ, United States   \n",
       "broadcast research analyst                                           Remote, New York, United States   \n",
       "business/data analyst intern (graduate student)                        Burnsville, MN, United States   \n",
       "clinical data analyst                                                  Richardson, TX, United States   \n",
       "cnsp surface force training requirements & data...              San Diego, California, United States   \n",
       "course associate, data analysis and visualizati...                      New York City, United States   \n",
       "customer success & insight analyst                                      Knoxville, TN, United States   \n",
       "data analyst                                                            Austin, Texas, United States   \n",
       "data analyst (dea)                                                      New York City, United States   \n",
       "data analyst (jira & azure devops or hp alm) - ...             California, California, United States   \n",
       "data analyst intern                                                Mount Prospect, IL, United States   \n",
       "data architect, internal it (remote in us)                           Indianapolis, IN, United States   \n",
       "data engineer                                                          Remote, REMOTE, United States   \n",
       "data engineering analyst                                                New York City, United States   \n",
       "data integration support representative                                Remote, REMOTE, United States   \n",
       "data management supervisor                                          Saint Charles, MO, United States   \n",
       "data quality analyst                                                      Provo, Utah, United States   \n",
       "data science & analytics internships ¬ñ academic...                 Universal City, CA, United States   \n",
       "data science intern                                                             Remote United States   \n",
       "data science lead                                                  Mount Prospect, IL, United States   \n",
       "data scientist                                                     New York, NEW YORK, United States   \n",
       "data scientist (elasticsearch)                                            Houston, TX, United States   \n",
       "data scientist (real-time ops)                               Walnut Creek, California, United States   \n",
       "data scientist - digitalization, trading & orig...                       Stamford, CT, United States   \n",
       "data scientist intern                                                    San Jose, CA, United States   \n",
       "entry level (recent tech grads) bi analyst - mu...          Parsippany-Troy Hills, NJ, United States   \n",
       "entry level (recent tech grads) business intell...          Parsippany-Troy Hills, NJ, United States   \n",
       "entry level data scientist                                              Lancaster, PA, United States   \n",
       "field sample specialist (air samples) - eurofin...                         Pueblo, CO, United States   \n",
       "information technology data analyst                           Kershaw, South Carolina, United States   \n",
       "junior data analyst                                                           United States - Remote   \n",
       "junior software engineer - python / java / ai / ml       Annapolis Junction, Maryland, United States   \n",
       "lead data scientist                                                   Jersey City, NJ, United States   \n",
       "machine learning engineer                                                 Houston, TX, United States   \n",
       "machine learning engineer intern                                               United States, Remote   \n",
       "machine learning for natural language processin...                      Sunnyvale, CA, United States   \n",
       "natural language processing intern                                      Sunnyvale, CA, United States   \n",
       "nlp engineer                                                              Houston, TX, United States   \n",
       "phd machine learning engineer intern (fall 2023)                    San Francisco, CA, United States   \n",
       "pre-college instructor, big data, machine learn...                      New York City, United States   \n",
       "product manager for healthcare ai products                             Remote, REMOTE, United States   \n",
       "program management data analytics internships ¬ñ...                      New York City, United States   \n",
       "research engineer- atmospheric perils vulnerabi...                         Boston, MA, United States   \n",
       "research scientist - machine learning and algor...  Mountain View, California, United States, Remote   \n",
       "rotational development program - artificial int...                       Plymouth, MI, United States   \n",
       "seismic imaging analyst                                                   Houston, TX, United States   \n",
       "senior data scientist                                                 Jersey City, NJ, United States   \n",
       "software engineer, computer vision program                  Charlottesville, Virginia, United States   \n",
       "software engineer, data streaming platform                                Atlanta, GA, United States   \n",
       "specification coordinator - data management                                Ithaca, NY, United States   \n",
       "summer 2023 data engineering intern                                      San Jose, CA, United States   \n",
       "\n",
       "                                                      Job Type  \\\n",
       "Job Title                                                        \n",
       "3d data quality analyst - contract                   Full Time   \n",
       "act two program- sr. analyst, data quality           Full Time   \n",
       "analyst - business intelligence (us remote in e...   Full Time   \n",
       "analyst, business intelligence                       Full Time   \n",
       "analyst, data engineering                            Full Time   \n",
       "analyst, decision sciences                           Full Time   \n",
       "analytics engineer                                   Full Time   \n",
       "bi analyst ¬ñ based in parsippany-troy hills, nj      Full Time   \n",
       "broadcast research analyst                           Full Time   \n",
       "business/data analyst intern (graduate student)     Internship   \n",
       "clinical data analyst                                Full Time   \n",
       "cnsp surface force training requirements & data...   Full Time   \n",
       "course associate, data analysis and visualizati...   Full Time   \n",
       "customer success & insight analyst                   Full Time   \n",
       "data analyst                                         Full Time   \n",
       "data analyst (dea)                                   Full Time   \n",
       "data analyst (jira & azure devops or hp alm) - ...   Full Time   \n",
       "data analyst intern                                  Full Time   \n",
       "data architect, internal it (remote in us)           Full Time   \n",
       "data engineer                                        Full Time   \n",
       "data engineering analyst                             Full Time   \n",
       "data integration support representative              Full Time   \n",
       "data management supervisor                           Full Time   \n",
       "data quality analyst                                 Full Time   \n",
       "data science & analytics internships ¬ñ academic...  Internship   \n",
       "data science intern                                 Internship   \n",
       "data science lead                                    Full Time   \n",
       "data scientist                                       Full Time   \n",
       "data scientist (elasticsearch)                       Full Time   \n",
       "data scientist (real-time ops)                       Full Time   \n",
       "data scientist - digitalization, trading & orig...   Full Time   \n",
       "data scientist intern                               Internship   \n",
       "entry level (recent tech grads) bi analyst - mu...   Full Time   \n",
       "entry level (recent tech grads) business intell...   Full Time   \n",
       "entry level data scientist                           Full Time   \n",
       "field sample specialist (air samples) - eurofin...   Full Time   \n",
       "information technology data analyst                  Full Time   \n",
       "junior data analyst                                  Full Time   \n",
       "junior software engineer - python / java / ai / ml   Full Time   \n",
       "lead data scientist                                  Full Time   \n",
       "machine learning engineer                            Full Time   \n",
       "machine learning engineer intern                    Internship   \n",
       "machine learning for natural language processin...  Internship   \n",
       "natural language processing intern                  Internship   \n",
       "nlp engineer                                         Full Time   \n",
       "phd machine learning engineer intern (fall 2023)    Internship   \n",
       "pre-college instructor, big data, machine learn...   Full Time   \n",
       "product manager for healthcare ai products           Full Time   \n",
       "program management data analytics internships ¬ñ...  Internship   \n",
       "research engineer- atmospheric perils vulnerabi...   Full Time   \n",
       "research scientist - machine learning and algor...   Full Time   \n",
       "rotational development program - artificial int...   Full Time   \n",
       "seismic imaging analyst                              Full Time   \n",
       "senior data scientist                                Full Time   \n",
       "software engineer, computer vision program           Full Time   \n",
       "software engineer, data streaming platform           Full Time   \n",
       "specification coordinator - data management          Full Time   \n",
       "summer 2023 data engineering intern                 Internship   \n",
       "\n",
       "                                                   Experience level    Salary  \\\n",
       "Job Title                                                                       \n",
       "3d data quality analyst - contract                      Entry-level   39000.0   \n",
       "act two program- sr. analyst, data quality              Entry-level       0.0   \n",
       "analyst - business intelligence (us remote in e...      Entry-level   39000.0   \n",
       "analyst, business intelligence                          Entry-level   44000.0   \n",
       "analyst, data engineering                               Entry-level   52000.0   \n",
       "analyst, decision sciences                              Entry-level   52000.0   \n",
       "analytics engineer                                      Entry-level   84000.0   \n",
       "bi analyst ¬ñ based in parsippany-troy hills, nj         Entry-level   48000.0   \n",
       "broadcast research analyst                              Entry-level   45000.0   \n",
       "business/data analyst intern (graduate student)         Entry-level       0.0   \n",
       "clinical data analyst                                   Entry-level   48000.0   \n",
       "cnsp surface force training requirements & data...      Entry-level  105000.0   \n",
       "course associate, data analysis and visualizati...      Entry-level   44000.0   \n",
       "customer success & insight analyst                      Entry-level   44000.0   \n",
       "data analyst                                            Entry-level   48000.0   \n",
       "data analyst (dea)                                      Entry-level   48000.0   \n",
       "data analyst (jira & azure devops or hp alm) - ...      Entry-level   48000.0   \n",
       "data analyst intern                                     Entry-level       0.0   \n",
       "data architect, internal it (remote in us)              Entry-level  135000.0   \n",
       "data engineer                                           Entry-level   71000.0   \n",
       "data engineering analyst                                Entry-level   52000.0   \n",
       "data integration support representative                 Entry-level   40000.0   \n",
       "data management supervisor                              Entry-level   44000.0   \n",
       "data quality analyst                                    Entry-level   44000.0   \n",
       "data science & analytics internships ¬ñ academic...      Entry-level       0.0   \n",
       "data science intern                                     Entry-level       0.0   \n",
       "data science lead                                       Entry-level   44000.0   \n",
       "data scientist                                          Entry-level       0.0   \n",
       "data scientist (elasticsearch)                          Entry-level   40000.0   \n",
       "data scientist (real-time ops)                          Entry-level   40000.0   \n",
       "data scientist - digitalization, trading & orig...      Entry-level   40000.0   \n",
       "data scientist intern                                   Entry-level       0.0   \n",
       "entry level (recent tech grads) bi analyst - mu...      Entry-level   48000.0   \n",
       "entry level (recent tech grads) business intell...      Entry-level   44000.0   \n",
       "entry level data scientist                              Entry-level   44000.0   \n",
       "field sample specialist (air samples) - eurofin...      Entry-level   40000.0   \n",
       "information technology data analyst                     Entry-level   48000.0   \n",
       "junior data analyst                                     Entry-level   40000.0   \n",
       "junior software engineer - python / java / ai / ml      Entry-level  125000.0   \n",
       "lead data scientist                                     Entry-level   40000.0   \n",
       "machine learning engineer                               Entry-level   30000.0   \n",
       "machine learning engineer intern                        Entry-level       0.0   \n",
       "machine learning for natural language processin...      Entry-level       0.0   \n",
       "natural language processing intern                      Entry-level       0.0   \n",
       "nlp engineer                                            Entry-level   44000.0   \n",
       "phd machine learning engineer intern (fall 2023)        Entry-level       0.0   \n",
       "pre-college instructor, big data, machine learn...      Entry-level   44000.0   \n",
       "product manager for healthcare ai products              Entry-level   39000.0   \n",
       "program management data analytics internships ¬ñ...      Entry-level       0.0   \n",
       "research engineer- atmospheric perils vulnerabi...      Entry-level  105000.0   \n",
       "research scientist - machine learning and algor...      Entry-level  120000.0   \n",
       "rotational development program - artificial int...      Entry-level   44000.0   \n",
       "seismic imaging analyst                                 Entry-level   85000.0   \n",
       "senior data scientist                                   Entry-level   39000.0   \n",
       "software engineer, computer vision program              Entry-level   84000.0   \n",
       "software engineer, data streaming platform              Entry-level  129000.0   \n",
       "specification coordinator - data management             Entry-level   39000.0   \n",
       "summer 2023 data engineering intern                     Entry-level       0.0   \n",
       "\n",
       "                                                   Requirment of the company   \\\n",
       "Job Title                                                                       \n",
       "3d data quality analyst - contract                                3D graphics   \n",
       "act two program- sr. analyst, data quality                              Agile   \n",
       "analyst - business intelligence (us remote in e...      Business Intelligence   \n",
       "analyst, business intelligence                          Business Intelligence   \n",
       "analyst, data engineering                                                 AWS   \n",
       "analyst, decision sciences                                         Consulting   \n",
       "analytics engineer                                                      Agile   \n",
       "bi analyst ¬ñ based in parsippany-troy hills, nj         Business Intelligence   \n",
       "broadcast research analyst                                      Data analysis   \n",
       "business/data analyst intern (graduate student)                     Economics   \n",
       "clinical data analyst                                        Computer Science   \n",
       "cnsp surface force training requirements & data...                      Excel   \n",
       "course associate, data analysis and visualizati...              Data analysis   \n",
       "customer success & insight analyst                      Business Intelligence   \n",
       "data analyst                                                 Computer Science   \n",
       "data analyst (dea)                                                 Consulting   \n",
       "data analyst (jira & azure devops or hp alm) - ...                      Azure   \n",
       "data analyst intern                                                Industrial   \n",
       "data architect, internal it (remote in us)                               APIs   \n",
       "data engineer                                                         Airflow   \n",
       "data engineering analyst                                                  AWS   \n",
       "data integration support representative                      Computer Science   \n",
       "data management supervisor                                    Data management   \n",
       "data quality analyst                                                     APIs   \n",
       "data science & analytics internships ¬ñ academic...                        AWS   \n",
       "data science intern                                                       AWS   \n",
       "data science lead                                                 A/B testing   \n",
       "data scientist                                               Computer Science   \n",
       "data scientist (elasticsearch)                                          Agile   \n",
       "data scientist (real-time ops)                                  Data analysis   \n",
       "data scientist - digitalization, trading & orig...                    Ansible   \n",
       "data scientist intern                                                   Agile   \n",
       "entry level (recent tech grads) bi analyst - mu...      Business Intelligence   \n",
       "entry level (recent tech grads) business intell...      Business Intelligence   \n",
       "entry level data scientist                                          Chemistry   \n",
       "field sample specialist (air samples) - eurofin...                  Chemistry   \n",
       "information technology data analyst                           Data management   \n",
       "junior data analyst                                                     Excel   \n",
       "junior software engineer - python / java / ai / ml           Computer Science   \n",
       "lead data scientist                                                  Big Data   \n",
       "machine learning engineer                                        Architecture   \n",
       "machine learning engineer intern                                          AWS   \n",
       "machine learning for natural language processin...         Autonomous Driving   \n",
       "natural language processing intern                                       APIs   \n",
       "nlp engineer                                                     Architecture   \n",
       "phd machine learning engineer intern (fall 2023)                 Architecture   \n",
       "pre-college instructor, big data, machine learn...                   Big Data   \n",
       "product manager for healthcare ai products                           Big Data   \n",
       "program management data analytics internships ¬ñ...         Business Analytics   \n",
       "research engineer- atmospheric perils vulnerabi...                Data Mining   \n",
       "research scientist - machine learning and algor...           Computer Science   \n",
       "rotational development program - artificial int...                    Airflow   \n",
       "seismic imaging analyst                                         Data analysis   \n",
       "senior data scientist                                                Big Data   \n",
       "software engineer, computer vision program                              Agile   \n",
       "software engineer, data streaming platform                            Airflow   \n",
       "specification coordinator - data management                   Data management   \n",
       "summer 2023 data engineering intern                                  Big Data   \n",
       "\n",
       "                                                             Facilities  \\\n",
       "Job Title                                                                 \n",
       "3d data quality analyst - contract                           Flex hours   \n",
       "act two program- sr. analyst, data quality           Career development   \n",
       "analyst - business intelligence (us remote in e...           Flex hours   \n",
       "analyst, business intelligence                      Startup environment   \n",
       "analyst, data engineering                            Career development   \n",
       "analyst, decision sciences                                  Health care   \n",
       "analytics engineer                                   Career development   \n",
       "bi analyst ¬ñ based in parsippany-troy hills, nj      Career development   \n",
       "broadcast research analyst                              401(k) matching   \n",
       "business/data analyst intern (graduate student)           no-Facilities   \n",
       "clinical data analyst                                     no-Facilities   \n",
       "cnsp surface force training requirements & data...   Career development   \n",
       "course associate, data analysis and visualizati...        no-Facilities   \n",
       "customer success & insight analyst                        no-Facilities   \n",
       "data analyst                                        Startup environment   \n",
       "data analyst (dea)                                   Career development   \n",
       "data analyst (jira & azure devops or hp alm) - ...        no-Facilities   \n",
       "data analyst intern                                       no-Facilities   \n",
       "data architect, internal it (remote in us)           Career development   \n",
       "data engineer                                           401(k) matching   \n",
       "data engineering analyst                             Career development   \n",
       "data integration support representative                 401(k) matching   \n",
       "data management supervisor                              401(k) matching   \n",
       "data quality analyst                                      no-Facilities   \n",
       "data science & analytics internships ¬ñ academic...   Career development   \n",
       "data science intern                                  Career development   \n",
       "data science lead                                    Career development   \n",
       "data scientist                                       Career development   \n",
       "data scientist (elasticsearch)                       Career development   \n",
       "data scientist (real-time ops)                          401(k) matching   \n",
       "data scientist - digitalization, trading & orig...   Career development   \n",
       "data scientist intern                                Career development   \n",
       "entry level (recent tech grads) bi analyst - mu...   Career development   \n",
       "entry level (recent tech grads) business intell...   Career development   \n",
       "entry level data scientist                              401(k) matching   \n",
       "field sample specialist (air samples) - eurofin...   Career development   \n",
       "information technology data analyst                  Career development   \n",
       "junior data analyst                                     401(k) matching   \n",
       "junior software engineer - python / java / ai / ml      401(k) matching   \n",
       "lead data scientist                                  Career development   \n",
       "machine learning engineer                            Career development   \n",
       "machine learning engineer intern                     Career development   \n",
       "machine learning for natural language processin...          Conferences   \n",
       "natural language processing intern                          Conferences   \n",
       "nlp engineer                                         Career development   \n",
       "phd machine learning engineer intern (fall 2023)     Career development   \n",
       "pre-college instructor, big data, machine learn...        no-Facilities   \n",
       "product manager for healthcare ai products                no-Facilities   \n",
       "program management data analytics internships ¬ñ...   Career development   \n",
       "research engineer- atmospheric perils vulnerabi...   Career development   \n",
       "research scientist - machine learning and algor...      401(k) matching   \n",
       "rotational development program - artificial int...   Career development   \n",
       "seismic imaging analyst                                 401(k) matching   \n",
       "senior data scientist                                Career development   \n",
       "software engineer, computer vision program              401(k) matching   \n",
       "software engineer, data streaming platform           Career development   \n",
       "specification coordinator - data management                  Flex hours   \n",
       "summer 2023 data engineering intern                  Career development   \n",
       "\n",
       "                                                     Plus Currency  \\\n",
       "Job Title                                                            \n",
       "3d data quality analyst - contract                   True      USD   \n",
       "act two program- sr. analyst, data quality          False       --   \n",
       "analyst - business intelligence (us remote in e...   True      USD   \n",
       "analyst, business intelligence                       True      USD   \n",
       "analyst, data engineering                           False      USD   \n",
       "analyst, decision sciences                          False      USD   \n",
       "analytics engineer                                  False      USD   \n",
       "bi analyst ¬ñ based in parsippany-troy hills, nj      True      USD   \n",
       "broadcast research analyst                          False      USD   \n",
       "business/data analyst intern (graduate student)     False       --   \n",
       "clinical data analyst                                True      USD   \n",
       "cnsp surface force training requirements & data...  False      USD   \n",
       "course associate, data analysis and visualizati...   True      USD   \n",
       "customer success & insight analyst                   True      USD   \n",
       "data analyst                                         True      USD   \n",
       "data analyst (dea)                                   True      USD   \n",
       "data analyst (jira & azure devops or hp alm) - ...   True      USD   \n",
       "data analyst intern                                 False       --   \n",
       "data architect, internal it (remote in us)           True      USD   \n",
       "data engineer                                       False      USD   \n",
       "data engineering analyst                            False      USD   \n",
       "data integration support representative             False      USD   \n",
       "data management supervisor                           True      USD   \n",
       "data quality analyst                                 True      USD   \n",
       "data science & analytics internships ¬ñ academic...  False       --   \n",
       "data science intern                                 False       --   \n",
       "data science lead                                    True      USD   \n",
       "data scientist                                      False       --   \n",
       "data scientist (elasticsearch)                       True      USD   \n",
       "data scientist (real-time ops)                       True      USD   \n",
       "data scientist - digitalization, trading & orig...   True      USD   \n",
       "data scientist intern                               False       --   \n",
       "entry level (recent tech grads) bi analyst - mu...   True      USD   \n",
       "entry level (recent tech grads) business intell...   True      USD   \n",
       "entry level data scientist                           True      USD   \n",
       "field sample specialist (air samples) - eurofin...  False      USD   \n",
       "information technology data analyst                  True      USD   \n",
       "junior data analyst                                 False      USD   \n",
       "junior software engineer - python / java / ai / ml  False      USD   \n",
       "lead data scientist                                  True      USD   \n",
       "machine learning engineer                            True      USD   \n",
       "machine learning engineer intern                    False       --   \n",
       "machine learning for natural language processin...  False       --   \n",
       "natural language processing intern                  False       --   \n",
       "nlp engineer                                         True      USD   \n",
       "phd machine learning engineer intern (fall 2023)    False       --   \n",
       "pre-college instructor, big data, machine learn...   True      USD   \n",
       "product manager for healthcare ai products           True      USD   \n",
       "program management data analytics internships ¬ñ...  False       --   \n",
       "research engineer- atmospheric perils vulnerabi...   True      USD   \n",
       "research scientist - machine learning and algor...  False      USD   \n",
       "rotational development program - artificial int...   True      USD   \n",
       "seismic imaging analyst                             False      USD   \n",
       "senior data scientist                                True      USD   \n",
       "software engineer, computer vision program          False      USD   \n",
       "software engineer, data streaming platform          False      USD   \n",
       "specification coordinator - data management          True      USD   \n",
       "summer 2023 data engineering intern                 False       --   \n",
       "\n",
       "                                                       City_State_Location  \\\n",
       "Job Title                                                                    \n",
       "3d data quality analyst - contract                               Palo Alto   \n",
       "act two program- sr. analyst, data quality                        New York   \n",
       "analyst - business intelligence (us remote in e...                 Atlanta   \n",
       "analyst, business intelligence                                Philadelphia   \n",
       "analyst, data engineering                                    New York City   \n",
       "analyst, decision sciences                                   New York City   \n",
       "analytics engineer                                                  Boston   \n",
       "bi analyst ¬ñ based in parsippany-troy hills, nj      Parsippany-Troy Hills   \n",
       "broadcast research analyst                                          Remote   \n",
       "business/data analyst intern (graduate student)                 Burnsville   \n",
       "clinical data analyst                                           Richardson   \n",
       "cnsp surface force training requirements & data...               San Diego   \n",
       "course associate, data analysis and visualizati...           New York City   \n",
       "customer success & insight analyst                               Knoxville   \n",
       "data analyst                                                        Austin   \n",
       "data analyst (dea)                                           New York City   \n",
       "data analyst (jira & azure devops or hp alm) - ...              California   \n",
       "data analyst intern                                         Mount Prospect   \n",
       "data architect, internal it (remote in us)                    Indianapolis   \n",
       "data engineer                                                       Remote   \n",
       "data engineering analyst                                     New York City   \n",
       "data integration support representative                             Remote   \n",
       "data management supervisor                                   Saint Charles   \n",
       "data quality analyst                                                 Provo   \n",
       "data science & analytics internships ¬ñ academic...          Universal City   \n",
       "data science intern                                   Remote United States   \n",
       "data science lead                                           Mount Prospect   \n",
       "data scientist                                                    New York   \n",
       "data scientist (elasticsearch)                                     Houston   \n",
       "data scientist (real-time ops)                                Walnut Creek   \n",
       "data scientist - digitalization, trading & orig...                Stamford   \n",
       "data scientist intern                                             San Jose   \n",
       "entry level (recent tech grads) bi analyst - mu...   Parsippany-Troy Hills   \n",
       "entry level (recent tech grads) business intell...   Parsippany-Troy Hills   \n",
       "entry level data scientist                                       Lancaster   \n",
       "field sample specialist (air samples) - eurofin...                  Pueblo   \n",
       "information technology data analyst                                Kershaw   \n",
       "junior data analyst                                 United States - Remote   \n",
       "junior software engineer - python / java / ai / ml      Annapolis Junction   \n",
       "lead data scientist                                            Jersey City   \n",
       "machine learning engineer                                          Houston   \n",
       "machine learning engineer intern                             United States   \n",
       "machine learning for natural language processin...               Sunnyvale   \n",
       "natural language processing intern                               Sunnyvale   \n",
       "nlp engineer                                                       Houston   \n",
       "phd machine learning engineer intern (fall 2023)             San Francisco   \n",
       "pre-college instructor, big data, machine learn...           New York City   \n",
       "product manager for healthcare ai products                          Remote   \n",
       "program management data analytics internships ¬ñ...           New York City   \n",
       "research engineer- atmospheric perils vulnerabi...                  Boston   \n",
       "research scientist - machine learning and algor...           Mountain View   \n",
       "rotational development program - artificial int...                Plymouth   \n",
       "seismic imaging analyst                                            Houston   \n",
       "senior data scientist                                          Jersey City   \n",
       "software engineer, computer vision program                 Charlottesville   \n",
       "software engineer, data streaming platform                         Atlanta   \n",
       "specification coordinator - data management                         Ithaca   \n",
       "summer 2023 data engineering intern                               San Jose   \n",
       "\n",
       "                                                                      Country_Location  \n",
       "Job Title                                                                               \n",
       "3d data quality analyst - contract                           California, United States  \n",
       "act two program- sr. analyst, data quality                     NEW YORK, United States  \n",
       "analyst - business intelligence (us remote in e...                   GA, United States  \n",
       "analyst, business intelligence                                       PA, United States  \n",
       "analyst, data engineering                                                United States  \n",
       "analyst, decision sciences                                               United States  \n",
       "analytics engineer                                                   MA, United States  \n",
       "bi analyst ¬ñ based in parsippany-troy hills, nj                      NJ, United States  \n",
       "broadcast research analyst                                     New York, United States  \n",
       "business/data analyst intern (graduate student)                      MN, United States  \n",
       "clinical data analyst                                                TX, United States  \n",
       "cnsp surface force training requirements & data...           California, United States  \n",
       "course associate, data analysis and visualizati...                       United States  \n",
       "customer success & insight analyst                                   TN, United States  \n",
       "data analyst                                                      Texas, United States  \n",
       "data analyst (dea)                                                       United States  \n",
       "data analyst (jira & azure devops or hp alm) - ...           California, United States  \n",
       "data analyst intern                                                  IL, United States  \n",
       "data architect, internal it (remote in us)                           IN, United States  \n",
       "data engineer                                                    REMOTE, United States  \n",
       "data engineering analyst                                                 United States  \n",
       "data integration support representative                          REMOTE, United States  \n",
       "data management supervisor                                           MO, United States  \n",
       "data quality analyst                                               Utah, United States  \n",
       "data science & analytics internships ¬ñ academic...                   CA, United States  \n",
       "data science intern                                                               None  \n",
       "data science lead                                                    IL, United States  \n",
       "data scientist                                                 NEW YORK, United States  \n",
       "data scientist (elasticsearch)                                       TX, United States  \n",
       "data scientist (real-time ops)                               California, United States  \n",
       "data scientist - digitalization, trading & orig...                   CT, United States  \n",
       "data scientist intern                                                CA, United States  \n",
       "entry level (recent tech grads) bi analyst - mu...                   NJ, United States  \n",
       "entry level (recent tech grads) business intell...                   NJ, United States  \n",
       "entry level data scientist                                           PA, United States  \n",
       "field sample specialist (air samples) - eurofin...                   CO, United States  \n",
       "information technology data analyst                      South Carolina, United States  \n",
       "junior data analyst                                                               None  \n",
       "junior software engineer - python / java / ai / ml             Maryland, United States  \n",
       "lead data scientist                                                  NJ, United States  \n",
       "machine learning engineer                                            TX, United States  \n",
       "machine learning engineer intern                                                Remote  \n",
       "machine learning for natural language processin...                   CA, United States  \n",
       "natural language processing intern                                   CA, United States  \n",
       "nlp engineer                                                         TX, United States  \n",
       "phd machine learning engineer intern (fall 2023)                     CA, United States  \n",
       "pre-college instructor, big data, machine learn...                       United States  \n",
       "product manager for healthcare ai products                       REMOTE, United States  \n",
       "program management data analytics internships ¬ñ...                       United States  \n",
       "research engineer- atmospheric perils vulnerabi...                   MA, United States  \n",
       "research scientist - machine learning and algor...   California, United States, Remote  \n",
       "rotational development program - artificial int...                   MI, United States  \n",
       "seismic imaging analyst                                              TX, United States  \n",
       "senior data scientist                                                NJ, United States  \n",
       "software engineer, computer vision program                     Virginia, United States  \n",
       "software engineer, data streaming platform                           GA, United States  \n",
       "specification coordinator - data management                          NY, United States  \n",
       "summer 2023 data engineering intern                                  CA, United States  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intern.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Plus</th>\n",
       "      <th>Currency</th>\n",
       "      <th>City_State_Location</th>\n",
       "      <th>Country_Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17760</th>\n",
       "      <td>Mitek Systems</td>\n",
       "      <td>Machine Learning Researcher (internship)</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Computer Vision</td>\n",
       "      <td>Career development</td>\n",
       "      <td>False</td>\n",
       "      <td>--</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17761</th>\n",
       "      <td>Mitek Systems</td>\n",
       "      <td>Machine Learning Researcher (internship)</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Deep Learning</td>\n",
       "      <td>Career development</td>\n",
       "      <td>False</td>\n",
       "      <td>--</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17762</th>\n",
       "      <td>Mitek Systems</td>\n",
       "      <td>Machine Learning Researcher (internship)</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Docker</td>\n",
       "      <td>Career development</td>\n",
       "      <td>False</td>\n",
       "      <td>--</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17763</th>\n",
       "      <td>Mitek Systems</td>\n",
       "      <td>Machine Learning Researcher (internship)</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Git</td>\n",
       "      <td>Career development</td>\n",
       "      <td>False</td>\n",
       "      <td>--</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17764</th>\n",
       "      <td>Mitek Systems</td>\n",
       "      <td>Machine Learning Researcher (internship)</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Linux</td>\n",
       "      <td>Career development</td>\n",
       "      <td>False</td>\n",
       "      <td>--</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42949</th>\n",
       "      <td>Equip Health</td>\n",
       "      <td>Data Science intern</td>\n",
       "      <td>Remote United States</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Computer Science</td>\n",
       "      <td>Salary bonus</td>\n",
       "      <td>False</td>\n",
       "      <td>--</td>\n",
       "      <td>Remote United States</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42950</th>\n",
       "      <td>Equip Health</td>\n",
       "      <td>Data Science intern</td>\n",
       "      <td>Remote United States</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Genetics</td>\n",
       "      <td>Salary bonus</td>\n",
       "      <td>False</td>\n",
       "      <td>--</td>\n",
       "      <td>Remote United States</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42951</th>\n",
       "      <td>Equip Health</td>\n",
       "      <td>Data Science intern</td>\n",
       "      <td>Remote United States</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GitHub</td>\n",
       "      <td>Salary bonus</td>\n",
       "      <td>False</td>\n",
       "      <td>--</td>\n",
       "      <td>Remote United States</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42952</th>\n",
       "      <td>Equip Health</td>\n",
       "      <td>Data Science intern</td>\n",
       "      <td>Remote United States</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>LLMs</td>\n",
       "      <td>Salary bonus</td>\n",
       "      <td>False</td>\n",
       "      <td>--</td>\n",
       "      <td>Remote United States</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42953</th>\n",
       "      <td>Equip Health</td>\n",
       "      <td>Data Science intern</td>\n",
       "      <td>Remote United States</td>\n",
       "      <td>Internship</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Salary bonus</td>\n",
       "      <td>False</td>\n",
       "      <td>--</td>\n",
       "      <td>Remote United States</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Company                                 Job Title  \\\n",
       "17760  Mitek Systems  Machine Learning Researcher (internship)   \n",
       "17761  Mitek Systems  Machine Learning Researcher (internship)   \n",
       "17762  Mitek Systems  Machine Learning Researcher (internship)   \n",
       "17763  Mitek Systems  Machine Learning Researcher (internship)   \n",
       "17764  Mitek Systems  Machine Learning Researcher (internship)   \n",
       "...              ...                                       ...   \n",
       "42949   Equip Health                       Data Science intern   \n",
       "42950   Equip Health                       Data Science intern   \n",
       "42951   Equip Health                       Data Science intern   \n",
       "42952   Equip Health                       Data Science intern   \n",
       "42953   Equip Health                       Data Science intern   \n",
       "\n",
       "                   Location    Job Type Experience level  Salary  \\\n",
       "17760             Barcelona  Internship      Entry-level     0.0   \n",
       "17761             Barcelona  Internship      Entry-level     0.0   \n",
       "17762             Barcelona  Internship      Entry-level     0.0   \n",
       "17763             Barcelona  Internship      Entry-level     0.0   \n",
       "17764             Barcelona  Internship      Entry-level     0.0   \n",
       "...                     ...         ...              ...     ...   \n",
       "42949  Remote United States  Internship      Entry-level     0.0   \n",
       "42950  Remote United States  Internship      Entry-level     0.0   \n",
       "42951  Remote United States  Internship      Entry-level     0.0   \n",
       "42952  Remote United States  Internship      Entry-level     0.0   \n",
       "42953  Remote United States  Internship      Entry-level     0.0   \n",
       "\n",
       "      Requirment of the company           Facilities   Plus Currency  \\\n",
       "17760            Computer Vision  Career development  False       --   \n",
       "17761              Deep Learning  Career development  False       --   \n",
       "17762                     Docker  Career development  False       --   \n",
       "17763                        Git  Career development  False       --   \n",
       "17764                      Linux  Career development  False       --   \n",
       "...                          ...                 ...    ...      ...   \n",
       "42949           Computer Science        Salary bonus  False       --   \n",
       "42950                   Genetics        Salary bonus  False       --   \n",
       "42951                     GitHub        Salary bonus  False       --   \n",
       "42952                       LLMs        Salary bonus  False       --   \n",
       "42953           Machine Learning        Salary bonus  False       --   \n",
       "\n",
       "        City_State_Location Country_Location  \n",
       "17760             Barcelona             None  \n",
       "17761             Barcelona             None  \n",
       "17762             Barcelona             None  \n",
       "17763             Barcelona             None  \n",
       "17764             Barcelona             None  \n",
       "...                     ...              ...  \n",
       "42949  Remote United States             None  \n",
       "42950  Remote United States             None  \n",
       "42951  Remote United States             None  \n",
       "42952  Remote United States             None  \n",
       "42953  Remote United States             None  \n",
       "\n",
       "[66 rows x 12 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame[dataFrame[\"Job Title\"].str.contains('intern')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Plus</th>\n",
       "      <th>Currency</th>\n",
       "      <th>City_State_Location</th>\n",
       "      <th>Country_Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>59880</th>\n",
       "      <td>Wise</td>\n",
       "      <td>Data Analytics Manager - Compliance, Risk &amp; In...</td>\n",
       "      <td>London</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>Airflow</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>London</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59881</th>\n",
       "      <td>Wise</td>\n",
       "      <td>Data Analytics Manager - Compliance, Risk &amp; In...</td>\n",
       "      <td>London</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>APIs</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>London</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59882</th>\n",
       "      <td>Wise</td>\n",
       "      <td>Data Analytics Manager - Compliance, Risk &amp; In...</td>\n",
       "      <td>London</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>Data Analytics</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>London</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59883</th>\n",
       "      <td>Wise</td>\n",
       "      <td>Data Analytics Manager - Compliance, Risk &amp; In...</td>\n",
       "      <td>London</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>Data pipelines</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>London</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59884</th>\n",
       "      <td>Wise</td>\n",
       "      <td>Data Analytics Manager - Compliance, Risk &amp; In...</td>\n",
       "      <td>London</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>Data warehouse</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>London</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59885</th>\n",
       "      <td>Wise</td>\n",
       "      <td>Data Analytics Manager - Compliance, Risk &amp; In...</td>\n",
       "      <td>London</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>London</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Company                                          Job Title Location  \\\n",
       "59880    Wise  Data Analytics Manager - Compliance, Risk & In...   London   \n",
       "59881    Wise  Data Analytics Manager - Compliance, Risk & In...   London   \n",
       "59882    Wise  Data Analytics Manager - Compliance, Risk & In...   London   \n",
       "59883    Wise  Data Analytics Manager - Compliance, Risk & In...   London   \n",
       "59884    Wise  Data Analytics Manager - Compliance, Risk & In...   London   \n",
       "59885    Wise  Data Analytics Manager - Compliance, Risk & In...   London   \n",
       "\n",
       "        Job Type Experience level    Salary Requirment of the company   \\\n",
       "59880  Full Time      Entry-level  120000.0                    Airflow   \n",
       "59881  Full Time      Entry-level  120000.0                       APIs   \n",
       "59882  Full Time      Entry-level  120000.0             Data Analytics   \n",
       "59883  Full Time      Entry-level  120000.0             Data pipelines   \n",
       "59884  Full Time      Entry-level  120000.0             Data warehouse   \n",
       "59885  Full Time      Entry-level  120000.0                Engineering   \n",
       "\n",
       "          Facilities  Plus Currency City_State_Location Country_Location  \n",
       "59880  no-Facilities  True      USD              London             None  \n",
       "59881  no-Facilities  True      USD              London             None  \n",
       "59882  no-Facilities  True      USD              London             None  \n",
       "59883  no-Facilities  True      USD              London             None  \n",
       "59884  no-Facilities  True      USD              London             None  \n",
       "59885  no-Facilities  True      USD              London             None  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame[dataFrame['Job Title'] == 'Data Analytics Manager - Compliance, Risk & Internal Audit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [WinError 10060] Une\n",
      "[nltk_data]     tentative de connexion a √©chou√© car le parti connect√©\n",
      "[nltk_data]     n‚Äôa pas r√©pondu convenablement au-del√† d‚Äôune certaine\n",
      "[nltk_data]     dur√©e ou une connexion √©tablie a √©chou√© car l‚Äôh√¥te de\n",
      "[nltk_data]     connexion n‚Äôa pas r√©pondu>\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\socket.py:836\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[0;32m    835\u001b[0m     sock\u001b[39m.\u001b[39mbind(source_address)\n\u001b[1;32m--> 836\u001b[0m sock\u001b[39m.\u001b[39mconnect(sa)\n\u001b[0;32m    837\u001b[0m \u001b[39m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] Une tentative de connexion a √©chou√© car le parti connect√© n‚Äôa pas r√©pondu convenablement au-del√† d‚Äôune certaine dur√©e ou une connexion √©tablie a √©chou√© car l‚Äôh√¥te de connexion n‚Äôa pas r√©pondu",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Set the data directory for NLTK\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m# nltk.data.path.append(\"C:/Users/Youcode/nltk_data\")\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[39m# Download necessary NLTK data\u001b[39;00m\n\u001b[0;32m      7\u001b[0m nltk\u001b[39m.\u001b[39mdownload(\u001b[39m'\u001b[39m\u001b[39mpunkt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m nltk\u001b[39m.\u001b[39mdownload(\u001b[39m'\u001b[39m\u001b[39maveraged_perceptron_tagger\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\nltk\\downloader.py:777\u001b[0m, in \u001b[0;36mDownloader.download\u001b[1;34m(self, info_or_id, download_dir, quiet, force, prefix, halt_on_error, raise_on_error, print_error_to)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshow\u001b[39m(s, prefix2\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    769\u001b[0m     print_to(\n\u001b[0;32m    770\u001b[0m         textwrap\u001b[39m.\u001b[39mfill(\n\u001b[0;32m    771\u001b[0m             s,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    774\u001b[0m         )\n\u001b[0;32m    775\u001b[0m     )\n\u001b[1;32m--> 777\u001b[0m \u001b[39mfor\u001b[39;00m msg \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mincr_download(info_or_id, download_dir, force):\n\u001b[0;32m    778\u001b[0m     \u001b[39m# Error messages\u001b[39;00m\n\u001b[0;32m    779\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(msg, ErrorMessage):\n\u001b[0;32m    780\u001b[0m         show(msg\u001b[39m.\u001b[39mmessage)\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\nltk\\downloader.py:629\u001b[0m, in \u001b[0;36mDownloader.incr_download\u001b[1;34m(self, info_or_id, download_dir, force)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[39m# Look up the requested collection or package.\u001b[39;00m\n\u001b[0;32m    628\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 629\u001b[0m     info \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info_or_id(info_or_id)\n\u001b[0;32m    630\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mOSError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    631\u001b[0m     \u001b[39myield\u001b[39;00m ErrorMessage(\u001b[39mNone\u001b[39;00m, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError loading \u001b[39m\u001b[39m{\u001b[39;00minfo_or_id\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\nltk\\downloader.py:603\u001b[0m, in \u001b[0;36mDownloader._info_or_id\u001b[1;34m(self, info_or_id)\u001b[0m\n\u001b[0;32m    601\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_info_or_id\u001b[39m(\u001b[39mself\u001b[39m, info_or_id):\n\u001b[0;32m    602\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(info_or_id, \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 603\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo(info_or_id)\n\u001b[0;32m    604\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    605\u001b[0m         \u001b[39mreturn\u001b[39;00m info_or_id\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\nltk\\downloader.py:1009\u001b[0m, in \u001b[0;36mDownloader.info\u001b[1;34m(self, id)\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minfo\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39mid\u001b[39m):\n\u001b[0;32m   1007\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the ``Package`` or ``Collection`` record for the\u001b[39;00m\n\u001b[0;32m   1008\u001b[0m \u001b[39m    given item.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1009\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_index()\n\u001b[0;32m   1010\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_packages:\n\u001b[0;32m   1011\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_packages[\u001b[39mid\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\nltk\\downloader.py:952\u001b[0m, in \u001b[0;36mDownloader._update_index\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    948\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_url \u001b[39m=\u001b[39m url \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_url\n\u001b[0;32m    950\u001b[0m \u001b[39m# Download the index file.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39minternals\u001b[39m.\u001b[39mElementWrapper(\n\u001b[1;32m--> 952\u001b[0m     ElementTree\u001b[39m.\u001b[39mparse(urlopen(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_url))\u001b[39m.\u001b[39mgetroot()\n\u001b[0;32m    953\u001b[0m )\n\u001b[0;32m    954\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_timestamp \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    956\u001b[0m \u001b[39m# Build a dictionary of packages.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\urllib\\request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    516\u001b[0m     req \u001b[39m=\u001b[39m meth(req)\n\u001b[0;32m    518\u001b[0m sys\u001b[39m.\u001b[39maudit(\u001b[39m'\u001b[39m\u001b[39murllib.Request\u001b[39m\u001b[39m'\u001b[39m, req\u001b[39m.\u001b[39mfull_url, req\u001b[39m.\u001b[39mdata, req\u001b[39m.\u001b[39mheaders, req\u001b[39m.\u001b[39mget_method())\n\u001b[1;32m--> 519\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_open(req, data)\n\u001b[0;32m    521\u001b[0m \u001b[39m# post-process response\u001b[39;00m\n\u001b[0;32m    522\u001b[0m meth_name \u001b[39m=\u001b[39m protocol\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m_response\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\urllib\\request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m    535\u001b[0m protocol \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mtype\n\u001b[1;32m--> 536\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_chain(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_open, protocol, protocol \u001b[39m+\u001b[39m\n\u001b[0;32m    537\u001b[0m                           \u001b[39m'\u001b[39m\u001b[39m_open\u001b[39m\u001b[39m'\u001b[39m, req)\n\u001b[0;32m    538\u001b[0m \u001b[39mif\u001b[39;00m result:\n\u001b[0;32m    539\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs)\n\u001b[0;32m    497\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\urllib\\request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttps_open\u001b[39m(\u001b[39mself\u001b[39m, req):\n\u001b[1;32m-> 1391\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_open(http\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mHTTPSConnection, req,\n\u001b[0;32m   1392\u001b[0m         context\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_context, check_hostname\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_hostname)\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\urllib\\request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1346\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1347\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1348\u001b[0m         h\u001b[39m.\u001b[39mrequest(req\u001b[39m.\u001b[39mget_method(), req\u001b[39m.\u001b[39mselector, req\u001b[39m.\u001b[39mdata, headers,\n\u001b[0;32m   1349\u001b[0m                   encode_chunked\u001b[39m=\u001b[39mreq\u001b[39m.\u001b[39mhas_header(\u001b[39m'\u001b[39m\u001b[39mTransfer-encoding\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m   1350\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m \u001b[39mas\u001b[39;00m err: \u001b[39m# timeout error\u001b[39;00m\n\u001b[0;32m   1351\u001b[0m         \u001b[39mraise\u001b[39;00m URLError(err)\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\http\\client.py:1283\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1280\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\u001b[39mself\u001b[39m, method, url, body\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, headers\u001b[39m=\u001b[39m{}, \u001b[39m*\u001b[39m,\n\u001b[0;32m   1281\u001b[0m             encode_chunked\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m   1282\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1283\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\http\\client.py:1329\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(body, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1326\u001b[0m     \u001b[39m# RFC 2616 Section 3.7.1 says that text default has a\u001b[39;00m\n\u001b[0;32m   1327\u001b[0m     \u001b[39m# default charset of iso-8859-1.\u001b[39;00m\n\u001b[0;32m   1328\u001b[0m     body \u001b[39m=\u001b[39m _encode(body, \u001b[39m'\u001b[39m\u001b[39mbody\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m-> 1329\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mendheaders(body, encode_chunked\u001b[39m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\http\\client.py:1278\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1276\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1277\u001b[0m     \u001b[39mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1278\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_send_output(message_body, encode_chunked\u001b[39m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\http\\client.py:1038\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1036\u001b[0m msg \u001b[39m=\u001b[39m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer)\n\u001b[0;32m   1037\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1038\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(msg)\n\u001b[0;32m   1040\u001b[0m \u001b[39mif\u001b[39;00m message_body \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1041\u001b[0m \n\u001b[0;32m   1042\u001b[0m     \u001b[39m# create a consistent interface to message_body\u001b[39;00m\n\u001b[0;32m   1043\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(message_body, \u001b[39m'\u001b[39m\u001b[39mread\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m   1044\u001b[0m         \u001b[39m# Let file-like take precedence over byte-like.  This\u001b[39;00m\n\u001b[0;32m   1045\u001b[0m         \u001b[39m# is needed to allow the current position of mmap'ed\u001b[39;00m\n\u001b[0;32m   1046\u001b[0m         \u001b[39m# files to be taken into account.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\http\\client.py:976\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    974\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    975\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_open:\n\u001b[1;32m--> 976\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconnect()\n\u001b[0;32m    977\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    978\u001b[0m         \u001b[39mraise\u001b[39;00m NotConnected()\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\http\\client.py:1448\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1445\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconnect\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1446\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mConnect to a host on a given (SSL) port.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1448\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mconnect()\n\u001b[0;32m   1450\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tunnel_host:\n\u001b[0;32m   1451\u001b[0m         server_hostname \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tunnel_host\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\http\\client.py:942\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[39;00m\n\u001b[0;32m    941\u001b[0m sys\u001b[39m.\u001b[39maudit(\u001b[39m\"\u001b[39m\u001b[39mhttp.client.connect\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mport)\n\u001b[1;32m--> 942\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msock \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_connection(\n\u001b[0;32m    943\u001b[0m     (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhost,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mport), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtimeout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_address)\n\u001b[0;32m    944\u001b[0m \u001b[39m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n\u001b[0;32m    945\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\socket.py:843\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[39mexcept\u001b[39;00m error \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m    842\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m all_errors:\n\u001b[1;32m--> 843\u001b[0m         exceptions\u001b[39m.\u001b[39mclear()  \u001b[39m# raise only the last error\u001b[39;00m\n\u001b[0;32m    844\u001b[0m     exceptions\u001b[39m.\u001b[39mappend(exc)\n\u001b[0;32m    845\u001b[0m     \u001b[39mif\u001b[39;00m sock \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Set the data directory for NLTK\n",
    "# nltk.data.path.append(\"C:/Users/Youcode/nltk_data\")\n",
    "\n",
    "# Download necessary NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Youcode/nltk_data'\n    - 'c:\\\\Users\\\\Youcode\\\\miniconda3\\\\envs\\\\scraping_brief\\\\nltk_data'\n    - 'c:\\\\Users\\\\Youcode\\\\miniconda3\\\\envs\\\\scraping_brief\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Youcode\\\\miniconda3\\\\envs\\\\scraping_brief\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Youcode\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:/Users/Youcode/nltk_data'\n    - 'C:/Users/Youcode/nltk_data'\n    - ''\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[103], line 51\u001b[0m\n\u001b[0;32m     48\u001b[0m df \u001b[39m=\u001b[39m dataFrame\n\u001b[0;32m     50\u001b[0m \u001b[39m# Extract job names and create a new column\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mJob Name\u001b[39m\u001b[39m'\u001b[39m], df[\u001b[39m'\u001b[39m\u001b[39mMore Job Information\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mdf[\u001b[39m'\u001b[39m\u001b[39mJob Title\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(extract_job_name_and_more_info))\n\u001b[0;32m     53\u001b[0m \u001b[39m# Extract cities, states, and countries and create new columns\u001b[39;00m\n\u001b[0;32m     54\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mCity\u001b[39m\u001b[39m'\u001b[39m], df[\u001b[39m'\u001b[39m\u001b[39mState\u001b[39m\u001b[39m'\u001b[39m], df[\u001b[39m'\u001b[39m\u001b[39mCountry\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mdf[\u001b[39m'\u001b[39m\u001b[39mLocation\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mapply(extract_location_info))\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pandas\\core\\series.py:4771\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4661\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4662\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4663\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4666\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4667\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[0;32m   4668\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4669\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4670\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4771\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39mapply()\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pandas\\core\\apply.py:1123\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m   1122\u001b[0m \u001b[39m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1123\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pandas\\core\\apply.py:1174\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1172\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1173\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m-> 1174\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mmap_infer(\n\u001b[0;32m   1175\u001b[0m             values,\n\u001b[0;32m   1176\u001b[0m             f,\n\u001b[0;32m   1177\u001b[0m             convert\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconvert_dtype,\n\u001b[0;32m   1178\u001b[0m         )\n\u001b[0;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1181\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1182\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1183\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[103], line 8\u001b[0m, in \u001b[0;36mextract_job_name_and_more_info\u001b[1;34m(job_title)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mextract_job_name_and_more_info\u001b[39m(job_title):\n\u001b[1;32m----> 8\u001b[0m     words \u001b[39m=\u001b[39m word_tokenize(job_title)\n\u001b[0;32m      9\u001b[0m     tagged_words \u001b[39m=\u001b[39m pos_tag(words)\n\u001b[0;32m     11\u001b[0m     job_name \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:129\u001b[0m, in \u001b[0;36mword_tokenize\u001b[1;34m(text, language, preserve_line)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mword_tokenize\u001b[39m(text, language\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m\"\u001b[39m, preserve_line\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    115\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[39m    Return a tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[39m    using NLTK's recommended word tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m    :type preserve_line: bool\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m     sentences \u001b[39m=\u001b[39m [text] \u001b[39mif\u001b[39;00m preserve_line \u001b[39melse\u001b[39;00m sent_tokenize(text, language)\n\u001b[0;32m    130\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m    131\u001b[0m         token \u001b[39mfor\u001b[39;00m sent \u001b[39min\u001b[39;00m sentences \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m _treebank_word_tokenizer\u001b[39m.\u001b[39mtokenize(sent)\n\u001b[0;32m    132\u001b[0m     ]\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\nltk\\tokenize\\__init__.py:106\u001b[0m, in \u001b[0;36msent_tokenize\u001b[1;34m(text, language)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msent_tokenize\u001b[39m(text, language\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     97\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[39m    Return a sentence-tokenized copy of *text*,\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[39m    using NLTK's recommended sentence tokenizer\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[39m    :param language: the model name in the Punkt corpus\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 106\u001b[0m     tokenizer \u001b[39m=\u001b[39m load(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtokenizers/punkt/\u001b[39m\u001b[39m{\u001b[39;00mlanguage\u001b[39m}\u001b[39;00m\u001b[39m.pickle\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    107\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenizer\u001b[39m.\u001b[39mtokenize(text)\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\nltk\\data.py:750\u001b[0m, in \u001b[0;36mload\u001b[1;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[0;32m    747\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m<<Loading \u001b[39m\u001b[39m{\u001b[39;00mresource_url\u001b[39m}\u001b[39;00m\u001b[39m>>\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    749\u001b[0m \u001b[39m# Load the resource.\u001b[39;00m\n\u001b[1;32m--> 750\u001b[0m opened_resource \u001b[39m=\u001b[39m _open(resource_url)\n\u001b[0;32m    752\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mformat\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraw\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m     resource_val \u001b[39m=\u001b[39m opened_resource\u001b[39m.\u001b[39mread()\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\nltk\\data.py:876\u001b[0m, in \u001b[0;36m_open\u001b[1;34m(resource_url)\u001b[0m\n\u001b[0;32m    873\u001b[0m protocol, path_ \u001b[39m=\u001b[39m split_resource_url(resource_url)\n\u001b[0;32m    875\u001b[0m \u001b[39mif\u001b[39;00m protocol \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m protocol\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnltk\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> 876\u001b[0m     \u001b[39mreturn\u001b[39;00m find(path_, path \u001b[39m+\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39mopen()\n\u001b[0;32m    877\u001b[0m \u001b[39melif\u001b[39;00m protocol\u001b[39m.\u001b[39mlower() \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfile\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    878\u001b[0m     \u001b[39m# urllib might not use mode='rb', so handle this one ourselves:\u001b[39;00m\n\u001b[0;32m    879\u001b[0m     \u001b[39mreturn\u001b[39;00m find(path_, [\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39mopen()\n",
      "File \u001b[1;32mc:\\Users\\Youcode\\miniconda3\\envs\\scraping_brief\\Lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m sep \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m70\u001b[39m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/english.pickle\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Youcode/nltk_data'\n    - 'c:\\\\Users\\\\Youcode\\\\miniconda3\\\\envs\\\\scraping_brief\\\\nltk_data'\n    - 'c:\\\\Users\\\\Youcode\\\\miniconda3\\\\envs\\\\scraping_brief\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Youcode\\\\miniconda3\\\\envs\\\\scraping_brief\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Youcode\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n    - 'C:/Users/Youcode/nltk_data'\n    - 'C:/Users/Youcode/nltk_data'\n    - ''\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "\n",
    "\n",
    "def extract_job_name_and_more_info(job_title):\n",
    "    words = word_tokenize(job_title)\n",
    "    tagged_words = pos_tag(words)\n",
    "\n",
    "    job_name = []\n",
    "    more_info = []\n",
    "\n",
    "    for i in range(len(tagged_words)):\n",
    "        word, tag = tagged_words[i]\n",
    "        if tag == 'NN' or tag == 'NNP':  # Noun or Proper Noun (potential job name)\n",
    "            prev_word, prev_tag = tagged_words[i - 1] if i > 0 else (None, None)\n",
    "            if prev_tag != 'JJ':  # Exclude if the previous word is an adjective (e.g., \"Senior\")\n",
    "                job_name.append(word)\n",
    "            else:\n",
    "                more_info.append(word)\n",
    "        else:\n",
    "            more_info.append(word)\n",
    "\n",
    "    return ' '.join(job_name), ' '.join(more_info)\n",
    "\n",
    "def extract_location_info(location):\n",
    "    location_info = location.split(', ')\n",
    "    num_parts = len(location_info)\n",
    "\n",
    "    city = location_info[0]\n",
    "\n",
    "    state = location_info[1] if num_parts > 1 else \"\"\n",
    "\n",
    "    country = location_info[-1]\n",
    "\n",
    "    return city, state, country\n",
    "\n",
    "# Example DataFrame with the provided lines\n",
    "# data = {'Company': ['Freeform', 'Opera', 'Bosch Group', 'Tiendanube', 'Ask Media Group', 'Angi', 'Visa', 'AVIV Group', 'Mutt Data', 'Global Atlantic Financial Group', 'REWE International Dienstleistungsgesellschaft m.b.H', 'Imagen Technologies', 'Sunnova Energy International'],\n",
    "#         'Job Title': ['Senior Software Engineer (Data Pipeline)', 'Senior Data Scientist', 'Data Science Lead (Hybrid)', 'Business Intelligence Analyst', 'Lead Business Intelligence Analyst', 'Senior Data Scientist', 'Sr Data Engineer', 'Data Modeler', 'Data Engineer', 'VP, Actuarial Modeling and Data Management', 'Junior Data Science Engineer (m/w/x)', 'Healthcare Data Analyst', 'Data Scientist'],\n",
    "#         'Location': ['Los Angeles, CA', 'Wroclaw, PL', 'Mount Prospect, IL, United States', 'Buenos Aires, Buenos Aires, Argentina - Remote', 'United States - Remote', 'Indianapolis, IN - Hybrid', 'Bengaluru, India', 'Brussels, Germany', 'Argentina', 'Boston, Massachusetts, United States', 'Wien, Austria', 'Remote', 'United States'],\n",
    "#         'Job Type': ['Full Time', 'Full Time', 'Full Time', 'Full Time', 'Full Time', 'Full Time', 'Full Time', 'Full Time', 'Full Time', 'Full Time', 'Full Time', 'Full Time', 'Full Time'],\n",
    "#         'Experience level': ['Senior-level', 'Senior-level', '', 'Senior-level', 'Senior-level', 'Senior-level', 'Senior-level', 'Senior-level', 'Mid-level', 'Senior-level', 'Entry-level', 'Mid-level', 'Senior-level'],\n",
    "#         'Salary': ['140K+', '129K+ *', '63K+ *', '49K+ *', '180K+', '', '115K+ *', '62K+ *', '73K+ *', '127K+', '', '60K+', '129K+ *'],\n",
    "#         'Requirements': ['Big Data, CI/CD, Computer Science, Computer Vision, Data pipelines, Data Warehousing', 'Agile, Airflow, Big Data, BigQuery, Computer Science, Data analysis', 'A/B testing, Data visualization, Economics, Engineering, Mathematics, Power BI', 'Business Intelligence, E-commerce, Python, SQL, Tableau,', 'A/B testing, Business Intelligence, Data visualization, KPIs, Looker, Mathematics', 'Big Data, Data Mining, Machine Learning, Mathematics, ML models, PhD', 'Agile, Big Data, Business Intelligence, Data Mining, Data visualization, Engineering', 'Architecture, Data governance, Data management, Engineering, KPIs, Privacy', 'Airflow, Architecture, AWS, Big Data, BigQuery, CI/CD', 'Data management, Excel, Finance, Mathematics, ML models, Privacy', 'CI/CD, Computer Science, Data pipelines, Deep Learning, Oracle, Pipelines', 'Business Intelligence, Engineering, Genetics, Git, Pandas, Python', 'Agile, APIs, Architecture, AWS, Big Data, Classification'],\n",
    "#         'Facilities': ['Career development, Equity, Flex hours, Flex vacation, Health care', 'Career development, Relocation support,,,', 'Career development, Competitive pay, Health care,,', ',,,,', 'Career development, Competitive pay, Equity, Fertility benefits', '401(k) matching, Career development, Competitive pay, Equity, Flex vacation', 'Career development, Flex hours, Startup environment,,,', 'Flex hours, Flex vacation,,,', 'Career development, Fitness / gym, Flex hours, Flex vacation, Gear', '401(k) matching, Career development, Competitive pay, Equity, Fertility benefits', ',,,,', 'Salary bonus, Startup environment,,,']}\n",
    "df = dataFrame\n",
    "\n",
    "# Extract job names and create a new column\n",
    "df['Job Name'], df['More Job Information'] = zip(*df['Job Title'].apply(extract_job_name_and_more_info))\n",
    "\n",
    "# Extract cities, states, and countries and create new columns\n",
    "df['City'], df['State'], df['Country'] = zip(*df['Location'].apply(extract_location_info))\n",
    "\n",
    "# Drop the original 'Job Title' and 'Location' columns (optional)\n",
    "# df.drop(columns=['Job Title', 'Location'], inplace=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Plus</th>\n",
       "      <th>Currency</th>\n",
       "      <th>City_State_Location</th>\n",
       "      <th>Country_Location</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>DeepL</td>\n",
       "      <td>Data Scientist | Insights (f/m/d) - GER, UK, N...</td>\n",
       "      <td>Remote job</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>Agile</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Remote job</td>\n",
       "      <td>None</td>\n",
       "      <td>Remote job</td>\n",
       "      <td></td>\n",
       "      <td>Remote job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>DeepL</td>\n",
       "      <td>Data Scientist | Insights (f/m/d) - GER, UK, N...</td>\n",
       "      <td>Remote job</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>Data visualization</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Remote job</td>\n",
       "      <td>None</td>\n",
       "      <td>Remote job</td>\n",
       "      <td></td>\n",
       "      <td>Remote job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>DeepL</td>\n",
       "      <td>Data Scientist | Insights (f/m/d) - GER, UK, N...</td>\n",
       "      <td>Remote job</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>Economics</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Remote job</td>\n",
       "      <td>None</td>\n",
       "      <td>Remote job</td>\n",
       "      <td></td>\n",
       "      <td>Remote job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>DeepL</td>\n",
       "      <td>Data Scientist | Insights (f/m/d) - GER, UK, N...</td>\n",
       "      <td>Remote job</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>Machine Learning</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Remote job</td>\n",
       "      <td>None</td>\n",
       "      <td>Remote job</td>\n",
       "      <td></td>\n",
       "      <td>Remote job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>DeepL</td>\n",
       "      <td>Data Scientist | Insights (f/m/d) - GER, UK, N...</td>\n",
       "      <td>Remote job</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>129000.0</td>\n",
       "      <td>Mathematics</td>\n",
       "      <td>Career development</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>Remote job</td>\n",
       "      <td>None</td>\n",
       "      <td>Remote job</td>\n",
       "      <td></td>\n",
       "      <td>Remote job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60037</th>\n",
       "      <td>Galileo Financial Technologies</td>\n",
       "      <td>Staff ETL Developer</td>\n",
       "      <td>UT - Remote; UT - Cottonwood Heights</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>Data pipelines</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>UT - Remote; UT - Cottonwood Heights</td>\n",
       "      <td>None</td>\n",
       "      <td>UT - Remote; UT - Cottonwood Heights</td>\n",
       "      <td></td>\n",
       "      <td>UT - Remote; UT - Cottonwood Heights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60038</th>\n",
       "      <td>Galileo Financial Technologies</td>\n",
       "      <td>Staff ETL Developer</td>\n",
       "      <td>UT - Remote; UT - Cottonwood Heights</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>Data warehouse</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>UT - Remote; UT - Cottonwood Heights</td>\n",
       "      <td>None</td>\n",
       "      <td>UT - Remote; UT - Cottonwood Heights</td>\n",
       "      <td></td>\n",
       "      <td>UT - Remote; UT - Cottonwood Heights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60039</th>\n",
       "      <td>Galileo Financial Technologies</td>\n",
       "      <td>Staff ETL Developer</td>\n",
       "      <td>UT - Remote; UT - Cottonwood Heights</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>Data Warehousing</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>UT - Remote; UT - Cottonwood Heights</td>\n",
       "      <td>None</td>\n",
       "      <td>UT - Remote; UT - Cottonwood Heights</td>\n",
       "      <td></td>\n",
       "      <td>UT - Remote; UT - Cottonwood Heights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60040</th>\n",
       "      <td>Galileo Financial Technologies</td>\n",
       "      <td>Staff ETL Developer</td>\n",
       "      <td>UT - Remote; UT - Cottonwood Heights</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>Engineering</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>UT - Remote; UT - Cottonwood Heights</td>\n",
       "      <td>None</td>\n",
       "      <td>UT - Remote; UT - Cottonwood Heights</td>\n",
       "      <td></td>\n",
       "      <td>UT - Remote; UT - Cottonwood Heights</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60041</th>\n",
       "      <td>Galileo Financial Technologies</td>\n",
       "      <td>Staff ETL Developer</td>\n",
       "      <td>UT - Remote; UT - Cottonwood Heights</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>ETL</td>\n",
       "      <td>no-Facilities</td>\n",
       "      <td>True</td>\n",
       "      <td>USD</td>\n",
       "      <td>UT - Remote; UT - Cottonwood Heights</td>\n",
       "      <td>None</td>\n",
       "      <td>UT - Remote; UT - Cottonwood Heights</td>\n",
       "      <td></td>\n",
       "      <td>UT - Remote; UT - Cottonwood Heights</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6856 rows √ó 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Company  \\\n",
       "336                             DeepL   \n",
       "337                             DeepL   \n",
       "338                             DeepL   \n",
       "339                             DeepL   \n",
       "340                             DeepL   \n",
       "...                               ...   \n",
       "60037  Galileo Financial Technologies   \n",
       "60038  Galileo Financial Technologies   \n",
       "60039  Galileo Financial Technologies   \n",
       "60040  Galileo Financial Technologies   \n",
       "60041  Galileo Financial Technologies   \n",
       "\n",
       "                                               Job Title  \\\n",
       "336    Data Scientist | Insights (f/m/d) - GER, UK, N...   \n",
       "337    Data Scientist | Insights (f/m/d) - GER, UK, N...   \n",
       "338    Data Scientist | Insights (f/m/d) - GER, UK, N...   \n",
       "339    Data Scientist | Insights (f/m/d) - GER, UK, N...   \n",
       "340    Data Scientist | Insights (f/m/d) - GER, UK, N...   \n",
       "...                                                  ...   \n",
       "60037                                Staff ETL Developer   \n",
       "60038                                Staff ETL Developer   \n",
       "60039                                Staff ETL Developer   \n",
       "60040                                Staff ETL Developer   \n",
       "60041                                Staff ETL Developer   \n",
       "\n",
       "                                   Location   Job Type Experience level  \\\n",
       "336                              Remote job  Full Time     Senior-level   \n",
       "337                              Remote job  Full Time     Senior-level   \n",
       "338                              Remote job  Full Time     Senior-level   \n",
       "339                              Remote job  Full Time     Senior-level   \n",
       "340                              Remote job  Full Time     Senior-level   \n",
       "...                                     ...        ...              ...   \n",
       "60037  UT - Remote; UT - Cottonwood Heights  Full Time     Senior-level   \n",
       "60038  UT - Remote; UT - Cottonwood Heights  Full Time     Senior-level   \n",
       "60039  UT - Remote; UT - Cottonwood Heights  Full Time     Senior-level   \n",
       "60040  UT - Remote; UT - Cottonwood Heights  Full Time     Senior-level   \n",
       "60041  UT - Remote; UT - Cottonwood Heights  Full Time     Senior-level   \n",
       "\n",
       "         Salary Requirment of the company           Facilities  Plus Currency  \\\n",
       "336    129000.0                      Agile  Career development  True      USD   \n",
       "337    129000.0         Data visualization  Career development  True      USD   \n",
       "338    129000.0                  Economics  Career development  True      USD   \n",
       "339    129000.0           Machine Learning  Career development  True      USD   \n",
       "340    129000.0                Mathematics  Career development  True      USD   \n",
       "...         ...                        ...                 ...   ...      ...   \n",
       "60037   63000.0             Data pipelines       no-Facilities  True      USD   \n",
       "60038   63000.0             Data warehouse       no-Facilities  True      USD   \n",
       "60039   63000.0           Data Warehousing       no-Facilities  True      USD   \n",
       "60040   63000.0                Engineering       no-Facilities  True      USD   \n",
       "60041   63000.0                        ETL       no-Facilities  True      USD   \n",
       "\n",
       "                        City_State_Location Country_Location  \\\n",
       "336                              Remote job             None   \n",
       "337                              Remote job             None   \n",
       "338                              Remote job             None   \n",
       "339                              Remote job             None   \n",
       "340                              Remote job             None   \n",
       "...                                     ...              ...   \n",
       "60037  UT - Remote; UT - Cottonwood Heights             None   \n",
       "60038  UT - Remote; UT - Cottonwood Heights             None   \n",
       "60039  UT - Remote; UT - Cottonwood Heights             None   \n",
       "60040  UT - Remote; UT - Cottonwood Heights             None   \n",
       "60041  UT - Remote; UT - Cottonwood Heights             None   \n",
       "\n",
       "                                       City State  \\\n",
       "336                              Remote job         \n",
       "337                              Remote job         \n",
       "338                              Remote job         \n",
       "339                              Remote job         \n",
       "340                              Remote job         \n",
       "...                                     ...   ...   \n",
       "60037  UT - Remote; UT - Cottonwood Heights         \n",
       "60038  UT - Remote; UT - Cottonwood Heights         \n",
       "60039  UT - Remote; UT - Cottonwood Heights         \n",
       "60040  UT - Remote; UT - Cottonwood Heights         \n",
       "60041  UT - Remote; UT - Cottonwood Heights         \n",
       "\n",
       "                                    Country  \n",
       "336                              Remote job  \n",
       "337                              Remote job  \n",
       "338                              Remote job  \n",
       "339                              Remote job  \n",
       "340                              Remote job  \n",
       "...                                     ...  \n",
       "60037  UT - Remote; UT - Cottonwood Heights  \n",
       "60038  UT - Remote; UT - Cottonwood Heights  \n",
       "60039  UT - Remote; UT - Cottonwood Heights  \n",
       "60040  UT - Remote; UT - Cottonwood Heights  \n",
       "60041  UT - Remote; UT - Cottonwood Heights  \n",
       "\n",
       "[6856 rows x 15 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_location_info(location):\n",
    "    location_info = location.split(', ')\n",
    "    num_parts = len(location_info)\n",
    "\n",
    "    city = location_info[0]\n",
    "\n",
    "    state = location_info[1] if num_parts > 1 else \"\"\n",
    "\n",
    "    country = location_info[-1]\n",
    "\n",
    "\n",
    "    return city, state, country\n",
    "\n",
    "df = dataFrame\n",
    "\n",
    "# Extract cities, states, and countries and create new columns\n",
    "df['City'], df['State'], df['Country'] = zip(*df['Location'].apply(extract_location_info))\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "df[df['City'].str.contains('Remote')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Detected Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGS</td>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>richardson, tx, united states</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48K+ *</td>\n",
       "      <td>Computer Science,Data quality,Genetics,Mathema...</td>\n",
       "      <td>,,,,</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ocorian</td>\n",
       "      <td>AML/CFT &amp; Data Analyst</td>\n",
       "      <td>eb√®ne, mauritius</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48K+ *</td>\n",
       "      <td>Agile,Data management,Finance,Security,,</td>\n",
       "      <td>,,,,</td>\n",
       "      <td>Mauritius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cricut</td>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>south jordan, ut, united states</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90K+ *</td>\n",
       "      <td>Agile,Architecture,AWS,Computer Science,Comput...</td>\n",
       "      <td>Career development,,,,</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bosch Group</td>\n",
       "      <td>Application Developer &amp; Data Analyst</td>\n",
       "      <td>nonantola, italy</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>48K+ *</td>\n",
       "      <td>Engineering,Industrial,Oracle,Power BI,R,R&amp;D</td>\n",
       "      <td>,,,,</td>\n",
       "      <td>Italy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Publicis Groupe</td>\n",
       "      <td>Data Engineer Full time (Public Sector) USA</td>\n",
       "      <td>arlington, va, united states</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Mid-level</td>\n",
       "      <td>108K+</td>\n",
       "      <td>AWS,Azure,Computer Science,Consulting,Dataflow...</td>\n",
       "      <td>Flex hours,Flex vacation,Parental leave,Unlimi...</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3193</th>\n",
       "      <td>Western Digital</td>\n",
       "      <td>Data Scientist - New College Graduate</td>\n",
       "      <td>bi√±an, philippines</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>39K+ *</td>\n",
       "      <td>APIs,Clustering,Computer Science,Data visualiz...</td>\n",
       "      <td>Career development,,,,</td>\n",
       "      <td>Philippines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3194</th>\n",
       "      <td>Experian</td>\n",
       "      <td>Cloud Data Analyst</td>\n",
       "      <td>heredia, costa rica</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>92K+ *</td>\n",
       "      <td>AWS,Big Data,Computer Science,GCP,Snowflake,SQL</td>\n",
       "      <td>Equity,Medical leave,Salary bonus,,</td>\n",
       "      <td>Costa Rica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3195</th>\n",
       "      <td>Locus Robotics</td>\n",
       "      <td>Robotics Engineer, Sensors</td>\n",
       "      <td>wilmington, ma, united states</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>62K+ *</td>\n",
       "      <td>E-commerce,Engineering,Linux,Python,Robotics,S...</td>\n",
       "      <td>,,,,</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3196</th>\n",
       "      <td>ATB Financial</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>edmonton, alberta, canada</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>39K+ *</td>\n",
       "      <td>Computer Science,Data Analytics,Data Mining,Ec...</td>\n",
       "      <td>Career development,Startup environment,,,</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>Shippeo</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>paris, france</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>115K+ *</td>\n",
       "      <td>Airflow,Architecture,BigQuery,CI/CD,Computer S...</td>\n",
       "      <td>,,,,</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3198 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Company                                    Job Title  \\\n",
       "0                 SGS                        Clinical Data Analyst   \n",
       "1             Ocorian                       AML/CFT & Data Analyst   \n",
       "2              Cricut                    Machine Learning Engineer   \n",
       "3         Bosch Group         Application Developer & Data Analyst   \n",
       "4     Publicis Groupe  Data Engineer Full time (Public Sector) USA   \n",
       "...               ...                                          ...   \n",
       "3193  Western Digital        Data Scientist - New College Graduate   \n",
       "3194         Experian                           Cloud Data Analyst   \n",
       "3195   Locus Robotics                   Robotics Engineer, Sensors   \n",
       "3196    ATB Financial                               Data Scientist   \n",
       "3197          Shippeo                         Senior Data Engineer   \n",
       "\n",
       "                             Location   Job Type Experience level    Salary  \\\n",
       "0       richardson, tx, united states  Full Time      Entry-level    48K+ *   \n",
       "1                    eb√®ne, mauritius  Full Time      Entry-level    48K+ *   \n",
       "2     south jordan, ut, united states  Full Time              NaN    90K+ *   \n",
       "3                    nonantola, italy  Full Time      Entry-level    48K+ *   \n",
       "4        arlington, va, united states  Full Time        Mid-level     108K+   \n",
       "...                               ...        ...              ...       ...   \n",
       "3193               bi√±an, philippines  Full Time      Entry-level    39K+ *   \n",
       "3194              heredia, costa rica  Full Time     Senior-level    92K+ *   \n",
       "3195    wilmington, ma, united states  Full Time     Senior-level    62K+ *   \n",
       "3196        edmonton, alberta, canada  Full Time      Entry-level    39K+ *   \n",
       "3197                    paris, france  Full Time     Senior-level   115K+ *   \n",
       "\n",
       "                             Requirment of the company   \\\n",
       "0     Computer Science,Data quality,Genetics,Mathema...   \n",
       "1              Agile,Data management,Finance,Security,,   \n",
       "2     Agile,Architecture,AWS,Computer Science,Comput...   \n",
       "3          Engineering,Industrial,Oracle,Power BI,R,R&D   \n",
       "4     AWS,Azure,Computer Science,Consulting,Dataflow...   \n",
       "...                                                 ...   \n",
       "3193  APIs,Clustering,Computer Science,Data visualiz...   \n",
       "3194    AWS,Big Data,Computer Science,GCP,Snowflake,SQL   \n",
       "3195  E-commerce,Engineering,Linux,Python,Robotics,S...   \n",
       "3196  Computer Science,Data Analytics,Data Mining,Ec...   \n",
       "3197  Airflow,Architecture,BigQuery,CI/CD,Computer S...   \n",
       "\n",
       "                                             Facilities Detected Country  \n",
       "0                                                  ,,,,    United States  \n",
       "1                                                  ,,,,        Mauritius  \n",
       "2                                Career development,,,,    United States  \n",
       "3                                                  ,,,,            Italy  \n",
       "4     Flex hours,Flex vacation,Parental leave,Unlimi...    United States  \n",
       "...                                                 ...              ...  \n",
       "3193                             Career development,,,,      Philippines  \n",
       "3194                Equity,Medical leave,Salary bonus,,       Costa Rica  \n",
       "3195                                               ,,,,    United States  \n",
       "3196          Career development,Startup environment,,,           Canada  \n",
       "3197                                               ,,,,           France  \n",
       "\n",
       "[3198 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pycountry\n",
    "\n",
    "# Sample DataFrame with the job titles and locations\n",
    "\n",
    "\n",
    "df = dataFrame\n",
    "\n",
    "# Function to detect countries in job locations\n",
    "def detect_country(location):\n",
    "    location=str(location).split(',')[-1]\n",
    "    try:\n",
    "        return pycountry.countries.search_fuzzy(location)[0].name\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return location\n",
    "\n",
    "# Preprocess 'Location' column to contain only country names\n",
    "df['Location'] = df['Location'].str.lower()  # Convert to lowercase for case-insensitive matching\n",
    "\n",
    "# Create a new column to store detected countries\n",
    "df['Detected Country'] = df['Location'].apply(detect_country)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job Type</th>\n",
       "      <th>Experience level</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Requirment of the company</th>\n",
       "      <th>Facilities</th>\n",
       "      <th>Detected Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DeepL</td>\n",
       "      <td>Data Scientist | Insights (f/m/d) - GER, UK, N...</td>\n",
       "      <td>remote job</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>129K+ *</td>\n",
       "      <td>Agile,Data visualization,Economics,Machine Lea...</td>\n",
       "      <td>Career development,,,,</td>\n",
       "      <td>remote job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>EX2 Outcoding</td>\n",
       "      <td>Data Engineer Scientist</td>\n",
       "      <td>remote worldwide</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Mid-level</td>\n",
       "      <td>73K+ *</td>\n",
       "      <td>Computer Science,Data Mining,Engineering,Pytho...</td>\n",
       "      <td>,,,,</td>\n",
       "      <td>remote worldwide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Neo Cybernetica</td>\n",
       "      <td>ML Research Engineer</td>\n",
       "      <td>poland or eastern europe remote</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>105K+ *</td>\n",
       "      <td>Cybernetics,DataRobot,Engineering,Keras,Machin...</td>\n",
       "      <td>Career development,Flex hours,Health care,Star...</td>\n",
       "      <td>poland or eastern europe remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Podium</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>lehi, utah, open to remote</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>115K+ *</td>\n",
       "      <td>APIs,Big Data,Computer Science,Data analysis,D...</td>\n",
       "      <td>,,,,</td>\n",
       "      <td>open to remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Tiendanube</td>\n",
       "      <td>Business Intelligence Analyst</td>\n",
       "      <td>buenos aires, buenos aires, argentina - remote</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>49K+ *</td>\n",
       "      <td>Business Intelligence,E-commerce,Python,SQL,Ta...</td>\n",
       "      <td>,,,,</td>\n",
       "      <td>argentina - remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3161</th>\n",
       "      <td>EquipmentShare</td>\n",
       "      <td>BI Data Analyst</td>\n",
       "      <td>remote: kansas city; denver; chicago; phoenix;...</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>36K+ *</td>\n",
       "      <td>Business Analytics,Business Intelligence,Finan...</td>\n",
       "      <td>401(k) matching,Career development,Competitive...</td>\n",
       "      <td>remote: kansas city; denver; chicago; phoenix;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>Rackspace</td>\n",
       "      <td>Trainee Data Engineer - R-16792</td>\n",
       "      <td>india - remote</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>59K+ *</td>\n",
       "      <td>Architecture,Azure,Big Data,Computer Science,D...</td>\n",
       "      <td>Team events,,,,</td>\n",
       "      <td>india - remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3174</th>\n",
       "      <td>Sand Cherry Associates</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>united states - remote</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Mid-level</td>\n",
       "      <td>65K+</td>\n",
       "      <td>Computer Science,Consulting,Data Analytics,Dat...</td>\n",
       "      <td>401(k) matching,Flex hours,Flex vacation,Healt...</td>\n",
       "      <td>united states - remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3176</th>\n",
       "      <td>iTech Media</td>\n",
       "      <td>Data Analytics Engineer</td>\n",
       "      <td>warsaw remote</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Entry-level</td>\n",
       "      <td>30K+ *</td>\n",
       "      <td>Airflow,Data Analytics,Engineering,Finance,Kaf...</td>\n",
       "      <td>Career development,Flex hours,Flex vacation,He...</td>\n",
       "      <td>warsaw remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3178</th>\n",
       "      <td>Galileo Financial Technologies</td>\n",
       "      <td>Staff ETL Developer</td>\n",
       "      <td>ut - remote; ut - cottonwood heights</td>\n",
       "      <td>Full Time</td>\n",
       "      <td>Senior-level</td>\n",
       "      <td>63K+ *</td>\n",
       "      <td>Computer Science,Data pipelines,Data warehouse...</td>\n",
       "      <td>Flex hours,Health care,Insurance,,</td>\n",
       "      <td>ut - remote; ut - cottonwood heights</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>438 rows √ó 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Company  \\\n",
       "19                             DeepL   \n",
       "24                     EX2 Outcoding   \n",
       "30                   Neo Cybernetica   \n",
       "32                            Podium   \n",
       "37                        Tiendanube   \n",
       "...                              ...   \n",
       "3161                  EquipmentShare   \n",
       "3164                       Rackspace   \n",
       "3174          Sand Cherry Associates   \n",
       "3176                     iTech Media   \n",
       "3178  Galileo Financial Technologies   \n",
       "\n",
       "                                              Job Title  \\\n",
       "19    Data Scientist | Insights (f/m/d) - GER, UK, N...   \n",
       "24                              Data Engineer Scientist   \n",
       "30                                 ML Research Engineer   \n",
       "32                                 Senior Data Engineer   \n",
       "37                        Business Intelligence Analyst   \n",
       "...                                                 ...   \n",
       "3161                                    BI Data Analyst   \n",
       "3164                    Trainee Data Engineer - R-16792   \n",
       "3174                                       Data Analyst   \n",
       "3176                            Data Analytics Engineer   \n",
       "3178                                Staff ETL Developer   \n",
       "\n",
       "                                               Location   Job Type  \\\n",
       "19                                           remote job  Full Time   \n",
       "24                                     remote worldwide  Full Time   \n",
       "30                      poland or eastern europe remote  Full Time   \n",
       "32                           lehi, utah, open to remote  Full Time   \n",
       "37       buenos aires, buenos aires, argentina - remote  Full Time   \n",
       "...                                                 ...        ...   \n",
       "3161  remote: kansas city; denver; chicago; phoenix;...  Full Time   \n",
       "3164                                     india - remote  Full Time   \n",
       "3174                             united states - remote  Full Time   \n",
       "3176                                      warsaw remote  Full Time   \n",
       "3178               ut - remote; ut - cottonwood heights  Full Time   \n",
       "\n",
       "     Experience level    Salary  \\\n",
       "19       Senior-level   129K+ *   \n",
       "24          Mid-level    73K+ *   \n",
       "30       Senior-level   105K+ *   \n",
       "32       Senior-level   115K+ *   \n",
       "37       Senior-level    49K+ *   \n",
       "...               ...       ...   \n",
       "3161     Senior-level    36K+ *   \n",
       "3164      Entry-level    59K+ *   \n",
       "3174        Mid-level      65K+   \n",
       "3176      Entry-level    30K+ *   \n",
       "3178     Senior-level    63K+ *   \n",
       "\n",
       "                             Requirment of the company   \\\n",
       "19    Agile,Data visualization,Economics,Machine Lea...   \n",
       "24    Computer Science,Data Mining,Engineering,Pytho...   \n",
       "30    Cybernetics,DataRobot,Engineering,Keras,Machin...   \n",
       "32    APIs,Big Data,Computer Science,Data analysis,D...   \n",
       "37    Business Intelligence,E-commerce,Python,SQL,Ta...   \n",
       "...                                                 ...   \n",
       "3161  Business Analytics,Business Intelligence,Finan...   \n",
       "3164  Architecture,Azure,Big Data,Computer Science,D...   \n",
       "3174  Computer Science,Consulting,Data Analytics,Dat...   \n",
       "3176  Airflow,Data Analytics,Engineering,Finance,Kaf...   \n",
       "3178  Computer Science,Data pipelines,Data warehouse...   \n",
       "\n",
       "                                             Facilities  \\\n",
       "19                               Career development,,,,   \n",
       "24                                                 ,,,,   \n",
       "30    Career development,Flex hours,Health care,Star...   \n",
       "32                                                 ,,,,   \n",
       "37                                                 ,,,,   \n",
       "...                                                 ...   \n",
       "3161  401(k) matching,Career development,Competitive...   \n",
       "3164                                    Team events,,,,   \n",
       "3174  401(k) matching,Flex hours,Flex vacation,Healt...   \n",
       "3176  Career development,Flex hours,Flex vacation,He...   \n",
       "3178                 Flex hours,Health care,Insurance,,   \n",
       "\n",
       "                                       Detected Country  \n",
       "19                                           remote job  \n",
       "24                                     remote worldwide  \n",
       "30                      poland or eastern europe remote  \n",
       "32                                       open to remote  \n",
       "37                                   argentina - remote  \n",
       "...                                                 ...  \n",
       "3161  remote: kansas city; denver; chicago; phoenix;...  \n",
       "3164                                     india - remote  \n",
       "3174                             united states - remote  \n",
       "3176                                      warsaw remote  \n",
       "3178               ut - remote; ut - cottonwood heights  \n",
       "\n",
       "[438 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Detected Country'].str.contains('remote')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA INSERTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sly\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = sly.create_engine('postgresql+psycopg2://postgres:admin@localhost:5432/postgres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans['repo_id'] = general_data['full_name'].astype('category').cat.codes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping_brief",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
